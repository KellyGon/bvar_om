\documentclass[12pt,a4paper,twoside]{extbook}
\usepackage{amsfonts}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage[russian]{babel}
\usepackage[numbers,square,sort]{natbib}
\bibpunct{(}{)}{,}{a}{,}{,}
\usepackage{graphicx}
\usepackage{lscape}
\usepackage{float}

%\renewcommand{\baselinestretch}{1.3}

\usepackage{setspace}

\usepackage{tabularx}

%\usepackage{subfloat}
\usepackage{longtable}
\usepackage{booktabs}

%\usepackage{literat}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[center]{subfigure}
%\setcounter{lofdepth}{2}
\usepackage{captcont}
%\def\figbox#1{%
%\fbox{\hbox to 2in{%
%\vbox to 1.5in{%
%\vfil
%\hbox to 2in{%
%\hfil
%#1
%\hfil}%
%\vfil}}}}

\usepackage[font=small,labelfont=bf]{caption}
%\usepackage[font=footnotesize]{subfig}

\usepackage{geometry}
\geometry{top=2cm,bottom=3cm, right=1cm,left=2cm}
\geometry{includehead}
\geometry{includefoot}

%\usepackage{ccaption}
%\captiondelim{. }

\usepackage{fancyhdr}

\pagestyle{fancy} %
\fancyhf{} %

%\renewcommand{\headrulewidth}{1 pt} %
%\renewcommand{\footrulewidth}{0 pt} %
%
%\fancyhead[RO]{\rightmark} \fancyhead[LE]{\leftmark}
%\fancyfoot[RO,LE]{\thepage} %
%\renewcommand{\chaptermark}[1]%
%{\markboth{ %\bfseries
%		%\chaptername~
%\small \thechapter.\ #1}{}}
%\renewcommand{\sectionmark}[1]%
%{\markright{%\bfseries
%\thesection.\ #1}
%}

\renewcommand{\headrulewidth}{1 pt} %
\renewcommand{\footrulewidth}{0 pt} %

\fancyhead[RO]{\rightmark}
 \fancyhead[LE]{\leftmark}

\fancyfoot[RO,LE]{\thepage} %

\renewcommand{\chaptermark}[1]%
{\markboth{ \scshape %\bfseries
		\chaptername~\small\thechapter.\ #1}{}}

\renewcommand{\sectionmark}[1]%
{\markright{\scshape%\bfseries
\thesection.\ #1}
}






\fancypagestyle{plain}{
%
\fancyhf{} % clear all header and footer fields
\fancyhead[RO,LE]{}
\fancyfoot[RO,LE]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
}


%-------------------------------------------------------------------
 % Правильные подписи под таблицей и рисунком
 \makeatletter
 \setlength\abovecaptionskip{2\p@}
 \setlength\belowcaptionskip{4\p@}
 \def\capfigure{figure}
 \def\captable{table}
 \long\def\@makecaption#1#2{%
 \vskip\abovecaptionskip
 \ifx\@captype\capfigure
 \centering #1.~~#2 \par
 \else
 \raggedleft #1. \par \centering #2 \par
 \fi
 \vskip \belowcaptionskip}
 \renewcommand{\@biblabel}[1]{#1}
 \makeatother
 %-------------------------------------------------------------------

%-------------------------------------------------------------------
 \makeatletter
 \LTcapwidth=\textwidth
 \def\LT@makecaption#1#2#3{%
 \LT@mcol\LT@cols c{\hbox to\z@{\hss\parbox[t]\LTcapwidth{%
 \sbox\@tempboxa{ #1{#2: } #3}%
 \ifdim\wd\@tempboxa>\hsize
 \hbox to\hsize{\hfil #1#2.\mbox{ }}
 \hbox to\hsize{\hfil \parbox[c]{0.9\textwidth}{\centering #3}\hfil }%%
 \else
 \hbox to\hsize{\hfil #1#2.\mbox{ }}
 \hbox to\hsize{\hfil #3\hfil}%
 \fi
 \endgraf\vskip 0.5\baselineskip}%
 \hss}}}
 \makeatother

%\makeatletter

%\renewcommand{\@biblabel}[1]{#1.}Дг
%\makeatother

\newtheorem{proposition}{Утверждение}

\newtheorem{assumption}{Предположение}

\newcolumntype{.}{D{.}{.}{5}}
\newcommand{\vc}[1]{%
   \ensuremath{%
   \ifcat #1a\mathbf{#1}%
   \else\boldsymbol{#1}%
   \fi}%
}

\newcommand{\ve}{\ensuremath{\operatorname{vec}}}
\newcommand{\vech}{\ensuremath{\operatorname{vech}}}

\begin{document}

\thispagestyle{empty}
\begin{center}
 \small Федеральное государственное бюджетное образовательное

 учреждение высшего профессионального образования \vspace{2ex}

 \normalsize
 <<РОССИЙСКАЯ АКАДЕМИЯ НАРОДНОГО ХОЗЯЙСТВА

 И ГОСУДАРСТВЕННОЙ СЛУЖБЫ ПРИ ПРЕЗИДЕНТЕ РОССИЙСКОЙ

 ФЕДЕРАЦИИ>>
 \end{center}

 \begin{raggedright}
 УДК

 № госрегистрации

 Инв. №
 \end{raggedright}

 \hfill\begin{minipage}[position]{20em}\centering
 <<УТВЕРЖДАЮ>>

 Ректор Академии\vspace{3ex}

 \rule{10em}{1pt} В.А Мау\vspace{2ex}

 <<\rule{2em}{1pt} >> \rule{7em}{1pt} 2013г.

 \end{minipage}

 \vfill


 \vfill\normalsize
 \begin{center}
 \Large ОТЧЕТ\normalsize

 О НАУЧНО-ИССЛЕДОВАТЕЛЬСКОЙ РАБОТЕ

 по теме:
 \vfill\normalsize

 \Large\textsc{ \textbf{Структурные VAR и VECM}}\\
 \end{center}
 \vfill\vfill\normalsize

 \noindent Научно-исследовательская работа выполнена в соответствии с Государственным заданием РАНХиГС при Президенте Российской Федерации на 2013 год

 \vfill

 \begin{center}
 \vfill\vfill\normalsize Москва\\ 2014

 \end{center}

 \newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                              РЕФЕРАТ
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Реферат}

 \markboth {\scshape Реферат}{\scshape Реферат}

 



\renewcommand{\contentsname}{Содержание}
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                              ВВЕДЕНИЕ
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{spacing}{1.3}


\chapter*{Введение}
 \addcontentsline{toc}{chapter}{Введение} %
 \markboth {\scshape Введение}{\scshape Введение}



\newpage

\thispagestyle{empty}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                              Условные обозначения и сокращения
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\chapter*{Условные обозначения и сокращения}
%\addcontentsline{toc}{chapter}{Условные обозначения и сокращения}
% \markboth {\scshape Условные обозначения и сокращения}{\scshape Условные обозначения и сокращения}
%
%\begin{tabbing}
%TS~~~~~~~~~~~~~~~~        \=-- ~\=стационарный относительно тренда ряд, \textit{Trend Stationary}\\
%DS        \>--\>стационарный в разностях ряд, \textit{Differences Stationary}\\
%OLS           \>--\> метод наименьших квадратов, \textit{Ordinary Least Squares}\\
%GLS        \>--\> обобщённый метод наименьших квадратов, \textit{Generalised Least Squares}\\
%NLS         \>--\> нелинейный метод наименьших квадратов, \textit{Nonlinear Least Squares}\\
%WSLS        \>--\> взвешенный симметричный метод наименьших квадратов,\\
%\>\>\textit{Weighted Symmetric Least Squares}\\
%(A)DF \>--\> (расширенный) тест Дики-Фуллера, \textit{(Augmented) Dickey-Fuller test}\\
%(F)CLT        \>--\> (функциональна) центральная предельная теорема\\
%\>\> \textit{(Functional) Central Limit Theorem}\\
%CMT  \>--\> теорема о непрерывном отображеии, \textit{Continuous Mapping Theorem}  \\
%HAC        \>--\> робастная к гетероседастичности и автокорреляции оценка \\
%\>\> ковариационной матрицы, \textit{Heteroskedasticity and}\\
%\>\>\textit{Autocorrelation Consistent covariance matrix estimator}\\
%LBI  \>--\> локально-наилучший инвариантный тест, \textit{Locally Best Invariant}\\
%(M)AIC \>--\>(модифицированный) информационный критерий Акаике, \\
%\>\>\textit{(Modified) Akaike Information Criteria}\\
%BIC        \>--\> информационный критерий Шварца, или Байесовский, \\
%\>\>\textit{Schwarz or Bayesian Information Criterion}\\
%DGP        \>--\> процесс порождения данных, \textit{Data Generating Process}\\
%$A(L)$          \>--\> лаговый полином\\
%$i.i.d.$        \>--\> независимые одинакого распределённые случайные величины,\\
%\>\>\textit{independently and identically distributed r.v.}\\
%\textit{I}(1)           \>--\> интегрированный порядка 1 ряд (нестационарный)\\
%\textit{I}(0)           \>--\> интегрированный порядка 0 ряд (стационарный)\\
%$N(a,b)$          \>--\> нормальное распределение с математическим ожиданием $a$\\
%\>\>и дисперсией $b$\\
%$O_p(1)$          \>--\> ограниченная по вероятности случайная величина\\
%$o_p(1)$        \>--\> сходящаяся по вероятности случайная величина\\
%$I_p$    \>--\> единичная матрица размерности $p$\\
%$E(a|b)$       \>--\> математическое ожидание $a$, условное на $b$\\
%$\Delta$       \>--\> оператор дифференцирования ряда\\
%$\|\cdot\|$       \>--\> Евклидова норма матрицы\\
%$\lfloor\cdot\rfloor$       \>--\> целая часть числа\\
%$Pr(\cdot)$          \>--\> вероятность события\\
%$\stackrel{p}{\longrightarrow}$ \>--\> сходимость по вероятности\\
%$p\lim$ \>--\> предел по вероятности\\
%$\stackrel{d}{\longrightarrow}$       \>--\> сходимость по распределению\\
%$\Rightarrow$      \>--\> слабая сходимость\\
%$T$          \>--\>длина временного ряда\\
%$T_j$          \>--\>дата \textit{j}-го структурного сдвига\\
%$\lambda_j=T_j/T$          \>--\> доля даты \textit{j}-го структурного сдвига\\
%$D_t(T_1)$          \>--\> импульсная дамми, $=\mathbb I(t=T_1+1)$\\
%$DU_t$, $DU_t(T_j)$          \>--\>дамми, отвечающая за сдвиг в уровнях $=\mathbb I(t>T_1+1)$\\
%$DT_t$, $DT_t(T_j)$          \>--\>дамми, отвечающая за изменение наклона тренда, $=(t-T_1)\mathbb I(t>T_1+1)$\\
%$\varepsilon$          \>--\>параметр усечения ряда (доля от выборки)\\
%$\Lambda$, $\Lambda(\varepsilon)$  \>--\>множество возможных дат структурных сдвигов\\
%\end{tabbing}
%\newpage
%\thispagestyle{empty}



%\chapter*{Введение}
%\addcontentsline{toc}{chapter}{Введение}


\newpage
\thispagestyle{empty}

\chapter{Теория SVAR и SVECM}

Innovation accounting и анализ импульсных откликов в контексте моделей векторых авторегрессий (VAR) начался с работ \citep{Sims1980,Sims1981} в качестве альтернативного подхода к классическому макроэкономическому анализу. Главный элемент критики Симса по поводу последнего типа анализа заключается в том, что макроэкономические модели часто не основаны на надежных экономических теориях или имеющиеся теории не способны предложить полностью специфицированую модель. Если экономические теории не доступны для спецификации модели, должны применяться статистические инструменты. При таком подходе полагается достаточно свободная модель, которая не накладывает жесткие априорные ограничения на процесс порождения. Статистические инструменты используется после этого для определения возможных ограничений. VAR модели представляют собой класс свободных моделей, которые могут быть использованы при таком подходе. Конечно, чтобы интерпретировать эти модели, должны быть сделаны некоторые ограничительные предположения. В частности, упорядочение переменных
может иметь важное значение для интерпретации импульсных откликов. \citep{Sims1981} предполагает попробовать различное упорядочивание и исследовать чувствительность соответствующих ортогонализованных импульсных откликов и соответствующих выводов на упорядочения переменных.

Данный раздел частично основан на \citep{Lutkepohl2005}, добавляя новые работы.

\section{Структурные VAR-модели}\label{SVAR}

В эмпирических работах часто имеет интерес отклик одной переменной на импульс другой переменной в система, которая также включает дополнительные переменные. Таким образом, хочется исследовать импульсные отклики между двумя переменными в системе с более высокой размерностью. Конечно, если есть реакция одной переменной на импульс другой переменной, мы можем назвать последнюю причинной для первой. В этом разделе мы изучим этот тип причинности, прослеживая влияние экзогенного шока или инновации в одной переменной на некоторую или все другие переменные. Этот вид анализа поверхности отклика иногда называется \textit{анализом мультипликаторов}.  

\subsection{Отклики на ошибки прогноза}

Рассмотрим простой случай VAR(1) процесса:
\begin{equation}\label{IR1}
y_t=v+A_1y_{t-1}+u_t,
\end{equation}
где $y_t=(y_{1t},\dots,y_{Kt})'$ -- случайный вектор размерности $(K\times 1)$, $A_i$ -- фиксированная матрциа коэффициентов размерности $(K\times K)$, $v=(v_1,\dots,v_K)'$ -- фиксированный вектор констант размерности $(K\times 1)$, который	допускает возможсость ненулевого среднего $E(y_t)$. Вектор $u_t=(u_{1t},\dots,u_{Kt})'$ являестя $K$-мерным \textit{процессом белого шума} или \textit{инноваций}, то есть $E(u_t)=0$, $E(u_tu'_t)=\Sigma_u$ и $E(u_tu'_s)=0$ для $s\neq t$. Ковариационная матрица $\Sigma_u$ предполагается невырожденной, если не предполагается обратное.

Процесс \eqref{IR1} имеет представление скользящего среднего (MA) при условии стабильности\footnote{Процесс VAR(1) является стабильным, если все собственные значения $A_1$ меньше единицы по модулю. Это эквивалентно условию $\det(I_K-A_1z)\neq0$ для $|z|\leq1$.}:
\begin{equation}\label{IR2}
y_t=\mu+\sum_{i=1}^\infty{\Phi_i}u_{t-i},\quad t=0,\pm1,\pm2,\dots,
\end{equation}
где $\mu=(I_K-A_1)^{-1}v$, $\Phi_i=A_1^i$.

Предположим, что нас интересует влияние инновации в какой-то из переменных. Чтобы изолировать такое влияние, предположим, что все переменные равны своему среднему значению до момента времени $t=0$, $y_t=\mu$ для $t<0$, а какая-то из переменных ($i$-я переменная) увеличивается на одну единицу в период $t=0$, то есть $u_{i,0}=1$. Мы можем проследить, что случится с системой в течение периодов $t=1,2,\dots$, если больше не происходит никаких шоков, то есть $u_{j,0}=0$ для всех $j\neq i$. Поскольку нас не интересует среднее системы, а только вариаци переменных около их средних, можно предположить, что все переменные имеют нулевое среднее и положить $v=0$ в \eqref{IR1}. Рассмотрим следующий простой пример трехмерной системы:
\begin{equation}\label{IR3}
\begin{bmatrix}
y_{1,t}\\
y_{2,t}\\
y_{3,t}
\end{bmatrix}=
\begin{bmatrix}
0.5&0&0\\
0.1&0.1&0.3\\
0&0.2&0.3
\end{bmatrix}
\begin{bmatrix}
y_{1,t-1}\\
y_{2,t-1}\\
y_{3,t-1}
\end{bmatrix}+
\begin{bmatrix}
u_{1,t}\\
u_{2,t}\\
u_{3,t}
\end{bmatrix}
\end{equation}
Пусть в первой переменной в период $t=0$ происходит единичный шок. Тогда можно получить, что 
\begin{eqnarray*}
y_0&=&
\begin{bmatrix}
y_{1,0}\\
y_{2,0}\\
y_{3,0}
\end{bmatrix}=
\begin{bmatrix}
u_{1,0}\\
u_{2,0}\\
u_{3,0}
\end{bmatrix}=
\begin{bmatrix}
1\\
0\\
0
\end{bmatrix},\\
y_1&=&
\begin{bmatrix}
y_{1,1}\\
y_{2,1}\\
y_{3,1}
\end{bmatrix}=A_1y_0=
\begin{bmatrix}
0.5\\
0.1\\
0
\end{bmatrix},\\
y_2&=&
\begin{bmatrix}
y_{1,2}\\
y_{2,2}\\
y_{3,2}
\end{bmatrix}=A_1y_1=A_1^2y_0=
\begin{bmatrix}
0.25\\
0.06\\
0.02
\end{bmatrix}.
\end{eqnarray*}
Продолжая эту процедуру, оказывается, что $y_i=(y_{1,i},y_{2,i},y_{3,i})'$ является только первым столбцом матрицы $A_1^i$. Аналогично можно показать, что единичный шок во второй (третьей) переменной в $t=0$ после $i$ периодов приводит к вектору $y_i$, который является вторым (третьим) столбцом матрицы $A_1^i$. Таким образом, элементы $A_1^i$ представляют эффект единичных шоков в переменных системы после $i$ периодов. Следовательно, они называются импульсными откликами, или динамическими мультипликаторами. Также отметим, что поскольку $A_1^i=\Phi_i$ является $i$-й матрицей коэффициентов в MA-представлении \eqref{IR2} процесса VAR(1), матрицы коэффициентов MA содержат импульсные отклики системы. 

Результат выше можно обобщить на случай процесса векторной авторегрессии порядка $p$, VAR($p$):
\begin{equation}\label{IR4}
y_t=v+A_1y_{t-1}+\dots+A_py_{t-p}+u_t.
\end{equation}
Любой VAR($p$)-процесс можно переписать в виде VAR(1) как
\begin{equation}\label{IR5}
Y_t=\vc{v}+\vc{A}Y_{t-1}+U_t,
\end{equation}
где
\begin{eqnarray*}
Y_t&=&\underset{(Kp \times 1)}{
\begin{bmatrix}
y_t\\
y_{t-1}\\
\vdots\\
y_{t-p+1}
\end{bmatrix}},\quad
\vc{v}=\underset{(Kp \times 1)}{
\begin{bmatrix}
v\\
0\\
\vdots\\
0
\end{bmatrix}},\\
\vc{A}&=&\underset{(Kp \times Kp)}{
\begin{bmatrix}
A_1 & A_2 & \dots & A_{p-1} & A_p\\
I_K & 0 & \dots & 0 & 0\\
0 & I_K &  & 0 & 0\\
\vdots & & \ddots & \vdots & \vdots\\
0 & 0 & \dots & I_K & 0
\end{bmatrix}},\quad
U_t=\underset{(Kp \times 1)}{
\begin{bmatrix}
u_t\\
0\\
\vdots\\
0
\end{bmatrix}}.
\end{eqnarray*}
Процесс $Y_t$ являестя стабильным, если $\det(I_{K_p}-\vc{A}_1z)\neq0$ для $|z|\leq1$. При этом условии $Y_t$ имеет MA-представление:
\begin{equation}\label{IR6}
Y_t=\vc{\mu}+\sum_{i=1}^\infty{\vc{A}_i}U_{t-i}.
\end{equation}
Процесс $y_t$ можно переписать в виде
\begin{equation}\label{IR7}
y_t=JY_t=J\vc{\mu}+\sum_{i=1}^\infty{J\vc{A}_iJ'JU_{t-i}}=\mu+\sum_{i=1}^\infty{\Phi_iu_{t-i}},
\end{equation}
где $J=[I_K \ : \ 0 \ : \ \cdots \ : \ 0]$ -- матрица размерности $(K\times Kp)$, $\mu=J\vc{\mu}$, $\Phi_i=J\vc{A}_iJ'$ и из-за особой структуры процесса белого шума $U_t$ мы имеем $U_t=J'JU_t$ и $JU_t=u_t$. Матрица $\Phi_i$ иначе может быть записана как $\Phi_0=I_K$, $\Phi_i=\sum_{j=1}^i{\Phi_{i-j}A_j}$, $i=1,2,\dots$.

Относительно импульсных откликов, как и в случае VAR(1) предположим, что $y_t=0$ для $t<0$, $u_t=0$ для $t>0$ и $y_0=u_0$ -- $K$-мерный единичный вектор $e_k$, скажем, с единицей на $k$-ой координате и нулями в остальных случаях. Тогда $Y_0=(e'_k,0,\dots,0)'$ и $Y_i=\vc{A}^iY_0$. Следовательно, импульсные отклики являются элементами верхнего левого $(K\times K)$ блока матрицы $\vc{A}^i$. Эта матрица, однако, является $i$-ой матрицей коэффициентов $\Phi_i$ MA-представление \eqref{IR7} для $y_t$. Другими словами, $\phi_{jk,i}$ -- $jk$-ый элемент $\Phi_i$, представляет реакцию $j$-ой переменной системы на единичный шок в переменной $k$, произошедший $i$ периодов назад, если, конечно, эффект не загрязнен другими шоками в системе. Поскольку $u_t$ является только прогнозом ошибки на один шаг вперед VAR процесса, шоки, рассмотренные здесь, можно рассматривать как ошибки прогноза, а импульсные отклики иногда называют\textit{импульсными откливами ошибки прогноза}.

Если переменные имеют различные масштабы, иногда полезно рассмотреть инновации одного стандартного отклонения, а не единичные шоки. Однако это всего лишь вопрос масштабирования импульчных откликов, такое шкалирвоание может иногда давать лучшие картинки динамических соотношений, поскольку средний размер инноваций, происходящих в системе, зависит от их стандартного отклонения.

Импульсные отклики равны нулю, если одна из переменных не является причинной по Гренджеру для других переменных, взятых в качестве группы. Более точно, инновация в переменной $k$ не имеет влияния на другие переменные, если она не причинна по Гренджеру для множества оставшихся переменных. В прикладных работах часто первостепенный интерес заклчается в том, имеет ли одна переменная влияние на конкретную другую переменную. То есть хотелось бы знать, для некоторого $k\neq j$ равно ли значение $\phi_{jk,i}$ нулю для $i=1,2,\dots$. Если $\phi_{jk,i}$ представляет фактические реакции переменной $j$ на единичный шок в переменной $k$, мы можем назвать последнюю \textit{непричинной} для $j$-ой переменной, если $\phi_{jk,i}=0$ для $i=1,2,\dots$. Чтобы проверить последнее условие, нет необходимости вычислять бесконечно много матриц $\Phi_i$. Достаточно проверить первые $p(K-1)$ матриц $\Phi_i$, поскольку если для $K$-мерного стационарного и стабильного VAR($p$) первые $p(K-1)$ откликов переменной $j$ на импульс в переменной $k$ нулевые, то все следующие отклики должны быть также нулевыми (см. \citep[Proposition 2.4]{Lutkepohl2005})

Иногда исследователя интересует накопленное влияние в течение нескольких периодов от шока одной переменной. Этот влияние может быть определено путем суммирования матриц коэффициентов MA-представления. Например, $k$-ый столбец в $\Psi_n=\sum_{i=0}^n{\Phi_i}$ содержит \textit{накопленные отклики} в течение $n$ периодов от единичного шока в $k$-ой переменной системы. Эти значения иногда называют $n$-ыми \textit{промежуточными мультипликаторами} (interim multipliers). Полные накпленные влияния для всех будущих периодов могут быть получены, суммируя все матрицы коэффициентов MA. $\Psi_\infty=\sum_{i=0}^\infty{\Phi_i}$ инога называют матрицей \textit{долгосрочных эффектов}, или \textit{полным мультипликатором}. Поскольку MA-оператор $\Phi(z)$  является обратным VAR-оператора $A(z)=I_K-A_1z-\dots-A_pz^p$, долгосрочные эффекты могут быть легко получены как
\begin{equation}\label{IR8}
\Psi_\infty=\Phi(1)=(I_K-A_1-\dots-A_p)^{-1}.
\end{equation}

\subsection{Отклики на ортогональные импульсы}\label{ROI}

Проблематичное предположение о данном виде анализа импульсных откликов заключается в том, что шок происходит только в одной переменной. Такое предположение может быть разумно, если шоки в различных переменных являюстя независимыми. Если это не так, можно утверждать, что ошибки состоят из всех влияний и переменных, которые не включены непосредственно во множество переменных $y$. Таким образом, в дополнении к силам, которые влияют на все переменные, могут быть силы, которые влияют, скажем, только на 1-у переменную. Если шок в первой переменной произошел из-за таких сил, то можно разумно интерпретировать коэффициенты $\Phi_i$ как динамические отклики. С другой стороны, корреляция ошибок может указывать на то, что шок в одной переменной вероятно будет сопровождаться шоком в другой переменной. В этом случае, полагая все другие остатки нулю, можно прийти к вводящим в заблуждение выводам о фактических динамических соотношениях между переменными. Все это являестя причиной, почему анализ импульсных откликов часто применяется в терминах следующего MA-представления:
\begin{equation}\label{IR9}
y_t=\mu+\sum_{i=0}^\infty{\Phi_i}PP^{-1}u_{t-i}=\mu+\sum_{i=0}^\infty{\Theta_i}w_{t-i},
\end{equation}
где $\Sigma_u=PP'$, $P$ -- нижнетреугольная матрица с положительными диагональными элементами, $\Theta_i=\Phi_iP$, компоненты $w_t=(w_{1t},\dots,w_{Kt})'$ являются некоррелированными и имеют единичную дисперсию ($w_t=P^{-1}u_t$, $\Sigma_w=P^{-1}\Sigma_u(P^{-1})'=I_K$), $\Sigma_w=I_K$. Компоненту среднего можно исключить из этого уранвения, поскольку она не является важной для текущего анализа. %Вспомним, что представление \eqref{IR9} получается путем разложения $\Sigma_u$ как $\Sigma_u=PP'$, где $P$ -- нижнетреугольная матрица, и определения $\Theta_i=\Phi_iP$ и $w_t=P^{-1}u_t$. 
В \eqref{IR9} разумно предположить, что изменение в одной компоненте $w_t$ не имеет влияния на другие компоненты, поскольку эти компоненты ортогональны (некоррелированы). Кроме того, дисперсии этих компонент равны единице. Таким образом, единичная инновация является только инновацией размера одного стандартного отклонения. Элементы $\Theta_i$ интерпретируются как отклики системы на такие инновации. Более точно, $jk$-ый элемент $\Theta_i$ предполагаестя представляющим влияние на переменную $j$ от единичной инновации в $k$-ой переменной, которая произошла $i$ периодов назад.

Чтобы соотнести эти импульсные отклики с VAR-моделью, рассмотрим процесс VAR($p$) с нулевым средним:
\begin{equation}\label{IR10}
y_t=A_1y_{t-1}+\dots+A_py_{t-p}+u_t.
\end{equation}
Этот процесс может быть переписан таким способом, чтобы остатки в различных уравнениях были некоррелированы. Для этой цели мы выбираем разложение ковариационной матрицы белого шума $\Sigma_u=W\Sigma_\varepsilon W'$, где $\Sigma_\varepsilon$ -- диагональная матрциа с положительными диагональными элементами, а $W$ -- нижнетреугольная матрица с единичной диагональю. Это разложение получено из разложения Холецкого $\Sigma_u=PP'$, определяя диагональную матрицу $D$, которая имеет ту же самую главную диагональ, и специфицируя $W=PD^{-1}$ и $\Sigma_\varepsilon=DD'$.

Умножая слева \eqref{IR10} на $\mathsf A=W^{-1}$, получаем
\begin{equation}\label{IR11}
\mathsf Ay_t=A_1^*y_{t-1}+\dots+A_p^*y_{t-p}+\varepsilon_t,
\end{equation}
где $A_i^*=\mathsf AA_i$, $i=1,\dots,p$, и $\varepsilon_t=(\varepsilon_{1t},\dots,\varepsilon_{Kt})'=\mathsf Au_t$ имеет диагональную ковариационную матрицу
\begin{equation*}
\Sigma_\varepsilon=E(\varepsilon_t\varepsilon'_t)=\mathsf AE(u_tu'_t)\mathsf A'=\mathsf A\Sigma_u\mathsf A'.
\end{equation*}
Добавление $(I_K-\mathsf A)$ к обоим сторонам \eqref{IR11} дает
\begin{equation}\label{IR12}
y_t=A_0^*y_t+A_1^*y_{t-1}+\dots+A_p^*y_{t-p}+\varepsilon_t,
\end{equation}
где $A_0^*=I_K-\mathsf A$. Поскольку $W$ является нижнетреугольной с единичной диагональю, то же самое верно и для $\mathsf A$. Следовательно,
\begin{equation*}
A_0^*=I_K-\mathsf A=
\begin{bmatrix}
0 & 0 & \dots & 0 & 0\\
\beta_{21} & 0 & \dots & 0 & 0\\
\vdots & \ddots & \ddots & & \vdots\\
\vdots & &\ddots & \ddots & \vdots\\
\beta_{K1} & \beta_{K2} & \dots  & \beta_{K,K-1} & 0
\end{bmatrix}
\end{equation*}
является нижнетреугольной матрицей с нулевой диагональю, и, таким образом, в представлении \eqref{IR12} нашего VAR($p$)-процесса первое уравнение не содержит текущих $y$-ов с правой стороны. Второе уравнение может содержать $y_{1t}$ в правой стороне. В общем случае, $k$-е уравнение может содержать $y_{1t},\dots,y_{k-1,t}$ и не содержать $y_{kt},\dots,y_{K,t}$ в правой стороне. Таким образом, если \eqref{IR12}  отражает фактическое поведение в системе, $y_{st}$ не может иметь мгновенное влияние на $y_{kt}$ для $k<s$. В эконометрической литературе такая система называется \textit{рекурсивной моделью} (см. \citep[Section 9.6]{Theil1971}). Herman Wold has advocated эти модели, где исследователь должен специфицировать мгновенный (текущий?) ``причинный'' порядок переменных. Этот тип причинности иногда называют \textit{Вольд-причинностью} (Wold-causality). Если мы проследим $\varepsilon_{it}$-инновации размера одной стандартной ошибки через систему \eqref{IR12}, мы  просто получим $\Theta$ импульсные отклики. Это может быть видно, решая систему \eqref{IR12} для $y_t$,
\begin{equation*}
y_t=(I_K-A_0^*)^{-1}A_1^*y_{t-1}+\dots+(I_K-A_0^*)^{-1}A_p^*y_{t-p}+(I_K-A_0^*)^{-1}\varepsilon_t.
\end{equation*}
Замечая, что $(I_K-A_0^*)^{-1}=W=PD^{-1}$ показывает, что текущие эффекты шоков одного стандартного отклонения ($\varepsilon_{it}$ размера одного стандартного отклонения) на систему представлены элементами $WD=P=\Theta_0$, поскольку диагональные элементы в $D$ являются просто стандартными отклонениями компонент $\varepsilon_t$. $\Theta_i$ может быть получена, прослеживая эти эффекты через систему.

Заметим, что $\Theta_0=P$ является нижнетреугольной, и некоторые элементы ниже диагонали будут ненулевыми, если $\Sigma_u$ имеет ненулевые элементы вне диагонали. Если ковариационная матрица белого шума $\Sigma_u$ содержит нули, некоторые компоненты $u_t=(u_{1t},\dots,u_{Kt})'$ одновременно некоррелированы. Предположим, например, что $u_{1t}$ некоррелированы с $u_{it}$ для $i=2,\dots,K$. В этом случае $\mathsf A=W^{-1}$ и, таким образом, $A_0^*$ имеют блок нулей, так что $y_1$ не имеет мгновенного влияния на $y_i$, $i=2,\dots,K$. Поскольку элементы $P=\Theta_0$ представляют немедленные отклики системы на единичные инновации, они иногда называются \textit{мультипликаторами вклада} (impact multipliers).

Чтобы определить, нет ли отклика одной переменной на импульс в одной из других переменных, достаточно рассмотреть первые $pK-p$ коэффициентов откликов и немедленный эффект.

Тот факт, что $\Theta_0$ -- нижнетреугольная, показывает, что имеет значение упорядочивание переменных, то есть важно, какая из переменных называется $y_1$, какая -- $y_2$ и так далее. Одна из проблем с этим типом анализа импульсных откликов заключается в том, что упорядочивание переменных не может быть определено статистическими методами, а должно быть специфицировано исследователем. Порядок должен быть таким, чтобы первая переменная являлась единственной, которая имеет потенциальное немедленное влияние на другие переменные. Вторая переменная может иметь влияние на оставшиеся $K-2$ компоненты $y_t$, но не на $y_1$, и так далее. Установление такого упорядочивания может быть достаточно сложным упражнением на практике. Выбор упорядочивания, причинное упорядочивание Вольда, может в значительной мере определять импульсные отклики и поэтому является критически важным для интерпретации системы. В настоящее время мы имеем дело только с известными системами. В этой ситуации, предположение, что порядок является известным, не может быть большим ограничением. 

Наша интерпретация ортогонализованных импульсных откликов основана на представлении \eqref{IR12}, и импульсы рассматриваются как изменения в наблюдаемых переменных. Иногда более правдоподобно сосредоточить внимание на импульсы, которые не могут быть легко связанными с изменениями конкретной наблюдаемой переменной внутри системы. В этом случае может быть более логично основывать интерпретацию на MA-представлении \eqref{IR9}, которое раскладывает переменные по их вкладу инноваций $w_{kt}$. Если эти инновации могут быть связаны с конкретным импульсом на систему, ортгонализованные импульсные отклики отражают реакции переменных таким возможно ненаблюдаемым инновациям. В этом случае конкретный импульс или шок в систему может иметь текущий эффект на несколько переменных, в то время как некоторый другой импульс может иметь только текущий эффект на одну конкретную переменную и может влиять на другие переменные только с запаздыванием. Раскладывая $\Sigma_u=PP'$ с некоторой нетреугольной матрицей $P$, также возможно, что шоки имеют текущее влияние на все наблюдаемые переменные в системе. В данном виде интерпретации нахождение матрицы разложения $P$ и, следовательно, инноваций $w_t$, которые фактически могут быть связаны с интересующими шоками, часто является сложной частью анализа.

\subsection{Идентификация структурных шоков}

\subsubsection{$\mathsf A$-модель, $\mathsf B$-модель и $\mathsf{AB}$-модель}\label{AB}

В данном подразделе мы рассмотрим $\mathsf A$-модель, $\mathsf B$-модель и $\mathsf{AB}$-модель в терминологии \citep{Lutkepohl2005}.
Рассмотрим модель \eqref{IR11}. В отличие от MA-представления \eqref{IR9}, где $\Theta_i=\Phi_iP$, рассмотри другое MA-представление:
\begin{equation}\label{AM1}
y_t=\Theta_0\varepsilon_t+\Theta_1\varepsilon_{t-1}+\theta_2\varepsilon_{t-2}+\dots,
\end{equation}
где $\Theta_j=\Phi_j\mathsf A^{-1}$ ($j=0,1,2,\dots$), а матрица $\mathsf A$ не специфицируется конкретным образом (рассмотренная ранее рекурсивная идентификация выбирается только если существет некоторое теоретическое обоснование выбранного упорядочивания), а только должна обеспечивать диагональную ковариационную матрицу у $\varepsilon_t$. Теперь $\epsilon_t$ не обязательно должны иметь единичные дисперсии, в отличие от $w_t$ в \eqref{IR9}.

В рассматрвиаемой модели идентификационные ограничения накладываются на матрицу $\mathsf A$, так чтобы $\varepsilon_t=\mathsf A u_t$ имел диагональную ковариационную матрицу. Эта модель в дальнейшем будем называть $\mathsf A$-моделью. Учитывая то, как мы ввели связанные ограничения, вполне вероятно предположить, что  $\mathsf A$ имеет единичную главную диагональ. В этом случае требуется $K(K-1)/2$ огарничений на внедиагональные элементы $\mathsf A$, чтобы гарантировать точноидентифицируемые шоки $\varepsilon_t$ и, следовательно, точноидентифицированные импульсные отклики.

Что касается ограничений на матрицу $\mathsf A$ понятно, что эти ограничения не могут быть произвольными. Записывая их в форме $C_{\mathsf A}\ve(\mathsf A)=c_{\mathsf A}$, где $C_{\mathsf A}$ -- selection matrix размерности $(\frac{1}{2}K(K+1)\times K^2)$, и $c_{\mathsf A}$ -- соответствующий фиксированный вектор размерности $(\frac{1}{2}K(K+1)\times1)$, ограничения должны быть такими, чтобы система уравнений
\begin{equation}\label{AM2}
\mathsf A^{-1}\Sigma_\varepsilon{\mathsf A^{-1}}'=\Sigma_u \quad \text{и}\quad C_{\mathsf A}\ve(\mathsf A)=c_{\mathsf A}
\end{equation}
имела единственное решение, по крайней мере локально. Ясно, что система является нелинейной по ${\mathsf A}$. Следовательно, мы можем только надеяться на локальную единственность, или идентификацию в целом. Необходимое и достаточное условие для \eqref{AM2}, чтобы эта система имела единственное решение и, таким образом, для локальной идентификации структурных параметров, заключается в следующем. Пусть $\Sigma_\varepsilon$ является положительноопределенной диагональной матрицей размерности $(K\times K)$, и пусть $\mathsf A$ является невырожденной матрицей размерности $(K\times K)$. Тогда для заданной симмутричной положительноопределенной $(K\times K)$-матрицы $\Sigma_u$, $(N\times K^2)$-матрицы $C_{\mathsf A}$ и фиксированного $(N\times 1)$-вектора  $c_{\mathsf A}$ система уравнение в \eqref{AM2} имеет локально единственное решение для $\mathsf A$ и диагональных элементов $\Sigma_\varepsilon$, тогда и только тогда, когда
\[\mathrm{rk}
\begin{bmatrix}
-2\vc{D}_K^+(\Sigma_u\otimes\mathsf A^{-1}) & \vc{D}_K^+(\mathsf A^{-1}\otimes\mathsf A^{-1})\vc{D}_K\\
C_{\mathsf A} & 0\\
0 & C_{\sigma}
\end{bmatrix}
=K^2+\frac{1}{2}K(K+1).\]
Здесь $\vc{D}_K$ -- дуплицирующая матрица размерности $(K^2\times \frac{1}{2}K(K+1))$, $\vc{D}_K^+=(\vc{D}'_K\vc{D}_K)^{-1}\vc{D}'_K$, $C_\sigma$ -- selection matrix размерности $(\frac{1}{2}K(K-1)\times \frac{1}{2}K(K+1))$, которая выбирает элементы $\vech(\Sigma_\varepsilon)$ ниже главной диагонали. Глобально единственное решение получается, если диагональные элементы в $\mathsf A$ ограничены, чтобы равняться 1.

Для практических целей является проблематичным, что это условие идентификации включает неизвестные параметры. Следовательно, строго говоря, это можно только проверить, когда истинные параметры известны. На практике неизвестные значения могут быть заменены на оценки, и улсовие можно проверить, используя оцененные матрицы, поскольку можно показать, что ранг соответствующей матрицы является или меньше $K^2+\frac{1}{2}K(K+1)$ всюду в пространстве параметров, или ранговое условие выполняется почти всюду. В последнем случае это может потерпеть неудачу только на множестве нулевой меры Лебега. Таким образом, если рассматривается случайно извлеченный вектор из пространства параметров, он должен удовлетворяеть ранговому условию с вероятностью единица, если модель локлаьно идентифицируема. В любом случае, $C_{\mathsf A}$ должна иметь по крайней мере $K(K+1)/2$ строк, чтобы гарантировать идентификацию. Другими словами, наличие $K(K+1)/2$ ограничений являестя необходимым условием идентификации.

Хотя мы сформулировали ограничения на матрицу $\mathsf A$ в виде $C_{\mathsf A}\ve(\mathsf A)=c_{\mathsf A}$, можно записать их в виде
\[\ve(\mathsf A)=R_{\mathsf A}\gamma_{\mathsf A}+r_{\mathsf A},\]
где $R_{\mathsf A}$ и $r_{\mathsf A}$ -- соответствующая фиксированная матрица и соответствующий вектор, соответственно, а $\gamma_{\mathsf A}$ -- вектор неограниченных параметров.

Как правило, в анализе импульсных откликов смещается акцен от спецификации соотношений между наблюдаемыми переменными на интерпретацию неожидаемой части их изменений или шоков. Следовательно, это не редкость, чтобы идентифицировать структурные инновации $\varepsilon_t$ непосредственно из ошибок прогноза или остатков $u_t$ в приведенной форме. Один из способов сделать это -- думать об ошибках прогноза как о линейных функциях структурных инноваций. В этом случае у нас есть соотношения $u_t=\mathsf B\varepsilon_t$. Следовательно, $\Sigma_u=\mathsf B\Sigma_\varepsilon\mathsf B'$. Нормализуя дисперсии структурных инноваций на единицу, то есть предполагая $\varepsilon_t\sim(0,I_K)$, мы получаем
\begin{equation}\label{AM3}
\Sigma_u=\mathsf B\mathsf B'.
\end{equation}
Из-за симметричности ковариационной матрицы нам снова необходимо $K(K-1)/2$ дополнительных ограничений для идентификации всех $K^2$ элементов в $\mathsf B$.

Текущая модель с 
\[u_t=\mathsf B\varepsilon_t\]
и $\varepsilon\sim(0,I_K)$ будем называть $\mathsf B$-моделью. Если существуют только нулевые ограничения, они могут быть записаны в виде
\begin{equation}\label{AM4}
C_{\mathsf B}\ve{\mathsf B}=0,
\end{equation}
где $C_{\mathsf B}$ -- selection matrix размерности $(N\times K^2)$. Необходимое и достаточное ранговое условие для локальной идентификации модели заключается в следующем. Пусть $\mathsf B$ является невырожденной $(K\times K)$-матрицей. Тогда для заданной симметричной положительно определенной $(K\times K)$-матрицы $\Sigma_u$ и $(N\times K^2)$-матрицы $C_{\mathsf B}$ система уравнений в \eqref{AM3} и \eqref{AM4} имеет локально единственное решение, тогда и только тогда, когда
\[\mathrm{rk}
\begin{bmatrix}
2\vc{D}_K^+(\mathsf B\otimes I_K)\\
C_{\mathsf B}
\end{bmatrix}
=K^2.\]

Необходимым условием для того, чтобы $((\frac{1}{2}K(K+1)+N)\times K^2)$-матрицы
\[\begin{bmatrix}
2\vc{D}_K^+(\mathsf B\otimes I_K)\\
C_{\mathsf B}
\end{bmatrix}\]
имела ранг, равный $K^2$, является $N=\frac{1}{2}K(K-1)$. Другими словами, нам нужно $\frac{1}{2}K(K-1)$ ограничений для идентификации, как упомянуто ранее.

Легко видеть, что решение системы \eqref{AM3}/\eqref{AM4} не является глобально единственным, поскольку для любой матрицы $\mathsf B$, удовлетворяющей уранвениям, $-\mathsf B$ будет также являться решением. Этот результат выполняется из-за того факта, что $\mathsf B$ входит в уравнения \eqref{AM3}, будучи возведенной в квадрат. Фактически для любого решения $\mathsf B$ матрица $\mathsf B\Lambda$ будет также являться решением для любой диагональной матрицы $\Lambda$, у которой только элементы 1 и -1 на главной лиагонали. Очевидно, что если $\mathsf B$ такова, что \eqref{AM3} и \eqref{AM4} выполняются, $\Sigma_u=\mathsf B\Lambda\Lambda'\mathsf B'$ также выполняется, поскольку $\Lambda\Lambda'=I_K$. Кроме того,
\[C_{\mathsf B}\ve(\mathsf B\Lambda)=C_{\mathsf B}(\Lambda\otimes I_K)\ve(\mathsf B)=0,\]
поскольку для каждого элемента $\mathsf b_{ij}=0$ мы имеем $-\mathsf b_{ij}=0$. Таким образом, каждый столбец в $\mathsf B$ можно заменить на столбец с противоположным знаком. Следовательно, ограничение в \eqref{AM4} идентифицирует $\mathsf B$ только локально в общем случае. Единственность может быть потенциально получена, фиксируя знаки диагональных элементов, однако. Знаки диагональных элементов в $\mathsf B$ определяют знаки шоков. Таким образом, если мы хотим изучить влияние положительного шока на определенную величину, в то время как соответствующий диагональный элемент в $\mathsf B$ отрицательный, мы можем просто поменять знаки всех элементов в соответствующем столбце в $\mathsf B$, или, другими словами, мы можем просто поменять  знаки всех текущих откликов на соответтствующий шок, чтобы найти желаемый результат.

Также стоит отметить, что ограничения могут быть выражены в альтернативном виде:
\begin{equation}\label{AM4.1}
\ve(\mathsf B)=R_{\mathsf B}\gamma_{\mathsf B},
\end{equation}
где $\gamma_{\mathsf B}$ содержит все неограниченные коэффициенты в $\mathsf B$, а $R_{\mathsf B}$ является фиксированной матрицей из нулей и единиц.

Также возможно рассмотреть оба типа ограничений одновременно. То есть мы можем рассмотреть так называемую $\mathsf{AB}$-модель:
\begin{equation}\label{AM5}
\mathsf Au_t=\mathsf B\varepsilon_t,\quad \varepsilon_t\sim(0,I_K).
\end{equation}
В этом случае одновременные уравнения системы формулируются для ошибок в модели приведенной формы, а не для наблюдаемых переменных непосредственно. Тем самым модель составляет переход от спецификации прямых соотнощений для наблюдаемых переменных к формулированию соотношений для инноваций.

В этой модели мы получаем из \eqref{AM5}, что $u_t=\mathsf A^{-1}\mathsf B \varepsilon_t$, и, следовательно, $\Sigma_u=\mathsf A^{-1}\mathsf B\mathsf B'{\mathsf A^{-1}}'$. Таким образом, у нас есть $K(K+1)/2$ уравнений вида
\begin{equation}\label{AM6}
\vech(\Sigma_u)=\vech(\mathsf A^{-1}\mathsf B\mathsf B'{\mathsf A^{-1}}'),
\end{equation}
в то время как две матрицы $\mathsf A$ и $\mathsf B$ имеют $K^2$ элементов каждая Таким образом, нам нужно дополнительно $2K^2-\frac{1}{2}K(K+1)$ ограничений для идентификации всех $2K^2$ элементов в $\mathsf A$ и $\mathsf B$ по крайней мере локально. Даже если диагональные элементы в $\mathsf A$ полагаются равными единице, для идентификации нужно $2K^2-K-\frac{1}{2}K(K+1)$ дополнительных ограничений. Следовательно, пожалуй, неудивительно, что большинство приложений рассматривает частные случаи с $\mathsf A=I_K$ ($\mathsf B$-модель) или $\mathsf B=I_K$ ($\mathsf A$-модель). Тем не менее, общая модель является полезной основой для анализа SVAR. Ограничения, как правило, являются нормализацией или нулевыми ограничениями, которые могут быть записаны в виде линейных уравнений вида
\begin{equation}\label{AM7}
\ve(\mathsf A)=R_{\mathsf A}\gamma_{\mathsf A}+r_{\mathsf A},\quad\text{и}\quad\ve(\mathsf B)=R_{\mathsf B}\gamma_{\mathsf B}+r_{\mathsf B},
\end{equation}
где $R_{\mathsf A}$ и $R_{\mathsf B}$ -- соответствующие фиксированные матрицы, состоящие из нулей и единиц, $\gamma_{\mathsf A}$ и $\gamma_{\mathsf B}$ -- векторы свободных параметров, $r_{\mathsf A}$ и $r_{\mathsf B}$ -- векторы фиксированных параметров, которые допускают, например, нормализацию диагональных элементов в $\mathsf A$. Хотя $r_{\mathsf B}$ обычно равен нулю, как в \eqref{AM4.1}, мы представляем ограничения на $\mathsf B$ с общим вектором $r_{\mathsf B}$, поскольку эта дополниетльная компонента не будет усложнять анализ.

Умножая два набора уранвений в \eqref{AM7} на ортогональные дополнения $R_{\mathsf A}$ и $R_{\mathsf B}$, $R_{\mathsf A\perp}$ и $R_{\mathsf B\perp}$, соответственно, легко видеть,ч то их можно записать в виде
\begin{equation}\label{AM8}
C_{\mathsf A}\ve(\mathsf A)=c_{\mathsf A}\quad\text{и}\quad\quad C_{\mathsf B}\ve(\mathsf B)=c_{\mathsf B},
\end{equation}
где $C_{\mathsf A}=R_{\mathsf A\perp}$, $C_{\mathsf B}=R_{\mathsf B\perp}$, $c_{\mathsf A}=R_{\mathsf A\perp}r_{\mathsf A}$ и $c_{\mathsf B}=R_{\mathsf B\perp}r_{\mathsf B}$. О матрицах $C_{\mathsf A}$ и $C_{\mathsf B}$ можно думать как о соответствующих selection matrices. Снова в общем случае ограничения будут гарантировать только локальную единственность для $\mathsf A$ и $\mathsf B$ из-за нелинейной природы полного множества уравнений. Ранговое условие для локлаьной идентификации заключается в следующем. Пусть $\mathsf A$ и $\mathsf B$ -- невырожденные $(K\times K)$-матрицы. Тогда для заданной симметричной положительно определенной $(K\times K)$-матрицы $\Sigma_u$ система уранвений \eqref{AM6} и \eqref{AM8} имеют локально единственное решение тогда и только тогда, когда
\[\mathrm{rk}
\begin{bmatrix}
-2\vc{D}_K^+(\Sigma_u\otimes\mathsf A^{-1}) & 2\vc{D}_K^+(\mathsf A^{-1}\mathsf B\otimes\mathsf A^{-1})\\
C_{\mathsf A} & 0\\
0 & C_{\mathsf B}
\end{bmatrix}
=2K^2.\]

\subsubsection{Идентификация Бланшара-Кваха}

Ясно, что не всегда легко найти подходящие и в целом приемлемые ограничения на матрицы $\mathsf A$ и $\mathsf B$. Накладывание ограничений непосредственно на эти матрицы фактически не является необходимым для идентификации структурных инноваций и импульсных откликов. Другой тип ограничений обсуждался в \citep{BlanchardQuah1989}. Авторы рассмотрели накопленные эффекты шоков на систему. В терминах структурных импульсных откликов \eqref{AM1} они сконцентрировали внимание на \textit{полной матрицы вклада} (total impact matrix):
\begin{equation}\label{AM9}
\Xi_\infty=\sum_{i=0}^\infty{\Theta_i}=(I_K-A_1-\dots-A_p)^{-1}\mathsf A^{-1}\mathsf B,
\end{equation}
и они идентифицировали структурные инновации, полагая нулевые ограничения на эту матрицу. Другими словами, они предполагали, что некоторые шоки не имеют полный долгосрочный эффект. 

\subsection{Декомпозиция дисперсий ошибок прогноза}

Если инновации, которые фактически приводят в движение систему могут быть идентифицированы, доступен дальнейший способ интерпретации VAr-модели. Предположим, что доступна рекурсивная идентификационная схема, так что может быть рассмотрено MA-представление с ортогонализованными инновациями белого шума. В контексте представления
\begin{equation}\label{IR13}
y_t=\mu+\sum_{i=0}^\infty{\Theta_i}w_{t-i},
\end{equation}
с $\Sigma_w=I_K$ ошибка оптимального прогноза на $h$ шагов равна
\begin{eqnarray}
y_{t+h}-y_t(h) &=& \sum_{i=0}^{h-1}{\Phi_iu_{t+h-i}}=\sum_{i=0}^{h-1}{\Phi_iPP^{-1}u_{t+h-i}}\notag \\
&=& \sum_{i=0}^{h-1}{\Theta_iw_{t+h-i}}.\label{IR14}
\end{eqnarray}
Обозначая $mn$-ый эелемент в $\Theta_i$ как $\theta_{mn,i}$, ошибка прогноза на $h$ шагов $j$-ой компоненты $y_t$ равна
\begin{eqnarray}
y_{j,t+h}-y_{j,t}(h) &=& \sum_{i=0}^{h-1}{(\theta_{j1,i}w_{1,t+h-i}+\dots+\theta_{jK,i}w_{K,t+h-i})}\notag \\
&=& \sum_{k=1}^{K}{(\theta_{jk,0}w_{k,t+h}+\dots+\theta_{jk,h-1}w_{k,t+1})}.\label{IR15}
\end{eqnarray}
Таким образом, ошибка прогноза $j$-ой компоненты потенциально состоит из всех инноваций $w_{1t},\dots,w_{Kt}$. Конечно, некоторые из $\theta_{mn,i}$ могут быть нулевыми, так что некоторые компоненты могут не появляться в \eqref{IR15}. Поскольку $w_{k,t}$ некоррелированы и имеют единичные дисперсии, MSE от $y_{j,t}(h)$ равна
\[E(y_{j,t+h}-y_{j,t}(h))^2=\sum_{k=1}^K{(\theta^2_{jk,0}+\dots+\theta^2_{jk,h-1})}.\]
Следовательно,
\begin{equation}\label{IR16}
\theta_{jk,0}^2+\theta_{jk,1}^2+\dots+\theta_{jk,h-1}^2=\sum_{i=1}^{h-1}{(e'_j\Theta_ie_k)^2}
\end{equation}
иногда интерпретируется как вклад инноваций в переменной $k$ на ошибку прогноза дисперсии, или MSE прогноза на $h$ шагов переменной $j$. Здесь $e_k$ -- $k$-ый столбец матрциы $I_K$. Деление \eqref{IR16} на
\[\mathrm{MSE}[y_{j,t}(h)]=\sum_{i=0}^{h-1}\sum_{k=1}^K\theta^2_{jk,i}\]
дает
\begin{equation}\label{IR17}
\omega_{jk,h}=\sum_{i=0}^{h-1}(e'_j\Theta_ie_k)^2/\mathrm{MSE}[y_{j,t}(h)],
\end{equation}
что является пропорцией ошибки дисперсии прогноза переменной $j$ на $h$ шагов, которая приходится на долю инноваций $w_{kt}$. Если $w_{kt}$ может быть связано с переменной $k$, $\omega_{jk,h}$ представляет пропорцию ошибки дисперсии прогноза переменной $j$ на $h$ шагов, которая приходится на долю инноваций в переменной $k$. Тем самым дисперсия ошибки прогноза раскладывается на компоненты, которые приходились на инновации в различных переменных системы. Из \eqref{IR14} видно, что матрица MSE прогноза на $h$ шагов будет
\[\Sigma_y(h)=\mathrm{MSE}[y_{t}(h)]=\sum_{i=0}^{h-1}{\Theta_i\Theta'_i}=\sum_{i=0}^{h-1}{\Phi_i\Sigma_u\Phi'_i}.\]
Диагональные элементы этой матрицы являются MSE от переменных $y_{jt}$, которые могут быть использованы в \eqref{IR17}. Анализ декомпозиции дисперсий иногда называется \textit{учетом инноваций} (innovation accounting).

% ссылки на G-causes

Для стационарного, стабильного, $K$-мерного VAR($p$)-процесса $y_t$ все пропорции дисперсии ошибки прогноза переменной $j$, которые приходятся на инновации в переменной $k$, будут равны нулю, если $\omega_{jk,h}=0$ для $h=pK-p+1$. В этом контексте стоит отметить соотношение между причинностью по Гренджеру и компонентами дисперсии ошибок прогноза. Для этой цели мы рассмотрим сначала двумерную систему $y_t=(z_t,x_t)'$. В такой системе, если $z_t$ не являестя причинной по Гренджеру для $x_t$, пропорции дисперсий ошиок прогноза $x_t$, которые приходятся на инновации в $z_t$, могут все еще быть ненулевыми. Это свойство прямо следует из определения $\Theta_i$. Непричинность по Гренджеру предполагае нулвые огарничения на $\Phi_i$, что может исчезать в $\Theta_i$, елси ковариационная матрица $\Sigma_u$ не являестя диагональной. Другими словами, если $\Sigma_u$ диагональная, так что нет текущей причинности между $z_t$ и $x_t$, и если в дополнение $z_t$ не является причинной по Гренджеру для $x_t$, нижний левый элемент в $\Theta_i$ будет нулевым. Следовательно, пропорция дисперсии ошибок прогноза $x_t$, которая приходится на инновации $z_t$, будет также нулевой.

В системах более высокого порядка предположим, что набор переменных $z_t$ не являестя причиной по Гренджеру для оставшихся переменных $x_t$, и не существует текущей причинности между двумя наборами переменных. В этом случае пропорции прогноза MSE всех переменных $x_t$, которые приходятся на переменных $z_t$, будут нулевыми.

Важно понимать, однако, что причинность по Гренджеру и разложение дисперсии ошибок прогноза являются достаточно различными понятиями, поскольку являюстя различными поянтиями причинность по Гренджеру и текущая причинность. В то время как причинность по Гренджеру --  единственно определяемое свойство двух подмножеств переменных в заданном процессе, декомпозиция дисперсии ошибок прогноза не являесят единственной, так как зависит от матриц $\theta_i$, и, таким образом, от выбора преобразующей матрицы $P$. Следовательно, интерпретация разложения дисперсии ошибок прогноза подвержена влиянию аналогичных критических замечаний, как и интерпретации импульсных откликов. В дополнение применимы все критические вопросы, поднятые в контексте причинности по Гренжеру. То есть компоненты дисперсии ошибок прогноза являюстя условными по отношению к рассматриваемой системе. Они могут измениться, если система будет расширена дополнительными переменными или если переменные будут удалены из системы. Также ошибки измерения, сезонная коррекция и использование агрегирования могут загрязнить декомпозиции дисперсий ошибок прогноза.

\subsection{Оценивание SVAR-модели}

Предположим, что мы хотим оценить следующую SVAR-модель:
\begin{equation}\label{est1}
\mathsf Ay_t=\mathsf A A Y_{t-1}+\mathsf B\varepsilon_t,
\end{equation}
где $y'_{t-1}=[y'_{t-1},\dots,y'_{t-p}]$, $A=[A_1,\dot,A_p]$ и $\epsilon_t$ -- гауссовский белый шум с ковариационной матрицей $I_K$, $\varepsilon_t\sim N(0,I_K)$. Предположение о нормальности сделано только для удобства получения оценок. асимптотические свойства оценок будут теми же самыми при более общих предположениях о распределении. Остатки в приведенной форме, соответствующие \eqref{est1}, будут иметь вид $u_t=\mathsf A^{-1}\mathsf B\varepsilon$.

Функция логарифмического правдоподобия для выборки $y_1,\dots,y_T$ равна
\begin{eqnarray}
\ln l(A,\mathsf A,\mathsf B) &=& -\frac{KT}{2}\ln 2\pi-\frac{T}{2}\ln |\mathsf A^{-1}\mathsf B\mathsf B'{\mathsf A'}^{-1}|\notag\\
&& -\frac{1}{2}\mathrm{tr} \{(Y-AX)'[\mathsf A^{-1}\mathsf B\mathsf B'{\mathsf A'}^{-1}](Y-AX)\}\notag\\
&=&\mathrm{constant}+\frac{T}{2}\ln |\mathsf A|^2-\frac{T}{2}\ln |\mathsf B|^2\notag\\
&&\frac{1}{2}\mathrm{tr}\{\mathsf A'{\mathsf B'}^{-1}\mathsf B^{-1}\mathsf A(Y-AX)(Y-AX)'\},\label{est2}
\end{eqnarray}
где, как обычно, $Y=[y_1,\dots,y_T]$, $X=[Y_0,\dots,Y_{T-1}]$, и используются матричные правила $|\mathsf A^{-1}\mathsf B\mathsf B'{\mathsf A'}^{-1}|=|\mathsf A^{-1}|^2|\mathsf B|^2=|\mathsf A'|^{-2}|\mathsf B|^2$ и $\mathrm{tr}(VW)=\mathrm{tr}(WV)$.

Предположим, что нет ограничений на параметры приведенной формы $A$. Тогда для любых заданных $\mathsf A$ и $\mathsf B$ функция логарифмического правдоподобия $\ln l(A,\mathsf A,\mathsf B)$ максимизируется по $A$ как $\hat{A}=YX'(X'X)^{-1}$. таким образом, заменяя $A$ на $\hat{A}$ в \eqref{est2}, мы получаем концентрированную функцию логарифмического правдоподобия
\begin{equation}\label{est3}
\ln l_c(\mathsf A,\mathsf B)=\mathrm{constant}+\frac{T}{2}\ln |\mathsf A|^2-\frac{T}{2}\ln |\mathsf B|^2- \frac{1}{2}\mathrm{tr}(\mathsf A'{\mathsf B'}^{-1}\mathsf B^{-1}\mathsf A\tilde{\Sigma}_u),
\end{equation}
где $\tilde{\Sigma}_u=T^{-1}(Y-\hat{A}X)(Y-\hat{A}X)'$ -- оцененная ковариационная матрица VAR-остатков (см. \citep{Breitung2001}). 

Максимизация функции \eqref{est2} по $\mathsf A$ и $\mathsf B$ относительно структурных ограничений \eqref{AM7} или \eqref{AM8} должна быть сделана при помощи численных методов, поскольку аналитическое решение обычно недоступно. Если ограничения задаются в виде \eqref{AM7}, ограниченная максимизации концентрированной логарифмической функции правдоподобия достигается максимизацией относительно $\gamma_{\mathsf A}$ и $\gamma_{\mathsf B}$. 

Если эти параметры локально идентифицируемы, ML-оценки имеют стандартные асимптотические свойства:
\[\sqrt{T}\left(
\begin{bmatrix}
\tilde{\gamma}_{\mathsf A}\\
\tilde{\gamma}_{\mathsf B}
\end{bmatrix}-
\begin{bmatrix}
\gamma_{\mathsf A}\\
\gamma_{\mathsf B}
\end{bmatrix}
\right)\stackrel{d}{\longrightarrow}
\left(
0,\mathcal{I}_\alpha
\begin{pmatrix}
\gamma_{\mathsf A}\\
\gamma_{\mathsf B}
\end{pmatrix}^{-1}
\right),
\]
где $\mathcal{I}_\alpha(\cdot)$ -- асимпттическая информационная матрица. Она имеет вид
\[\mathcal{I}_\alpha
\begin{pmatrix}
\gamma_{\mathsf A}\\
\gamma_{\mathsf B}
\end{pmatrix}
=
\begin{bmatrix}
R'_{\mathsf A} & 0\\
0 & R'_{\mathsf B}
\end{bmatrix}
\mathcal{I}_\alpha
\begin{pmatrix}
\ve{\mathsf A}\\
\ve{\mathsf B}
\end{pmatrix}
\begin{bmatrix}
R_{\mathsf A} & 0\\
0 & R_{\mathsf B}
\end{bmatrix}
\]
и
\begin{equation}\label{est4}
\mathcal{I}_\alpha
\begin{pmatrix}
\ve{\mathsf A}\\
\ve{\mathsf B}
\end{pmatrix}=
\begin{bmatrix}
\mathsf A^{-1}\mathsf B\otimes {\mathsf B'}^{-1} \\
-(I_K\otimes {\mathsf B'}^{-1}) 
\end{bmatrix}(I_{K^2}+\vc{K}_{KK})\bigl[(\mathsf B'{\mathsf A'}^{-1}\otimes \mathsf B^{-1}) \ : \ -(I_K\otimes {\mathsf B'}^{-1})  \bigr]
\end{equation}

Если $\gamma_{\mathsf A}$ и $\gamma_{\mathsf B}$ идентифицируемы, то же самое верно и для $\mathsf A$ и $\mathsf B$. Оценивание этих матриц таково, что $\ve(\tilde{\mathsf A})=R_{\mathsf A}\tilde{\gamma}_{\mathsf A}+r_{\mathsf A}$ и $\ve(\tilde{\mathsf B})=R_{\mathsf B}\tilde{\gamma}_{\mathsf B}+r_{\mathsf B}$, соответственно, мы получаем следующее следствие:
\[\sqrt{T}\left(
\begin{bmatrix}
\ve\tilde{\mathsf A}\\
\ve\tilde{\mathsf B}
\end{bmatrix}-
\begin{bmatrix}
\ve{\mathsf A}\\
\ve{\mathsf B}
\end{bmatrix}
\right)\stackrel{d}{\longrightarrow}N(0,\Sigma_{\mathsf A\mathsf B}),\]
где
\[\Sigma_{\mathsf A\mathsf B}=
\begin{bmatrix}
R_{\mathsf A} & 0\\
0 & R_{\mathsf B}
\end{bmatrix}
\mathcal{I}_\alpha
\begin{pmatrix}
\gamma_{\mathsf A}\\
\gamma_{\mathsf B}
\end{pmatrix}^{-1}
\begin{bmatrix}
R'_{\mathsf A} & 0\\
0 & R'_{\mathsf B}
\end{bmatrix}.
\]

Если накладываются только точноидетифицируемые огарничения на структурные параметры, у нас есть ML-оценка для $\Sigma_u$,
\[\tilde{\Sigma}_u=T^{-1}(Y-\hat{A}X)(Y-\hat{A}X)'=\tilde{\mathsf A}^{-1}\tilde{\mathsf B}\tilde{\mathsf B'}\tilde{\mathsf A'}^{-1}.\]
Если, однако, на $\mathsf A$ и/или $\mathsf B$ накладываются сверхидентифицирующие ограничения, соответствующая оценка для $\Sigma_u$, 
\begin{equation}\label{est5}
\tilde{\Sigma}_u^r=\tilde{\mathsf A}^{-1}\tilde{\mathsf B}\tilde{\mathsf B'}\tilde{\mathsf A'}^{-1},
\end{equation}
будет отличаться от $\tilde{\Sigma}_u$. Фактически LR-статистику,
\begin{equation}\label{est6}
\lambda_{LR}=T(\ln|\tilde{\Sigma}_u^r|-\ln|\tilde{\Sigma}_u|),
\end{equation}
можно использовать для проверки сверхидентифицирующих огарничений. при нулевой гипотезе, что ограничения верны, эта статистика имеет асимптотическое распределение $\chi^2$ с числом степеней свободы, равной числу сверхидентифицирующих ограничений. Другими словами, число степеней свободы равно числу независимых ограничений, накладываемых на $\mathsf A$ и $\mathsf B$ минус $2K^2-\frac{1}{2}K(K+1)$.

Рассмотрим теперь максимизацию функции \eqref{est2}. В \citep{AmisanoGianini1997} предлагается использовать скоринговый алгоритм, где $i$-ая итерация имеет вид
\begin{equation}\label{est7}
\begin{bmatrix}
\tilde{\gamma}_{\mathsf A}\\
\tilde{\gamma}_{\mathsf B}
\end{bmatrix}_{i+1}=
\begin{bmatrix}
\tilde{\gamma}_{\mathsf A}\\
\tilde{\gamma}_{\mathsf B}
\end{bmatrix}_i+
l\mathcal I\left(
\begin{bmatrix}
\tilde{\gamma}_{\mathsf A}\\
\tilde{\gamma}_{\mathsf B}
\end{bmatrix}_i
\right)^{-1}\vc{s}\left(
\begin{bmatrix}
\tilde{\gamma}_{\mathsf A}\\
\tilde{\gamma}_{\mathsf B}
\end{bmatrix}_i\right),
\end{equation}
где $\mathcal I(\cdot)$ обозначает информационную матрицу свободных параметров $\gamma_{\mathsf A}$ и $\gamma_{\mathsf B}$, то есть в этом случае $\mathcal I(\cdot)=T\mathcal I_\alpha(\cdot)$, $\vc{s}(\cdot)$ -- вектор вклада (score vector), $l$ -- длина шага.

Вектор вклада может быть получен, исопльзуя правила матричного и векторного дифференцирования. Прменяя цепное парвило для векторного дифференцирования, получим
\begin{equation}\label{est8}
\vc{s}\begin{pmatrix}
\gamma_{\mathsf A}\\
\gamma_{\mathsf B}
\end{pmatrix}=\frac{\partial \ln l}{\partial (\gamma'_{\mathsf A},\gamma'_{\mathsf B})'}=
\begin{bmatrix}
R'_{\mathsf A} & 0\\
0 & R'_{\mathsf B}
\end{bmatrix}
\vc{s}\begin{pmatrix}
\ve{\mathsf A}\\
\ve{\mathsf B}
\end{pmatrix},
\end{equation}
и
\[\vc{s}\begin{pmatrix}
\ve{\mathsf A}\\
\ve{\mathsf B}
\end{pmatrix}=
\frac{\partial \ln l}{\partial \begin{pmatrix}
\ve{\mathsf A}\\
\ve{\mathsf B}
\end{pmatrix}}=
\begin{bmatrix}
(I_K\otimes{\mathsf B'}^{-1})\\
-(\mathsf B^{-1}\mathsf A\otimes {\mathsf B'}^{-1})
\end{bmatrix}\vc{s}(\ve[\mathsf B^{-1}\mathsf A])
\]
с
\[\vc{s}(\ve[\mathsf B^{-1}\mathsf A])=T\ve({[\mathsf B^{-1}\mathsf A]'}^{-1})-T(\tilde{\Sigma}_u\otimes I_K)\ve(\mathsf B^{-1}\mathsf A).\]
На практике скоринговый алгоритм останавливается, если предварительно специфицированные критерии сходимости, такие как относительные изменения логарифмического правдоподобия и параметров, выполняются. Чтобы этот алгоритм работал, обращение информационной матрицы должно существовать, что гарантируется идентификацией параметров, по крайней мере в окрестности их истинных значений. В \citep{Giannini1992} используется это свойство для получения альтернативных условий дял идентификации модели. Более точно, автор получил идентификационные условия из огоф акта, что, например, $\mathsf{AB}$-модель локально идентифицируема тога и только тогда, когда матрица
\begin{equation}\label{est9}
\begin{bmatrix}
\mathcal I_\alpha\begin{pmatrix}
\ve{\mathsf A}\\
\ve{\mathsf B}
\end{pmatrix}\\
\begin{bmatrix}
C_{\mathsf A} & 0\\
0 & C_{\mathsf B}
\end{bmatrix}
\end{bmatrix}
\end{equation}
имеет полный ранг по столбцам, когда $\mathcal I_\alpha(\cdot)$ оценена в истинных значениях параметров.

Данный подход легко обобщить на случай наличия детерминированных компонент. Кроме того, та же самая концентрированная функция правдоподобия получается, если есть ограничения на $A$. В этом случае теоретически мы можем просто заменить $\tilde{\Sigma}_u$ на ковариационную матрицу остатков ограниченной ML-оценки приведенной формы. Для практических целей, однако, точная ML-оценка обычно не используется, поскольку в общем случае ее вычисление требует методов нелинейной оптимизации. Вместо этого может быть использован доступный GLS, чьи асимптотические свойства совпадают с ML. В этом случае \eqref{est3} не строго концентрированная функция логарифмического правдоподобия, но для простоты мы будем ссылаться на нее как на концентрированную функцию логарифмического правдоподобия.

Рассмотрим теперь оценвиание долгосрочных ограничений типа Бланшара-Кваха. Если матрциа полного вклада $\Xi_\infty$ ограничена треугольной формой как в \citep{BlanchardQuah1989} и \citep{Gali1999}, оценивание становится особенно легким. Специфицируя $\mathsf A=I_K$, используя соотношение $\Xi_\infty=(I_K-A_1-\dots-A_p)^{-1}\mathsf B$ и замечая, что
\[\Xi_\infty\Xi'_\infty=(I_K-A_1-\dots-A_p)^{-1}\Sigma_u(I_K-A'_1-\dots-A'_p)^{-1},\]
матрица $\mathsf B$ может быть вычислена умножением разложения Холецкого для матрицы
\[(I_K-\hat{A}_1-\dots-\hat{A}_p)^{-1}\tilde{\Sigma}_u(I_K-\hat{A}'_1-\dots-\hat{A}'_p)^{-1}\]
на $(I_K-\hat{A}_1-\dots-\hat{A}_p)$.

Последняя процедура работает только если оператор VAR являестя стабильным, и процесс является стационарным, поскольку для интегрированных процессов не существует обращения $(I_K-\hat{A}_1-\dots-\hat{A}_p)$. С другой стороны, коинтегрированные переменные не создают проблемы для других методов оценивания SVAR-моделей.

\subsection{Асимптотические распределения импульсных откликов и декомпозиции дисперсий ошибок прогноза}

В данном подразделе приводятся асимптотические распределения оценок $\Phi_i$ и $\Theta_i$ в \eqref{IR7} и \eqref{IR9}, предполагая их неизвестными и вычисленными посредством коэффициентов VAR и ковариационной матрицы ошибок. заметим, что нам не нужно существование MA-представления. Мы только предполагаем, что $\Phi_i$ получены из заданных коэффициентов $A_1,\dots,A_p$ по рекурсивной формуле $\Phi_i=\sum_{j=1}^i{\Phi_{i-j}A_j}$, $i=1,2,\dots$, начиная с $\Phi_0=I_k$ и полагая $A_j=0$ для $j>p$. Кроме того, $\Theta_i$ получены из $A_1,\dots,A_p$ и $\Sigma_u$ как $\Theta_i=\Phi_iP$, где выражение для $P$ зависит от метода идентификации (либо $P=\mathsf A^{-1}$, либо $P=\mathsf B$, либо $P=\mathsf A^{-1}\mathsf B$). В дополнение даются распределения накопленных импульсных откликов
\begin{eqnarray*}
\Psi_n&=&\sum_{i=0}^n{\Phi_i}, \quad \Psi_\infty=\sum_{i=0}^\infty{\Phi_i}=(I_K-A_1-\dots-A_p)^{-1}, \ \text{если существует},\\
\Xi_n&=&\sum_{i=0}^n{\Theta_i}, \quad \Xi_\infty=\sum_{i=0}^\infty{\Theta_i}=(I_K-A_1-\dots-A_p)^{-1}P, \ \text{если существует}\\
\end{eqnarray*}
и компонент дисперсии ошиок прогноза
\begin{equation*}
\omega_{jk,h}=\sum_{i=0}^{h-1}(e'_j\Theta_ie_k)^2/\mathrm{MSE}_j(h).
\end{equation*}
Здесь $e_k$ -- $k$-ый столбец в $I_K$, и
\[\mathrm{MSE}_j(h)=\sum_{i=0}^{h-1}{e'_j\Phi_i\Sigma_u\Phi'_ie_j}\]
является $j$-ым диагональным элементом MSE-матрицы $\Sigma_y(h)$ прогноза на $h$ шагов.

При формальном написании асимптотических распределений, мы используем следующие обозначения:
\begin{eqnarray*}
\vc{\alpha}&=&\ve(A_1,\dots,A_p)\qquad\qquad\qquad \ (K^2p\times 1),\\
\vc{A}&=&
\begin{bmatrix}
A_1 & A_2 & \dots & A_{p-1} & A_p\\
I_K & 0 & \dots & 0 & 0\\
0 & I_K &  & 0 & 0\\
\vdots & & \ddots & \vdots & \vdots\\
0 & 0 & \dots & I_K & 0
\end{bmatrix}\quad (Kp\times Kp),\\
\vc{\sigma}&=&\vech(\Sigma_u) \qquad\qquad\qquad\qquad\quad \  (\frac{1}{2}K(K+1)\times 1),
\end{eqnarray*}
а соответствующие оценки обозначаются с символом крышки. Оператор $\ve$ является оператором векторизации, а $\vech$ -- оператор который собирает элементы ниже главной диагонали. Мы также используем коммутационную матрицу $\vc{K}_{mn}$, определенную таким образом, чтобы для любой $(m\times n)$ матрицы $G$ размерности $\vc{K}_{mn}\ve(G)=\ve(G')$, дуплицирующую матрицу $\vc{D}_m$ размерности $(m^2\times \frac{1}{2}m(m+1))$, определенную таким образом, чтобы $\vc{D}_{m}\vech(F)=\ve(F)$ для любой симметричной $(m\times m)$ матрицы $F$ и матрицу исключения $\vc{L}_m$ размерности $(\frac{1}{2}m(m+1)\times m^2)$, определенную таким образом, чтобы $\vech{F}=\vc{L}_m\ve(F)$ для любой $(m\times m)$ матрицы $F$. Кроме того, $J=[I_K \ : \ 0 \ : \ \cdots \ : \ 0]$ -- матрица размерности $(K\times Kp)$. С этими обозначениями в \citep{Lutkepohl1990} было установлено асимптотическое следующее поведение импульсных откликов.

Предположим, что
\begin{equation}\label{IR19}
\sqrt{T}
\begin{bmatrix}
\hat{\vc{\alpha}}-\vc{\alpha}\\
\hat{\vc{\sigma}}-\vc{\sigma}
\end{bmatrix}\stackrel{d}{\longrightarrow}
N\left(0,
\begin{bmatrix}
\Sigma_{\hat{\vc{\alpha}}} & 0\\
0 & \Sigma_{\hat{\vc{\sigma}}}
\end{bmatrix}
\right),
\end{equation}
где $\Sigma_{\hat{\vc{\alpha}}}=\Gamma_Y(0)^{-1}\otimes\Sigma_u$, $\Sigma_{\hat{\vc{\sigma}}}=2\vc{D}_K^+(\Sigma_u\otimes\Sigma_u){\vc{D}_K^{+}}'$, $\Gamma_Y(0)=E(Y_t^0{Y_t^{0}}')$, $Y_t^0=(y_t-\mu, \times, y_{t-p+1}-\mu)'$ -- матрица размерности $(Kp\times 1)$, $\vc{D}_K^+=(\vc{D}'_K\vc{D}_K)^{-1}\vc{D}'_K$ -- псевдообратная матрица Мура-Пенроуза от дуплицирующей матрицы $\vc{D}_K$.

Тогда
\begin{enumerate}
\item $\sqrt{T}\ve(\hat{\Phi}_i-\Phi_i)\stackrel{d}{\longrightarrow}N(0,G_i\Sigma_{\hat{\vc{\alpha}}}G'_i)$, $i=1,2,\dots,$
где
\[G_i=\frac{\partial\ve(\Phi_i)}{\partial\vc{\alpha}'}=\sum_{m=1}^{i-1}{J(\vc{A}')^{i-1-m} \otimes \Phi_m}.\]
\item $\sqrt{T}\ve(\hat{\Psi}_i-\Psi_i)\stackrel{d}{\longrightarrow}N(0,F_n\Sigma_{\hat{\vc{\alpha}}}F'_n)$, $i=1,2,\dots,$ где $F_n=G_1+\dots+G_n.$
\item Если $(I_K-A_1-\dots-A_p)$ невырождена, $\sqrt{T}\ve(\hat{\Psi}_\infty-\Psi_\infty)\stackrel{d}{\longrightarrow}N(0,F_\infty\Sigma_{\hat{\vc{\alpha}}}F'_\infty)$, где $F_\infty=\underbrace{(\Psi'_\infty,\dots,\Psi'_\infty)}_{\text{$p$ раз}}\otimes\Psi_\infty$.
\item $\sqrt{T}\ve(\hat{\Theta}_i-\Theta_i)\stackrel{d}{\longrightarrow}N(0,C_i\Sigma_{\hat{\vc{\alpha}}}C'_i+\bar{C}_i\Sigma_{\hat{\vc{\alpha}}}\bar{C}'_i)$, $i=0,1,2,\dots,$
где 
\[C_0=0, \ C_i=(P'\otimes I_K)G_i, \ i=1,2,\dots, \ \bar{C}_i=(I_K\otimes\Phi_i)H, \ i=0,1,\dots,\]
и
\begin{eqnarray*}
H &=&\frac{\partial\ve(P)}{\partial\vc{\sigma}'}=\vc{L}'_K\{\vc{L}_K[(I_K\otimes P)\vc{K}_{KK}+(P\otimes I_K)]\vc{L}'_K\}^{-1}\\
&=& \vc{L}'_K\{\vc{L}_K(I_{K^2}+\vc{K}_{KK})(P\otimes I_K)\vc{L}'_K\}^{-1}
\end{eqnarray*}
\item $\sqrt{T}\ve(\hat{\Xi}_n-\Xi_n)\stackrel{d}{\longrightarrow}N(0,B_n\Sigma_{\hat{\vc{\alpha}}}B'_n+\bar{B}_n\Sigma_{\hat{\vc{\sigma}}}\bar{B}'_n)$, где $B_n=(P'\otimes I_K)F_n$ и $\bar{B}_n=(I_K\otimes \Psi_n)H$.
\item Если $(I_K-A_1-\dots-A_p)$ невырождена, $\sqrt{T}\ve(\hat{\Xi}_\infty-\Xi_\infty)\stackrel{d}{\longrightarrow}N(0,B_\infty\Sigma_{\hat{\vc{\alpha}}}B'_\infty+\bar{B}_\infty\Sigma_{\hat{\vc{\sigma}}}\bar{B}'_\infty)$, где $B_\infty=(P'\otimes I_K)F_\infty$ и $\bar{B}_\infty=(I_K\otimes \Psi_\infty)H$.
\item $\sqrt{T}\ve(\hat{\omega}_{jk,h}-\omega_{jk,h})\stackrel{d}{\longrightarrow}N(0,d_{jk,h}\Sigma_{\hat{\vc{\alpha}}}d'_{jk,h}+\bar{d}_{jk,h}\Sigma_{\hat{\vc{\sigma}}}\bar{d}'_{jk,h})$, $j,k=1,\dots,K$, $h=1,2,\dots$, где
\begin{multline*}
d_{jk,h}=\frac{2}{\mathrm{MSE}_j(h)^2}\sum_{i=0}^{h-1}{\bigl[\mathrm{MSE}_j(h)(e'_j\Phi_iPe_k)(e'_kP'\otimes e'_j)G_i\bigr.}\\
\bigl. -(e'_j\Phi_iPe_k)^2\sum_{m=0}^{h-1}{e'_j\Phi_m\Sigma_u\otimes e'_j}G_m\bigr]
\end{multline*}
с $G_0=0$ и
\begin{multline*}
\bar{d}_{jk,h}=\sum_{i=0}^{h-1}{\bigl[2\mathrm{MSE}_j(h)(e'_j\Phi_iPe_k)(e'_k\otimes e'_j\Phi_i) \bigr.}\\
\bigl. -(e'_j\Phi_iPe_k)^2\sum_{m=0}^{h-1}{e'_j\Phi_m\otimes e'_j\Phi_m}\vc{D}_K\bigr]/\mathrm{MSE}_j(h)^2.
\end{multline*}
\end{enumerate}

Далее приводим несколько замечаний.

\noindent\textbf{Замечание 1.} Некоторые матрицы частных производных могут быть нулевыми. Например, если оценивается VAR(1)-модель, хотя истинный порядок нулевой (то есть $y_t$ -- белый шум), то
\[G_2=J\vc{A}'\otimes I_K+JI_K\otimes\Phi_1=0,\]
поскольку $\vc{A}=A_1=0$ и $\Phi_1=A_1=0$. Следовательно, для $\sqrt{T}(\hat{\Phi}_2-\Phi_2)$ получается вырожденное предельное распределение с нулевой ковариационной матрицей. Оценивание ковариационных матриц, полученных заменой неизвестных значений их обычными оценками, может быть проблематичным, когда асимптотическое распределение вырожденное. В этом случае обычные $t$-статистики и доверительные интервалы могут не быть подходящими и приводящими к неверным выводам.

\noindent\textbf{Замечание 2.} Процесс $y_t$ не обязательно должен быть стабильным для всех установленных результатов. Решающим улсовием является асимптотическое поведение параметров в \eqref{IR19}, однако асимптотическая нормальность также может быть получена для некоторых нестационарных и нестабильных процессов. Следовательно, некоторые части утверждения выше могут быть полезны и в нестационарном контексте.

\noindent\textbf{Замечание 3.} Блочно-диагональная структура ковариационной матрицы асимпотического распределения в \eqref{IR19} ни в коей мере не являесят необходимой для асимптотической нормальности импульсных откликов. Фактически асимптотические рапсределения в пунктах 1-3 остаются неизменными, даже если асимптотическая ковариационная матрица не является блочно-диагональной. С другой стороны, без блочно-диагональнйо структуры простая аддитивная структура асимптотических ковариационных матриц в пунктах 4-7 пропадает, хотя можно было бы обобщить эти результаты на случай общей асимптотической ковариационной матрицы в \eqref{IR19}.

\noindent\textbf{Замечание 4.} Зная выражения для $\Sigma_{\hat{\vc{\alpha}}}$ и $\Sigma_{\hat{\vc{\sigma}}}$ в \eqref{IR19}, можно получить некотоыре упрощения в ковариационных матрицах. Например, ковариационная матрица $G_i\Sigma_{\hat{\vc{\alpha}}}G'_i$ в пункте 1 становится равна
\begin{eqnarray*}
G_i\Sigma_{\hat{\vc{\alpha}}}G'_i&=&\\
&=& \left[\sum_{m=0}^{i-1}{J(\vc{A}')^{i-1-m}}\otimes \Phi_m \right] (\Gamma_Y(0)^{-1}\otimes\Sigma_u)\left[\sum_{n=0}^{i-1}{J(\vc{A}')^{i-1-n}}\otimes \Phi_n \right]'\\
&=& \sum_{m=0}^{i-1}\sum_{n=0}^{i-1}[J(\vc{A}')^{i-1-m}\Gamma_Y(0)^{-1}\vc{A}^{i-1-n}J']\otimes (\Phi_m\Sigma_u\Phi'_n),
\end{eqnarray*}
что вычислительно более удобно, поскольку все ключенные матрицы имеют относительно небольшой размер. преимущество общей формулировки в том, что она может использовать другие матрицы $\Sigma_{\hat{\vc{\alpha}}}$.

\noindent\textbf{Замечание 5.} На практике для использования асимптотических рапсределений для статистических выводов неизвестные значения в ковариационных матрицах могут быть заменены на их обычные оценки (LS, ML и др.) для случая стационарного и стабильного $y_t$ (см., однако, Замечание 1).

\noindent\textbf{Замечание 6.} Суммируя компоненты ошибок дисперсии прогноза по $k$,
\[\sum_{k=1}^K{\omega_{jk,h}}=\sum_{k=1}^K{\hat{\omega}_{jk,h}}=1\]
для каждого $j$ и $h$. Эти ограничения не принимаются во внимание в получении асимптотических распределений в пункте 7. Легко проверить, однако, что для размерности $K=1$ стандартные ошибки, полученные в пункте 7, нулевые, как они и должны быть, поскольку компоненты дисперсии ошибок прогноза равны 1 в этом случае. Проблема в данном контексте заключается в том, что асимптотическое рапсределение $\hat{\omega}_{jk,h}$ не может быть использовано обычным способом для тестов на значимость и построения доверительных интервалов, если $\omega_{jk,h}=0$. В этом случае из определенеия $d_{jk,h}$ и $\bar{d}_{jk,h}$ дисперсия асимптотического распределения, как легко видно, будет нулевой, следовательно, оценивание этих значений путем замены неизвестных параметров их обычными оценками может привести к $t$-статистикам, не имеющим асимптотически стандартное нормальное распределение, и, следовательно, они не могут использоваться обычным способом для статистических выводом (см. Замечание 1). Такое положение дел вызывает сожаление с практической точки зрения, потому что проверка значимости компонентов дисперсии ошибок пргнозов представляет особый интерес на практике. Однако следует отметить, что
\[\omega_{jk,h}=0 \ \Longleftrightarrow  \ \theta_{jk,i}=0 \ \text{для} \ i=0,\dots,h.\]
Может быть возможно тестировать последюю гипотезу.

\noindent\textbf{Замечание 7.} Совместные доверительные области и тестовые статистики для проверки гипотез, которые включают несколько коэффициентов откликов, могут быть полученыиз пунктов 1-7 обычным способом. Однако должно быть принято во внимание, что, например, элементы $\hat{\Phi}_i$ и $\hat{\Phi}_j$ не будут асимптотически независимыми. Если элементы из двух или более MA-матриц включены, должно быть определено совместное распределение всех матриц. Это распределение может быть легко получено из результатов, заданных в пунктах 1-7. Например, ковариационная матрица совместного асимптотического распределения $\ve(\hat{\Phi}_i,\hat{\Phi}_j)$ равно
\[\frac{\partial\ve(\hat{\Phi}_i,\hat{\Phi}_j)}{\partial\vc{\alpha}'}\Sigma_{\hat{\vc{\alpha}}}\frac{\partial\ve(\hat{\Phi}_i,\hat{\Phi}_j)'}{\partial\vc{\alpha}},\]
где
\[\frac{\partial\ve(\hat{\Phi}_i,\hat{\Phi}_j)}{\partial\vc{\alpha}'}=
\begin{bmatrix}
\cfrac{\partial\ve(\hat{\Phi}_i)}{\partial\vc{\alpha}'}\\
\cfrac{\partial\ve(\hat{\Phi}_j)}{\partial\vc{\alpha}'}=
\end{bmatrix}
\]
и так далее. Мы выбрали сформулировтаь утверждение для для индивидуальных матриц коэффициентов MA, поскольку тем самым все необходимые матрицы имеют относительно небольшие размеры и, следовательно, легко вычисляемы.

\noindent\textbf{Замечание 8.} Обозначая $jk$-ые элементы $\Phi_i$ и $\Theta_i$ как $\phi_{jk,i}$ и $\theta_{jk,i}$, соответственно, очевидно инетерсующими гипотезами для $j\neq k$ являются
\begin{equation}\label{IR20}
H_0:\phi_{jk,i}=0 \ \text{для $i=1,2,\dots$}
\end{equation}
и
\begin{equation}\label{IR21}
H_0:\theta_{jk,i}=0 \ \text{для $i=0,1,2,\dots$,}
\end{equation}
поскольку они могут интерпретироваться как гипотезы непричинности переменной $k$ для переменной $j$, то есть импульс в переменной $k$ не вызывает како-либо отклик в переменной $j$. Как уже было замечено в Разделе \ref{ROI}, это эквивалентно тому, что
\begin{equation}\label{IR22}
H_0:\phi_{jk,i}=0 \ \text{для $i=1,2,\dots,p(K-1)$}
\end{equation}
и
\begin{equation}\label{IR23}
H_0:\theta_{jk,i}=0 \ \text{для $i=0,1,2,\dots,p(K-1)$.}
\end{equation}

Используя неравенство Бонферрони, тест для \eqref{IR22} с уровнем значимости по крайней мере $100\gamma\%$ получается, отвергая $H_0$, если
\begin{equation}\label{IR24}
|\sqrt{T}\hat{\phi}_{jk,i}/\hat{\sigma}_{\phi_{jk}}(i)|>z_{(\gamma/2p(K-1))}
\end{equation}
для по крайней мере одного $i\in\{1,2,\dots,p(K-1)\}$. Здесь $z_{(\gamma)}$ является верхней $100\gamma$ процентной точкой стандартного нормального распределения, а $\hat{\sigma}_{\phi_{jk}}(i)$ является оценкой асимптотического стандартного отклонения $\sigma_{\phi_{jk}}(i)$ для $\sqrt{T}\hat{\phi}_{jk,i}$. Чтобы получить асимптотическое стандартное нормальное распределение $t$-отношения $\sqrt{T}\hat{\phi}_{jk,i}/\hat{\sigma}_{\phi_{jk}}(i)$, дисперсия $\sigma^2_{\phi_{jk}}(i)$ должна быть ненулевой.

Тест \eqref{IR23}  с уровнем значимости по крайней мере $\gamma$ получается, отвергая $H_0$, если
\begin{equation}\label{IR25}
|\sqrt{T}\hat{\theta}_{jk,i}/\hat{\sigma}_{\theta_{jk}}(i)|
\begin{cases}
>z_{(\gamma/2(pK-p+1))}& \text{для по крайней мере одного $i\in\{0,1,2,\dots,p(K-1)\}$, если $j>k$}\\
<z_{(\gamma/2(pK-p))}& \text{для по крайней мере одного $i\in\{0,1,2,\dots,p(K-1)\}$, если $j<k$}
\end{cases}
\end{equation}
Здесь $\hat{\sigma}_{\theta_{jk}}(i)$ является состоятельной оценкой стандартного отклонения асимптотического распределения $\sqrt{T}\hat{\theta}_{jk,i}$, которое предполагается ненулевым.

Тест, основанный на принципе Бонферрони, может иметь достаточно низкую мощность, посколкьу фактический уровень значимости может быть намного меньше, чем заданная верхняя гарница. Следовательно, тест, основанный на $\chi^2$- или $F$-статистиках, будет предпочтительнее. К сожалению, такие тесты не являются легкодоступными для нынешней ситуации. 
% Проблема аналогична обсужденное в разделе 3.6.4 в контексте тестирвоания многошаговой причинности
Для большего обсуждения см. также \citep{Lutkepohl1990}, а для различных подходов представления неопределенности в оцененных импульсных откликов см. \citep{SimsZha1999}.

Альтернативой использования асимптотических результатов, представленных выше, является методы бутстрепа. Хотя эти методы достаточно затратны с точки зрения вычислительного времени, они часто используются для оценивания свойств функций импульсных откликов (см., например, \citep{Runkle1987} и \citep{Kilian1998,Kilian1999}), поскольку не требуют явного получения выражений асимптотических дисперсий.

В текущей ситуации существует несколько подходов для симуляций. Один из них предполагает конкретный вид распределения процесса белого шума, например, $u_t\sim N(0,\hat{\Sigma_u})$ и генерирует большое число реализаций временного ряда, основанное на оценивании VAR-коэффициентов. По этим временным рядам затем оценивается новый набор коэффициентов, соответствующие импульсные отклики и компоненты дисперсии ошибок прогноза. Полученные этим способом эмпирические распределения могут быть использованы для исследования фактических распределений интересующих параметров.

Если не сделано никаких предположений о распределении инноваций, можно использовать методы бутстрепа путем создания нового набора остатков, извлеченных из оцененных остатков. Кратко рассмотрим основные положения данного метода. Сначала оценивается интересующая модель. Если оцененные остатки обозначаются как $\hat{u}_t$, вычисляются центрированные остатки $\hat{u}_1-\bar{\hat{u}},\dots,\hat{u}_T-\bar{\hat{u}}$, а бутстреп=остатки, $u_1^*,\dots,u_T^*$ вычисляются путем случайного извлечения с повторением из центрированных остатков. Затем $u_t^*$ используются для вычисления бутстреп-временных рядов рекурсивно, начиная с заданных начальных значений $y_{-p+1},\dots,y_0$ для модели с $p$ лагами. Модель переоценивается и интересующие параметры определяются на основе оценок параметров. Повторяя этот шаг много раз, мы получим эмпирическое бутстреп-распределение интересующих параметров. Из этого распределения могут быть получены необходимые квантили и, следовательно, доверительные интервалы.

Обозначим символами $\phi$, $\hat{\phi}$ b $\hat{\phi}^*$, соответственно, коэффициент импульсного отклика, его оценку и соответствующую бутстреп-оценку. Обычно рассматрвиаются следующие доверительные интервалы (см., например, \citep*{BLW2001}):
\begin{itemize}
\item \textit{Стандартный процентильный интервал}
\newline Самым употребимым на практике методом построения доверительных интервалов для импульсных откликов является интервал
\[CI_S=[s^*_{\gamma/2}, s^*_{(1-\gamma/2)}],\]
где $s^*_{\gamma/2}$ и $s^*_{(1-\gamma/2)}$ -- $\gamma/2$- и $(1-\gamma/2)$-квантили, соответственно, эмпирического распределения $\hat{\phi}^*$. Интервал $CI_S$ является процентильным доверительным интервалом, опсианным, например, в \citep{EfronTibshirani1993}.
\item \textit{Процентильный интервал Холла}
\newline В \citep{Hall1992} была представлена обычная бутстреп-аналогия, утверждающая что распределение $(\hat{\phi}-\phi)$ приближенное равно распределению $(\hat{\phi}^*-\hat{\phi})$на больших выборках. Из этого результата вытекает, что можно получить интервал
\[CI_H=[\hat{\phi}-t^*_{(1-\gamma/2)},\hat{\phi}-t^*_{\gamma/2}],\]
где $t^*_{(1-\gamma/2)}$ и $t^*_{\gamma/2}$ -- $(1-\gamma/2)$- и $\gamma/2$-квантили, соответственно, эмпирического распределения $(\hat{\phi}^*-\hat{\phi})$.
\item \textit{Стюдентизированный интервал Холла}
\newline В некоторых ситуациях может быть предпочтительнее использовать стьюдентизированную статистику $(\hat{\phi}-\phi)/\widehat{\mathrm{var}}(\hat{\phi})^{1/2}$ для построения доверительного интервала. В этом случае используются бутстреп-квантили $t^{**}_{\gamma/2}$ и $t^{**}_{1-\gamma/2}$ из распределения $(\hat{\phi}^*-\hat{\phi})/\widehat{\mathrm{var}}(\hat{\phi}^*)^{1/2}$ для построения интервала
\[CI_{SH}=[\hat{\phi}-t^{**}_{(1-\gamma/2)}\widehat{\mathrm{var}}(\hat{\phi}^*)^{1/2},\hat{\phi}-t^{**}_{\gamma/2}\widehat{\mathrm{var}}(\hat{\phi}^*)^{1/2}].\]
В этом подходе дисперсии оцениваются через бутстреп внутри каждого бутстреп-повторения.
\end{itemize}

Нужно подчеркнуть, что бутстреп не решает проблемы вырожденного асимптотического распределения импульсных откликов и получающихся потенциально неверных статистических выводов. Если асимптотическое распределение вырожденное, бутстреп может давать осмысленные доверительные интервалы. Более детальное обсуждение этой проблемы см. в \citep*{BLN2000}, где также рассматриваются методы для коррекции асимптотических выводов. Одно из возможных решений -- рассмотреть бутстреп-процедуры, которые адаптируются к типу вырожденности предельного распределения. Например, можно использовтаь subsampling для оценивания скорости сходимости оценок параметров в дополнение к параметрам модели. Эти и другие методы имеют, однако недостатки в эмпирическихз приложениях. Или они не очень практичны для процессов реалистичной размерности и авторегрессионного порядка, или они не применяются хорошо в выборках типичного объема. Второе возможное решение -- удалить все точки, где может происходить вырожденность асимптотического распределения до проведения анализа импульсных откликов. В данном случае это предложение сводится к определению всех нулевых коэффициентов в первом этапе анализа и применению полученных нулевых ограничений на следующем этапе, где в результате subset model оценивается и используется для вычисления импульсных откликов. Третья возможность обойти проблему -- рассмотреть VAR-процесс бесконечного порядка, допускающий увеличение порядка, когда становится достыпно большее количество информации (другими словами, порядок модели предполагается расходящимся к бесконечности с соответствующей скоростью при увеличении объема выборки).

Другая проблема посроения доверительных интервалов была указана в \citep{Lutkepohl2013b}. Известно, что шоки идентифицированы с точностью до знака, и эта особенность может привести к вводящим в заблуждение доверительным интервалам для импульсных откликов, если для их построения используются методы симуляций, в частности, бутстреп. Рассмотрим следующий иллюстративный пример. Пусть $b$ является $i$-ым столбцом матрицы $\mathsf B$, то есть $b$ представляет вектор текущих эффектов $i$-го шока. Должно быть всегда сделано фиксирование знака для элемента, который явно отличается от нуля, поскольку тогда обеспечивание определенного знака не является ограничительным для других элементов. Если фиксирование знака  сделано через элемент, который близок к нулю, это может привести к искаженным симулированным доверительным интервалам других параметров в $b$. Предположм, что $b=(b_1,b_2)'$ -- просто двумерный вектор, и фиксирование знака сделано через $b_2$, хотя истинное знаечние $b_2=0$. Дополнительно предположим, что фактическое распределение оценки $\hat{b}$ есть $N(b,\Sigma_b)$. Тогда $(1-\gamma)$-доверительный интервал для $b_1$ должен быть
\[\hat{b}_1-c_{1-\gamma/2}\sigma_{11},\hat{b}_1+c_{1-\gamma/2}\sigma_{11},\]
где $c_\eta$ -- $\eta$-квантиль стандартного нормального распределения, а $\sigma^2_{11}$ -- верхний левый элемент в $\Sigma_b$. Однако, если мы строим доверительный интервал следующим симуляционным методом, может быть получен достаточно отличный, более широкий доверительный интервал. Пусть $b^{(n)}$ для $n=1,\dots,N$ следующий:
\begin{enumerate}
\item Извлечем $\tilde{b}=(\tilde{b}_1,\tilde{b}_2)'$ из распределения $N(b,\Sigma_b)$.
\item Положим
\[b^{(n)}=
\begin{cases}
\tilde{b}, & \text{если $\tilde{b}_2\geq0$,}\\
-\tilde{b}, & \text{если $\tilde{b}_2<0$.}
\end{cases}
\]
\end{enumerate}
Выбирая доверительный интервал для $b_1$ из эмпирического распределения как
\begin{equation}\label{CIsign}
[b_1^{(N\gamma/2)},b_1^{(N(1-\gamma/2))}]
\end{equation}
может очевидно привести к более широкому доверительному интервалу с не очень большой вероятностью включения, поскольку знак $\hat{b}_1$ меняется с веоятностью около 0.5, если истинное значение $b_1$ ясно и значимо положительно. Фактическая вероятность покрытия и длина интервала \eqref{CIsign} зависит, конечно, от истинных значений параметра. Проблема заключаестя в том, что $b_2$ будет давать положительные и отрицательные знаечния в симуляциях. Всякий раз, когда получается отрицательное значение, оно будет конвертировано в положительное значение. В то же время $b_1$ будет также отражается в другую сторону от начала координат. Фактически пара $(b_1,b_2)'$ из части пространства параметров, связанной с различными локальными максимумами функции правдоподобия, выбрана этим способом. Когда $b_1$ всегда положительно в области пространства параметров, соответствующей первому оптимуму функции правдоподобия, это может привести к очень широкому доверительному интервалу для $b_1$, поскольку включены значения $b_1$ из двух различных локальных оптимумов функции правдоподобия, даже если область вариации $b_1$ мала в окрестности одного локального оптимума. Если $b_1$ была использована для фиксирования знака, ситуация будет достаточно отличной. Эти рассмотрения предлагают, что хорошей стратегией являестя исключение фиксирвоания знака, основанного на неточно оцененных impact effects. Другими словами, можно захотеть проверить $t$-отношения оцененных элементов в $\mathsf B$ и рассмотреть переменные для фиксирвоания знака, которые имеют impact effects с большими (по абсолютному значению) $t$-статистиками. В \citep{Lutkepohl2013b} рассматриваются два примера с применением этой методологии.

\subsubsection{Доверительные дапазоны}

Обычно доверительные диапазоны строятся относительно индивидуальных коэффициентов импульсных откликов. Если индивидуальные доверительные интервалы для заданного уровня значимости строятся около коэффициентов импульсных откликов для каждого горизонта отклика отдельно, то нет гарантии, что общий уровень покрытия для всех импульсных откликов одной переменной будет соответствовать предварительно специфицированному уровню доверия. Другими словами, вероятность диапазона, содержащего истинную функцию импульсного отклика конкретной переменной будет, в общем случае, не равна $1-\gamma$, если доверительный диапазон строится как объединение индивидуальных $(1-\gamma)\times 100\%$-доверительных интервалов, то есть игнорируется совместное рапсределение. Такие доверительные диапазоны называют \textit{наивными} диапазонами. Следовательно, желательно построить доверительные диапазоны с общей предварительно специфицированной вероятностью покрытия. Соответствующие методы для этого рассматриваются в \citep*{LSBW2013}, ограничиваясь классическим оцениванием (хотя соответствующие Байесовские доверительные диапазоны уже были рассмотрены, например, в \citep{SimsZha1999}). 

Многие из методов, рассматрвиаемые в \citep*{LSBW2013}, основаны на стандартном остаточном бутстрепе. Также вместо обычных OLS-оценок VAR-коэффициентов используются скорректированные на смещение оценки, поскольку они оказались лучше работающими в этом контексте (см. \citep{Kilian1998,Kilian2001}). Рассматриваются следующие процедуры:

\begin{enumerate}
\item \textit{Наивный диапазон (naive)}
\newline Как уже было отмечено, наивный доверительный диапазон задается собранием доверительных интервалов для индивидуальных коэффициентов импульсных откликов. Пусть $s^*_{\gamma/2}$ и $s^*_{1-\gamma/2}$ обозначают $\gamma/2$ и $1-\gamma/2$ бутстреп-распределения оцененного коэффициента импульсного отклика на горизонте $h$ ($\phi_{ij,h}$), где $h=0,\dots,H$. Тогда $(1-\gamma)\times 100\%$-доверительный интервал для $\phi_{ij,h}$ просто задается как
\[s^*_{\gamma/2},s^*_{1-\gamma/2}\]
для всех горизонтов $h=0,\dots,H$. Хотя метод не гарантирует совместную вероятность покрытия $1-\gamma$, он часто используется в прикладных работах возможно на том основании, что доверительные диапазоны призваны просто служить указанием неопределенности выборки, связанной с оцененными импульсными откликами.

\item \textit{Традиционный диапазон Бонферрони (B)}
\newline В отличие от наивных диапазонов, диапазоны Бонферрони принимают во внимание стохастическую зависимость в оцененных коэффициентах импульсных откликах путем увеличения величины диапазонов, так чтобы гарантировать предварительно специфицированную нижнюю границу уровня доверия по крайней мере асимптотически. То есть они в общем случае будут консервативными. Формально диапазоны Бонферрони строятся по доверительным интервалам для индивидуальных коэффициентов импульсных откликов. Номинальный уровень доверия каждого интервала задается как $(1-\gamma/L)\times100\%$, где $L=H+1$ если эффект вклада не ограничивается нулем, и $L=H$, если эффект вклада ограничен нулем. Для каждого горизонта $h$ ($h=0,\dots,H$) $(1-\gamma/L)\times100\%$-доверительный интервал для $\phi_{ij,h}$ задается как
\[s^*_{\gamma/2L},s^*_{1-\gamma/2},\]
где $s^*_{\gamma/2L}$ и $s^*_{1-\gamma/2}$ являются $\gamma/2L$ и $1-\gamma/2L$ квантили бутстреп-распределения оценки $\phi_{ij,h}$.

\item \textit{Скоректированный диапазон Бонферрони (B-adj)}
\newline Поскольку традиционные диапазоны Бонферрони являются консервативными по построению, в \citep*{LSBW2013} предлагается коррекция, которая уменьшает диапазоны, но все еще соблюдает общий уровень покрытия относительно бутстреп импульсных откликов. В дальнейшем число бутстреп повторений обозначается как $b$. Сначала диапазон Бонферрони строится как в пункте 2. Этот диапазон покрывает и полные, и неполные бутстреп функции откликов. Бутстреп импульсные отклики полностью внутри диапазоны идентифицируются и сохраняются, и новый интервал получается как граница этих функций. Получившийся в результате диапазон является более узким, или по крайней мере не шире, чем традиционный диапазон Бонферрони. На последнем шаге число бутстреп импульсных откликов, покрытых диапазоном, вычисляется и обозначается как $nb$. Если $nb>(1-\gamma)b$, применяется последовательная процедура, направленная на устранение $nb-(1-\gamma)b$ бутстреп импульсных откликов. На каждом шаге бутстреп импульсные отклики идентифицируются, чтобы предоставлять по крайней мере одну точку на текущих диапазоных. Существует самое большее $2(H+1)$ таким функций. Функция, которая наибольшим образом способствует размеру текущего диапазона (измеренного как сумма ширин индивидуальных интервалов) отвергается. Процедура останавливается после того, как устраняется $nb-(1-\gamma)b$ функций. Диапазон получается как граница оставшихся $(1-\gamma)b$ бутстреп импульсных откликов.

\quad\newline Эта процедура называется скорректирвоанном методом Бонферрони и сокращается как B-adj в дальнейшем. Она имеет асимптотически корректный уровень покрытия, всякий раз когда бутстреп предлагает доверительное множество с асимптотически точным уровнем покрытия, поскольку данный метод сохраняет $(1-\gamma)b$ бутстреп выборок и исопльзует внешнюю границу доверительного множества.

\item \textit{Диапазон Шеффе (Scheff\'{e})}
\newline Так называемый диапазон Шеффе был преложен в \citep{Jorda2009}. Он основан на асимптотическом распределении импульсных откликов и вычисляется, используя нисходящую процедуру (step-down procedure), предложенную в \citep{JordaMarcellino2010} в контексте построения совместных диапазонов прогноза. Для описания этого метода более формально мы исопльзуем следующее обозначение: $\phi_{ij}=(\phi_{ij,0},\dots,\phi_{ij,H})$ является $(H+1)$-мерным вектором откликов переменной $i$ на $j$-ый шок, $\phi_{ij,1,\dots,H}=(\phi_{ij,1},\dots,\phi_{ij,H})$ обозначает соответствующий вектор, когда эффект вклада ограничен нулем и, следовательно, не оценивается. Оцененную асимптотическую ковариационную матрицу для $\hat{\phi}_{ij}$, $\hat{\Omega}_{ij}/T$ можно разложить как $\hat{\phi}_{ij}$, $\hat{\Omega}_{ij}/T=PP'$, где $P$ -- нижнетреугольная матрциа разложения Холецкого. $c^2_{\gamma}(h+1)$ являеся $(1-\gamma)$-квантилем рапсределения $\chi^2$ с $h+1$ степенью свободы, а $\left[\sqrt{c^2_\gamma(h+1)/(h+1)}\right]$ -- $((H+1)\times1)$-вектор, $(h+1)$-ый элемент которого равен $\sqrt{c^2_\gamma(h+1)/(h+1)}$ (для $h=0,1,\dots,H$). Используя эти обозначения, диапазон задается как
\begin{equation}\label{CB1}
\hat{\phi}_{ij}\pm P\left[\sqrt{\frac{c^2_\gamma(h+1)}{h+1}}\right],
\end{equation}
если эффект вклада шока неограничен, и как
\begin{equation}\label{CB1}
\hat{\phi}_{ij,1,\dots,H}\pm P^*\left[\sqrt{\frac{c^2_\gamma(h)}{h}}\right],
\end{equation}
если эффект вклада шока равен нулю по построению. Здесь $P^*$ являестя нижнетреугольной матрицей, полученной из разложения Холецкого матрицы, полученной из $\hat{\Omega}_{ij}/T$ путем удаления первого столбца и первой строки, а $\left[\sqrt{c^2_\gamma(h)/h}\right]$ -- $(H\times1)$-вектор с $h$-ым элементом, равным $\sqrt{c^2_\gamma(h)/h}$ (для $h=1,2,\dots,H$).

\quad\newline Заметим, что диапазон Шеффе основан на оценках наименьших квадратов VAR-коэффициентов, как изначально предлагалось, а не на скорректированных на смещение оценках. Также для больших $H$ (например, $H=10$) может возникнуть проблема получения разложения Холецкого, и в \citep*{LSBW2013} предлагается заменять все собствнные знаечния оцененной ковариационной матрицы, коорые меьше или раны 0, на значение $10^{-6}$.

\item \textit{Диапазон соседней траектории (neighbouring path band, NP)}
\newline Метод соседней траектории (NP), предложенная в \citep{Staszewska2007}, является процедурой, основнаной на $b$ бутстреп траекториях откликов $\hat{\phi}_{ij}^{c*}$. В последовательном алгоритме удаляется $\gamma b$ бутстреп траекторий. Граница оставшихся $(1-\gamma)b$ траекторий дает доверительный диапазон. While eliminating individual paths, метод направлен на достижения узкого доверительного диапазона (все еще содержащего ($(1-\gamma)b$ бутстреп траекторий). Следовательно, траектории кандидаты для удаления на каждом шаге являются теми, которые содержат по крайней мере одну точку вне границы других бутстреп траекторий. Из группы этих траекторий кандидатов алгоритм выбирает одну самый дальний (в смысле евклидова расстояния) от импульсного отклика, полученного из исходных данных. После устранения этой крайней траектории, шаг удаления повторяется до тех пор, пока не будут исключены $\gamma b$ траекторий.

\item \textit{Диапазон Wolf \& Wunderli (Wolf \& Wunderli band, WW)}
\newline В \citep{WolfWunderli2012} были предложены диапазоны для multiple horizon forecasts, и этот метод был адаптирован в \citep*{LSBW2013} для построения диапазонов импульсных откликов. Диапазон основан на $b$ бутстреп тракториях откликов $\hat{\phi}_{ij}^{c*}$ и вычисляется как
\[\hat{\phi}_{ij}^{c}\pm\left[d^{\max,c}_{|\cdot|,1-\gamma}\sqrt{\hat{\omega}^c_{h+1,h+1}}\right],\]
где $\left[d^{\max,c}_{|\cdot|,1-\gamma}\sqrt{\hat{\omega}^c_{h+1,h+1}}\right]$ -- вектор размерностью $((H+1)\times 1)$, $(h+1)$-ый элемент которого (для $h=0,1,\dots,H$) задается как $d^{\max,c}_{|\cdot|,1-\gamma}\sqrt{\hat{\omega}^c_{h+1,h+1}}$. Здесь $\hat{\omega}^c_{h+1,h+1}$ является $(h+1)$-ым элементом главной диагонали $\hat{\Omega}^c_{ij}$, а $d^{\max,c}_{|\cdot|,1-\gamma}$ вычисляеся следующим образом:
\begin{itemize}
\item В отдельной итерации бутстреп-метода вычисляются
\[\hat{s}^{c*}_{ij}(h)=\frac{\hat{\phi}_{ij,h}^{c*}-\hat{\phi}_{ij,h}^{c}}{\sqrt{\hat{\omega}^{c*}_{h+1,h+1}}}, \ h=0,\dots,H.\]
Вычисляется величина $\max^{c*}_{|\cdot|}\equiv \max(|\hat{S}^{c*}(H)|)$, где $\hat{S}^{c*}(H)=(\hat{s}^{c*}_{ij}(0),\dots,\hat{s}^{c*}_{ij}(H))'$.
\item После применения $b$ итераций бутстреп метода и получения $\max^{c*}_{|\cdot|,1},\dots,\max^{c*}_{|\cdot|,b}$ вычисляется $d^{\max,c}_{|\cdot|,1-\gamma}$, обозначающая эмпирическую квантиль уровня $(1-\gamma)$ статистик $\max^{c*}_{|\cdot|,1},\dots,\max^{c*}_{|\cdot|,b}$.
\end{itemize}
\end{enumerate}

Исходя из результатов симуляци, авторы приходят к слеудующим общим выводам:
\begin{enumerate}
\item Наивный и Шеффе методы могут иметь очень плохие уровни покрытия, намного меньшие номинального уровня. Это верно в частности для метода Шеффе. Эти два метода не могут быть рекомендованы, если желателен хороший уровень покрытия. Конечно, метод Шеффе должен быть  dismissed для построения доверительных диапазонов для импульсных откликов. 
\item Метод WW может давать чрезвычайно широкие доверительные диапазоны по сранвению с методами Бонферрони и NP, особенно когда объем выборки мал. Таким образом, этот метод должен быть использован с осторожностью, в частности для относительно малых выборок.
\item Традиционный метод Бонферони, как парвило, производит несколько более широкие диапазоны, чем методы B-adj и NP, особенно если propagation horizon is large.
\item Методы B-adj и NP примняются хорошо в терминах уровня покрытия и ширины диапазона для большинства сценариев. Исключением является процессы с единичным корнем, когда объем выборки мал.
\end{enumerate}
Таким образом, эксперименты Монте-Карло подтверждают, что метод B-adj достаточно конкурентен, и в некоторых отношениях даже лучший. В то время как он имеет хорошее покрытие, он также приводит к достаточно малым диапазонам. Метод NP является ближайшим конкурентом, 
однако, до сих пор ему не хватает теоретической базы. 

\subsection{Другие возможности идентификации структурных шоков}

\subsubsection{Идентификация через сдвиги в волатильности}

Одна из возможностей идентификации структурных шоков использует предположение о том, что существует по крайней мере один сдвиг в волатильности остатков, и, следовательно, остатки в модели будут гетероскедастичными. Этот подход был исопльзован в \citep{Rigobon2003}, \citep{RigobonSack2003} и \citep{LanneLutkepohl2008a,LanneLutkepohl2008b}. Рассмотрение в контексте обобщенной модели было предложено в \citep{Lutkepohl2013a}. Предположим, что существует единственный сдвиг в волатильности переменных в течение периода выборки. Следовательно, предположим, что у нас есть выборка объема $T$ и сдвиг в волатильности шоков происходит, скажем, в период $T_B$:
\begin{equation}\label{Vol1}
\Sigma_u=
\begin{cases}
\Sigma_1 &\text{для $t=1,\dots,T_B-1$,}\\
\Sigma_2 &\text{для $t=T_B,\dots,T$.}
\end{cases}
\end{equation}
Ковариационные матрицы $\Sigma_1$ и $\Sigma_2$ можно диагонализировать одновременно, то есть существует $(K\times K)$-матрица $W$ и диагональная матрица $\Psi=\mathrm{diag}(\psi_1,\dots,\psi_K)$ с положительными диагональными элементами $\psi_i$, $i=1,\dots,K$, такие что $\Sigma_1=WW'$ и $\Sigma_2=W\Psi W'$. Здесь диагональные элементы $\Psi$ отражают сдвиги в дисперсиях шоков после возможно произошедшего изменения в волатильности. Фактически сдвигв волатильности произошел, если значения $\psi_i$ отличаются от единицы. В \citep{LanneLutkepohl2008a} было показано, что $W$ является единственной за исключением перемены знака, если все $\psi_i$ различны и упорядочены некоторым способом (см. также \citep*{LLM2010}). Таким образом, если мы выбираем $\mathsf B=W$, мы получаем единственность шоков $\varepsilon_t$ (за исключением перемены знака) без необходимости делать дополнительные идентификационные предположения. Структурные шоки имеют тогда единичную ковариационную матрицу в первом режиме и $\Psi$ во втором режиме, то есть
\begin{equation}\label{Vol1}
\Sigma_\varepsilon=
\begin{cases}
I_K &\text{для $t=1,\dots,T_B-1$,}\\
\Psi &\text{для $t=T_B,\dots,T$.}
\end{cases}
\end{equation}
Следовательно, они ортогональны обоим режимам. Это является достаточным для идетификации шоков.

Рассмотрим иллюстративный пример, предложенный в \citep{Lutkepohl2013a}. пусть у нас есть двумерная система, такая что
\[u_t=
\begin{bmatrix}
u_{1t}\\
u_{2t}
\end{bmatrix}=
\begin{bmatrix}
b_{11} & b_{12}\\
b_{21} & b_{22}
\end{bmatrix}
\begin{bmatrix}
\varepsilon_{1t}\\
\varepsilon_{2t}
\end{bmatrix}
\]
Для этого случая соотношения $\Sigma_1=WW'$ и $\Sigma_2=W\Psi W'$ соответствуют
\[
\begin{bmatrix}
\sigma^2_{1,1} & \sigma_{12,1}\\
\sigma_{12,1} & \sigma^2_{2,1}
\end{bmatrix}=
\begin{bmatrix}
b_{11}^2+b_{12}^2 & b_{11}b_{21}+b_{12}b_{22}\\
b_{11}b_{21}+b_{12}b_{22} & b_{21}^2+b_{22}^2
\end{bmatrix}
\]
и
\[
\begin{bmatrix}
\sigma^2_{1,2} & \sigma_{12,2}\\
\sigma_{12,2} & \sigma^2_{2,2}
\end{bmatrix}=
\begin{bmatrix}
\lambda_1b_{11}^2+\lambda_2b_{12}^2 & \lambda_1b_{11}b_{21}+\lambda_2b_{12}b_{22}\\
\lambda_1b_{11}b_{21}+\lambda_2b_{12}b_{22} & \lambda_1b_{21}^2+\lambda_2b_{22}^2
\end{bmatrix}.
\]
Таким образом, мы получаем шесть соотношений:
\begin{eqnarray*}
\sigma^2_{1,1}  &=&b_{11}^2+b_{12}^2,\\
\sigma_{12,1}  &=&b_{11}b_{21}+b_{12}b_{22},\\
\sigma^2_{2,1}  &=&b_{21}^2+b_{22}^2,\\
\sigma^2_{1,2}  &=&\lambda_1b_{11}^2+\lambda_2b_{12}^2,\\
\sigma_{12,2}  &=&\lambda_1b_{11}b_{21}+\lambda_2b_{12}b_{22},\\
\sigma^2_{2,2}  &=&\lambda_1b_{21}^2+\lambda_2b_{22}^2,
\end{eqnarray*}
которые мы можем решить относительно шести структурных параметров $b_{11}$, $b_{12}$, $b_{11}$, $b_{22}$, $\lambda_1$, $\lambda_2$. Здесь последние два параметра являюстя диагональными элементами матрицы $\Psi$. Решение единственное (до знака), если $\lambda_1$ и $\lambda_2$ различны и упорядочены некоторым конкретным образом, например, $\lambda_1<\lambda_2$. Заметим, что дисперсии структурных шоков нормализованы на единицу в первой части выборки. Следовательно, $\lambda_i$ указывает на изменение дисперсии при переключении с первого на второй режим. Другими словами,  они интерпретируются как относительные диспесии во втором режиме выборки. Требование единственности только означает, что сдвиг в дисперсии не является однородным среди обеих переменных. Фактически только дисперсия одной переменной должна измениться. Этого уже достаточно для единственности решения.

Требование, что все все $\psi_i$ различны, удовлетворяется, если сдвиги в волатильности не пропорциональны во всех переменных. Даже если волатильность в одном из шоков не меняется вообще, то есть одно из $\psi_i$ может быть единицей, значения $\psi_i$ могут, конечно, быть различными, и это является существенным требованием для единственности $\mathsf B$. Любые другие ограничения на $\mathsf B$ будут сверхидентифицирующими. Так как сдвиг в дисперсии являестя тестируемым предположением, мы не должны полагаться исключительно на информацию из экономической теории или других ресурсов, чтобы гарантировать идентификацию структурных шоков. Вместо этого мы можем использовать информацию из данных и применить статистические процедуры для получения идентификации.

Для получения единственности $W$ и, следовательно, $\mathsf B$, мы можем, например, упорядочить $\psi_i$ от наименьшего к наибольшему. Если ограничения накладываются на $\mathsf B$, они могут быть только совместимы с одним конкретным порядком в $\psi_i$ и не обязательно с порядком согласно размеру. Следовательно, в оцеривании с ограничениями на $\mathsf B$ мы не накладываем какое-нибудь конкретное упорядочивание на $\psi_i$, но позволяем данным решать, какое являестя лучшим. Это не являестя проблемой, поскольку локальная идентификация гарантируется любым упорядочиванием $\psi_i$, при условии что все они различны.

Факт о том, что всегда возможно поменять знаки всех элементов в единственном столбце матрицы $W=\mathsf B$ без влияния на правдоподобие, не являестя проблемой в данном контексте, поскольку для выполнения асимптотической теории нам нужна только локльная идентификация, которая гарантируется несмотря на перемены знака. Для практических целей изменение всех знаков в столбце в $W$ просто означает, что рассматривается отрицательный шок, если шоки изначально положительны, и наоборот.

Также возможно учитывать возможно больше одного сдвига в волатильности. Если существует $n+1$ различных режимов, и ковариации в этих режимах равны $WW',W\Psi_1 W',\dots,W\Psi_n W'$, где все $\Psi_i$ являются диагональными матрциами, единственность $W$ (до знака) гарантируется, например, если все диагональные элементы только в одной из $\Psi_i$ различны, и м можем снова выбирать $\mathsf B=W$ (см. также \citep[Section 3.1]{Lutkepohl2013a}). Проблемы, возможные в данной постановке, заключаются в следующем: короткие режимы, что может привести к плохо интерпретируемым оценкам, а также неизвестные даты переключения этих режимов (см. \citep*{EFR2011}, где производится предварительное тестирвоание дат сдвигов).

Оценивается модель посредством метода максимального правдоподобия. Определим оценки ковариационных матриц в двух режимах как
\[\tilde{\Sigma}_1=\frac{1}{T_B-1}\sum_{t=1}^{T_B-1}{\hat{u}_t\hat{u}'_t}\quad\text{и}\quad\tilde{\Sigma}_2=\frac{1}{T-T_B+1}\sum_{t=T_B}^{T}{\hat{u}_t\hat{u}'_t},\]
где $\hat{u}_t$ -- остатки от оценивания VAR($p$)-модели. Заменяя VAR-параметры в гауссовской функции правдоподобия на их OLS-оценки, мы получаем концентрированную функцию логарифма правдоподобия вида
\begin{multline}
\log L_H=\frac{T_B-1}{2}\left(\log\det(WW')+\mathrm{tr}\left\{\tilde{\Sigma}_1(WW')^{-1}\right\}\right)\\
-\frac{T-T_B+1}{2}\left(\log\det(W\Psi W')+\mathrm{tr}\left\{\tilde{\Sigma}_1(W\Psi W')^{-1}\right\}\right).
\end{multline}
Однако полученные оценки не являются ML-оценками, поскольку OLS-оценки VAR-коэффициентов не являются ML-оценками в данном случае, посколкьу они не принимают во внимание гетероскедастичнсть ошибок. Аналогично LR-тест на сверхидетифицирующие ограничения не являестя LR-тестом в обычном смысле, поскольку он основан на максимизации псевдо концентрированной функции правдоподобия. Однако LR-тест все еще имеет обычные асимптотические свойства стандартного LR-теста, и все еще можно использовать распределение $\chi^2$ для этого теста.

Вторая возможность идентификации через изменения в волатильности -- предположить не гетероскедастичные ошибки, а условно гетероскедастичные. В \citep{NormandinPhaneuf2004} предлагается использовать многомерную GARCH-модель для учета изменения в волатильности. пусть ошибки в приведенной форме порождаются многомерной GARCH (MGARCH) процессом вида
\begin{equation}\label{GARCH1}
\Sigma_{u,t|t-1}=E(u_tu'_t|u_{t-1},\dots)=W\Sigma_{\varepsilon,t|t-1}W',
\end{equation}
где $\Sigma_{\varepsilon,t|t-1}=\mathrm{diag}(\sigma^2_{1,t|t-1},\dots,\sigma^2_{K,t|t-1})$ является диагональной матрицей с
\begin{equation}\label{GARCH2}
\sigma^2_{k,t|t-1}=\gamma_{k0}+\sum_{j=1}^q{\gamma_{kj}\varepsilon^2_{t-j}}+\sum_{j=1}^s{g_{kj}\sigma^2_{k,t-j|t-j-1}}, \ k=1,\dots,K.
\end{equation}
Другими словами, предполагается, что структурные шоки $\varepsilon_t$ instantaneously некоррелированными и имеют диагональную MGARCH($q,s$)-структуру (см. \citep{vdWeide2002} и \citep{VDP2002}). Для простоты предполагается MGARCH(1,1)-модель.

В \citep{SentanaFiorentini2001} предлагается общие результаты, которые влекут идентификацию структурных шоков (за исключением перестановок и изменений знаков), если все, кроме одной компоненты фактически условно гетероскедастичны и $\Gamma'\Gamma$ обратима, где $(\sigma^2_{k,10},\dots,\sigma^2_{k,T|T-1})$ -- $k$-ая строка в $\Gamma'$. Другими словами, в случае GARCH(1,1) у нас есть самое большее один $k\in\{1,\dots,K\}$, в котором $\gamma_{k1}=g_{k1}=0$. Обратимость $\Gamma'\Gamma$ гарантирует, что условная гетероскедастичность не обусловлена небольшим количеством процессов как в факторной модели, где единственный процесс может определять развитие большого множества переменных. Конечно, это требование соответствует условию, что должна быть существенная неоднородность в измнениях режимов волатильности, когда существует только конечное число режимов волатильности. При условии, что идентификационные условию выполняются, структура \eqref{GARCH1} гарантирует, что если мы выберем $\mathsf B=W$, структурные шоки будут единственными, а импульсные отклики, включающие эффекты воздействия (impact effects), являются инвариантными по времени.

Для оценивания параметров в \citep{NormandinPhaneuf2004} предлагается двухшаговая процедура, в которой на первом шаге оценивается VAR($p$)-модель, а затем путем максимизации соответствующей функции правдоподобия получаются оценки параметров GARCH и структурных параметров. Другими словами, матрица $\mathsf B$ и параметры GARCH оцениваются путем максимизации
\begin{equation}\label{GARCH3}
\log L_{GARCH}(W,\vc{\gamma})=-\frac{1}{2}\sum_{t=1}^T{[\log\det(W\Sigma_{\varepsilon,t|t-1}W')+\hat{u}'_t(W\Sigma_{\varepsilon,t|t-1}W')^{-1}\hat{u}_t]},
\end{equation}
где $\hat{u}_t$ -- остатки от оценивания VAR($p$) на первом шаге, а $\vc{\gamma}$ -- вектор GARCH-параметров. В \citep{BouakezNormandin2010} было замечено, что полная оптимизация \eqref{GARCH3} может быть сложной в системах высокой размерности. В этом случае могут быть необходимы дополнительные упрощения. например, можно разделить систему и ввести дополнительные шаги в оценивание, в частности, если допустимы соответствующие ограничения на $\mathsf B$.

В принципе, условия идентификации можно проверитьс татистическими методами. В частности, можно тестировать, являются ли параметры GARCH в \eqref{GARCH2} статистически значимыми. Кроме того, можно проверить невырожденность матрицы $\Gamma'\Gamma$.

Третья возможность идентификации через изменения в волатильности предлагает конечное число режимов волатильсноти, которые порождаются эндогенно через марковский процесс. Данный подход (в контексте идентификации структурных шоков) был предложен в \citep*{LLM2010}. Более полная методология для использования этого в модели SVAR была представлена в \citep{HerwartzLutkepohl2011}. В этом подходе предполагается, что распределение ошибок $u_t$ зависит от дискретного марковского процесса $s_t$ ($t=0,\pm1,\pm2,\dots$) с $M$ состояниями. Другими словами, $s_t\in\{1,\dots,M\}$. Переходные вероятности между состояниями равны
\[p_{ij}=\mathrm{Pr}(s_t=j|s_{t-1}=i),\quad i,j=1,\dots,M.\]
В \citep{LLM2010} предполагается, что условное распределение $u_t$ при заданном состоянии $s_t$ является нормальным,
\[u_t|s_t\sim N(0,\Sigma_{s_t}).\]
Это предположение сделано для удобства и может быть ослаблено. Также VAR-коэффициенты не зависят от марковского процесса $s_t$ и предполагаются инвариантными по времени. Хотя существует только конечное количество состояний волатильности, модель может смешивать эти состояния, назначая вероятности строго между нулем и единицей в любой определенный период $t$. Таким образом, она может охватить постепенный переход из одного состояния в другое, и можно утверждать, что она может также порождать континуум состояний. Они сосредоточены на конечным количестве состояний, что может упростить интерпретацию. Ковариационные матрицы состояний $\Sigma_1,\dots,\Sigma_M$ используются для идентификации шоков, то есть они раскладываются аналогичным способом, как и в предыдущих моделях. 

При оценивании существуют некоторые дополнительные проблемы: число состояний волатильности должно быть определено, параметры полной модели должны быть оценены, диагональные элементы матрицы $\Psi_m$, $m=1,\dots,M$, должны быть сравнимы, и возможно идентифицирующие ограничения из обычного анализа должны быть тестированы внутри текущей структуры. При предположении оь условном нормальном распределении при заданных состояниях логарифмическая функция правдоподобия имеет вид
\begin{equation}\label{MS}
\log l_{MS}(W,\Psi_1,\dots,\Psi_M,P)=\sum_{t=1}^T{\log\left(\sum_{m=1}^M{\mathrm{Pr}(s_t=m|Y_{t-1})f(y_t|s_t=m,Y_{t-1})}\right)}
\end{equation}
где $P$ -- матрица переходных вероятностей, $Y_{t-1}=(y'_{t-1},\dots,y'_{t-p})'$ и
\[f(y_t|s_t=m,Y_{t-1})=(2\pi)^{-K/2}\det(\Sigma_m)^{-1/2}\exp\left\{-\frac{1}{2}u'_t\Sigma_m^{-1}u_t\right\}.\]
Для максимизации в \citep{HerwartzLutkepohl2011} предлагается соответствующий EM-алгоритм. К сожалению, этот алгоритм надежно работает только для относительно небольших систем с малым числом переменных $K$, малым числом состояний волатильности $M$ и с умеренным числом лагов $p$.

Статистическая проверка параметров матриц $\Psi_i$ может быть выполнена, используя стандартные процедуры. Например, раевнство некоторых параметров можно проверить стандарными тестами Вальда или LR. Однако последние тесты имеют недостаток в текущей ситуации, поскольку включают в себя две сложные процедуры максимизации функций правдоподобия. Следовательно, тесты Вальда может быть предпочтительнее с точки зрения вычислительной точки зрения. К сожалению, изветсно, что они имеют плохие свойства на конечных выборках в похожих ситуациях и, следовательно, могут не быть полностью удовлетворительными. В любом случае, в прицнипе, эти тесты могут использоваться для проверки условий идентифиации. Кроме того, если шоки могут идентифицироваться через структуру волатильности, другие ограничения можно также проверить обычными тестами. Для выбора между моделями с различным количеством режимов можно пользоваться стандартными критериями (см. \citep{PsaradakisSpagnolo2006}).

Когда структурная модель с идентифицируемыми шоками специфицирвоана, оан может исопльзоваться для структурного анализа. Импульсные отклики являются стандартной техников для этих целей. В классическом ML-анализе доверительные интервалы для импульсных откликов обычно порождаются методами бутстрепа. Ясно, что такие методы проблематичны, когда единственное оценивание сложно. Для уменьшения вычислительных проблем в \citep{HerwartzLutkepohl2011} предлагается процедура fixed design wild bootstrap. такая процедура имеет смысл в текущей модели, поскольку она может позаботиться об условной гетероскедастичности (см. \citep{GoncalvesKilian2004}). Бутстреп-выборки строятся условно на ML-оценки, исопльзуя
\[y_t^*=\hat{v}+\hat{A}_1y_{t-1}+\dots+\hat{A}_py_{t-p}+u_t^*.\]
Здесь переменные в правой стороне для заданного $t$ всегда являются оригинальными лагированными переменными, а ошибки $u_t^*=\eta_t\hat{u}_t$, где $\eta_t$ -- бинарная случайная величина, принимающая значения 1 или -1 с равной вероятностью. Процедура сохраняет гетероскедастичность и картину одновременной зависимости данных. В \citep{HerwartzLutkepohl2011} предлагаются бутстреп-оценки параметров $\theta^*$ для $\theta=\ve[v,A_1,\dots,A_p]$ и $W^*$ для $W$, условные на начлаьные оценки переходных вероятностей и $\Psi_i$, чтобы ограничить вычислительную нагрузку. Вычисление бутстреп-импульсных откликов требует нелинейной оптимизации логарифмической функции правдоподобия даже с этими упрощениями, что вычислительно затратно.

\subsubsection{SVAR с ненормальными ошибками}\label{MN}

В \citep{LanneLutkepohl2010} предлагается подход, в котором предположения о распределении ошибок могут помочь в идентификации шоков. Рассмотрим следующую приведенную форму VAR($p$):
\begin{equation}\label{MN1}
A(L)y_t=u_t,
\end{equation}
где предполагается, что $n$-мерный вектор ошибок $u_t$ являестя смесью двух серийно независимых нормальных случайных векторов, таких что
\begin{equation}\label{MN2}
u_t=
\begin{cases}
e_{1t}\sim N(0,\Sigma_1) &\text{с вероятностью $\gamma$,}\\
e_{2t}\sim N(0,\Sigma_2) &\text{с вероятностью $1-\gamma$.}
\end{cases}
\end{equation}
Предплагается, что $\Sigma_1\neq\Sigma_2$, поскольку в противном случае $\gamma$ не будет индентифицирована. Заметим, что $u_t\sim N(0,\gamma\Sigma_1+(1-\gamma)\Sigma_2)$. Рассмотрим так называемую $\mathsf B$-модель, то есть где $u_t=\mathsf B\varepsilon_t$ (хотя анализ может быть обобщен на случай $\mathsf{AB}$-модели). Существует альтернативный способ выбрать единственную матрицу $\mathsf B$. Существуют диагональная матрица $\Psi=\mathrm{diag}(\psi_1,\dots,\psi_n)$, $\psi_i>0$, $1=1,\dots,n$ и $(n\times n)$-матрица $W$, такие что $\Sigma_1=WW'$ и $\Sigma_2=W\Psi W'$, и $W$ являестя единственной, за исключением случая изменения всех знаков в столбце, при условии что все $\psi_i$ различны. Поэтому мы можем перепараметризовать $\Sigma_u$ как
\[\Sigma_u=W(\gamma I_K+(1-\gamma)\Psi)W'.\]
В этом случае мы находим (локально) единственную матрицу $\mathsf B=W(\gamma I_K+(1-\gamma)\Psi)^{1/2}$. Если смешанное нормальное распределение представляет данные из двух различных режимов, такой выбор $\mathsf B$ приводит к ортогональности шоков к обоим режимам, в который они входят, $N(0,\Sigma_1)$ или $N(0,\Sigma_2)$, и, конечно, $\varepsilon_t$ имеет единичную ковариационную матрицу. Локальная идентификация -- это все, на что мы можем надеяться в моделировании SVAR, поскольку все знаки в столбце $\mathsf B$ могут всегда измениться без изменения произведения $\mathsf B\mathsf B'$. 

Заметим что идентификация достигается путем использования только специфической структуры ковариационной матрицы. Такая структура также получается, конечно, если смешаны любые два распределения с нулевыми средними и ковариационными матрицами $\Sigma_1$ и $\Sigma_2$. Предположение о смешанном нормальном рапсределении сделано просто для удобства, так как это делает легким оценивание. 

Данный подход позволяет использовать чисто статистический подход, чтобы не делать предположение о том, что существуют нефундаментальные шоки. Интерпретация ошибок как смеси двух нормлаьных рапсределений может быть поянтна, если предположить, что ненормальность распределения исходит из-за, например, выбросов, то есть два режима отличаются друг от друга волатильностью. Наличие нефундаментальных шоков в данном подходе можно отдельно проверять, например, LR-тестом. 

Предположим, что у нас есть $m$ шоков, которые идентифицируются непосредственно накладывая огарничения на матрицу $\mathsf B$ и предположим, что, без потери общности, что они устанавливаются в последних $m$ позициях в $\varepsilon_t$. Тогдя для точной идентификации всех шоков в разложении $\Sigma_2=W\Psi W'$ с $\Psi=\mathrm{diag}(\psi_1,\dots,\psi_n)$ только первые $n-m$ значений $\psi_i$ должны быть различными. если некоторые из $m$ значений $\psi_i$ также различны, шоки фактически сверхидентифицируемы. В этом случае можнотестировать ограничения до тех пор, пока шоки остаются идентифицируемы при нулевой гипотезе.

Для оценивания параметров данной модели строится функция правдоподобия, в которой плотности являются просто линейной (по вероятностям) комбинацией соответствующих плотностей для каждого из режимов. Более конкретно, мы оцениваем параметры $\gamma$, $\Psi$ и $W$ путем макимизации псевдоконцентрированной функции правдоподобия
\begin{equation}\label{MN3}
L_{MN}(W,\Psi,\gamma)=\prod_{t=1}^T{f_{t-1}}(y_t),
\end{equation}
где 
\begin{multline}
f_{t-1}(y_t)=\gamma\det(W)^{-1}\exp\left\{-\frac{1}{2}(A(L)y_t)'(WW')^{-1}(A(L)y_t)\right\}\\
+(1-\gamma)\det(\Psi)^{-1/2}\det(W)^{-1}\exp\left\{-\frac{1}{2}(A(L)y_t)'(W\Psi W')^{-1}(A(L)y_t)\right\}
\end{multline}

Данный подход также использовался в \citep{LanneLutkepohl2008b}, где предлагается на первом шаге оценить VAR($p$)-модель, получить остатки (поскольку оценки удут состоятельными), а затем полученные остатки $\hat{u}_t$ подставить в функцию правдоподобия \eqref{MN3} вместо $A(L)y_t$. 

В целом, подход, использующий ненормальные ошибки, аналогичен предыдущему подходу, использующему информацию о сдвиге в волатильности, только в последнем подходе режимы изменяются в некоторый фиксированный момент времени, в то время как в подходе с ненормальными ошибками режимы регулируются случайным механизмом.

\subsection{Критика анализа импульсных откликов}

Помимо спецификации соответствующих импульсов в системе, существует некоторое количество других проблем, которые делают сложным интерпретацию импульсных откликов. главное ограничение нашей системы заключается в ее потенциальной неполности. Хотя в реальной экономической системн почти все всегда зависит от всего, мы обычно работаем в VAR-системе небольшой размерности. Все эффекты пропущенных переменных предполагаются содержащимися в инновациях. Если важная переменная пропущена в системе, это может привести к существенным искажениям импульсных откликов и делает их бесполезными для структурных интерпретаций. Однако, система может все еще быть полезной для предсказания.

Чтобы видеть связанные с этим проблемы более ясно, рассмотрим систему $y_t$, которая разивается на векторы $z_t$ и $x_t$
%
. Если рассматрвиаются только переменные $z_t$, а переменные $x_t$ пропущены, мы получаем систему
\begin{eqnarray}
z_t &=& \mu_1+\sum_{i=0}^\infty{\Phi_{11,i}u_{1,t-i}}+\sum_{i=0}^\infty{\Phi_{12,i}u_{2,t-i}}\notag \\
&=& \mu_1+\sum_{i=0}^\infty{F_iv_{t-i}}.\label{IR18}
\end{eqnarray}
Фактические реакции компонент $z_t$ на инновации $u_{1t}$ могут быть заданы матрциами $\Phi_{11,i}$. С другой стороны, $F_i$ или соответствующие ортогонализованные ``импульсные отклики'' вероятно будут интерпретироваться как импульсные отклики, если исследователь не понимает, что пропущены важные переменные. Здесь $F_i$ будет равна $\Phi_{11,i}$, если и тлько если $x_t$ не является причинyой по Гренджеру для $z_t$.

Дальнейшие проблемы, связанные с интерпретацией MA-коэффициентов как динамических мультипликаторов или импульсных откликов, получаются из-за ошибок измерения и использования сезонно скорректированных или временно и/или одновремено агрегированных переменных. Детальное изложение пробелмы агрегирования дано в \citep{Lutkepohl1987}. Эти проблемы существенно ограничивают интерпретируемость MA-коэффициентов VAR-системы как импульсных откликов. 

\section{Структурные VECM-модели}

Интегрированные и коинтегрированные системы нужно интерпретировтаь с осторожностью. В коинтегрированной системе принято считать, что коинтегрирующий вектор $\beta'y_t$ (который, напомним, должен быть стационарной линейной комбинацией) обычно представляет долгосрочное равновесное соотношение между переменными. Предположим, что существует только одно такое соотношение, скажем
\[\beta_1y_{1t}+\dots+\beta_Ky_{Kt}=0,\]
или, если $\beta_1\neq 0$,
\[y_{1t}=-\frac{\beta_2}{\beta_1}y_{2t}-\dots-\frac{\beta_K}{\beta_1}y_{Kt}.\]
Очень хотелось бы утверждать, что долгосрочный эффект единичного увеличения в $y_2$ будет изменять $y_1$ на величину $\beta_2/\beta_1$. Это, однако, игнорирует все другие соотношения между переменными в VAR($p$) или соответствующей VECM. Елинчиная инновация в некоторый момент времени в $y_2$ может влиять на различные другие переменные, которые также имеют влияние на $y_1$. Следовательно, долгосрочный эффект инноваций в $y_2$ на $y_1$ может достаточно отличаться от $-\beta_2/\beta_1$. Импульсные отклики могут давать лучшую картину соотношений между переменными.

В Разделе \ref{SVAR} было показано, что импульсные отклики стационарного и стабильного процесса VAR($p$) являются коэффициентами конкретных MA-представлений. Нестабильный, интегрированный или коинтегрированный процесс VAR($p$) не обладает обоснованными MA-предс\-тав\-ле\-ни\-ями, представленными в Разделе \ref{SVAR}. Несмотря на это матрицы $\Phi_i$ и $\Theta_i$ могут быть вычеслены, как и ранее, и элементы матрицы $\Phi_i$ -- $\phi_{jk,i}$ -- могут редставлять импульсные отклики, как и в случае стабильности. Но в стабильных процессах отклики затухают с течением времени ($i\rightarrow\infty$), однако, это свойство не выполняется для нестабильных систем, в которых влияние импульса в некоторый момент времени не затухает асимптотически. Аналогично можно вычислять и накопленные импульсные отклики ортогонализованным остаткам и декомпозиции дисперсии ошибок прогноза, кроме полных ``долгосрочных эффектов'', или полных мультипликаторов, $\Psi_\infty$ и $\Xi_\infty$, поскольку они могут не быть конечными (например, стабильность требуется для ограничений Бланшара-Кваха, поскольку матрица $(I_K-A_1-\dots-A_p)$ является вырожденной для коинтегрированных процессов). Другими словами, мы можем даже специфицировать и оценить VECM в приведенной форме, преобразовать эту модель в модель VAR в уровнях, а затем использовать ее как основу для $\mathsf{AB}$-анализа, как обсуждалось в Разделе \ref{AB}. Однако существуют некоторые недостатки этго подхода. %Есть, однако, преимущества в использовании коинтеграционных свойств переменных. Они дают ограничения, которые могут быть выгодно приняты во внимание в идентификации структурных шоков. Следовательно, полезно отдельно рассматривать SVECM-модель.

В \citep{Phillips1998} были получены следующие результаты. Пусть процесс $y_t$ не является стабильным, то есть имеет корни вне или на единичной окружности. Тогда если горизонт для импульсных откликов предполагается фиксированным, то функции импульсных откликов остаются состоятельными и асимптотически нормальными, как и в случае стабильных VAR. Однако асимптотическая ковариационная матрица оцененных коэффициентов VAR будет вырожденной, поскольку только стационарные компоненты системы имеют $\sqrt{T}$-асимптотику. Однако, если задвать горизон прогноза как $i/T\rightarrow0$ при $T,i\rightarrow\infty$ или как $i=fT$, где $f>0$ -- фиксированная доля от выборки, то при наличиие единичных корней или почти единичных корней (near unit roots) в VAR импульсные отклики, оцененные неограниченной OLS-регрессией, будут несостоятельными. В частности, пределы оцененных откликов будут некоторыми случайными величинами, а не истинными импульсными откликами. Это может показаться удивительным, поскольку наличие единичных корней или почти единичных корней ускоряет сходимость оценок коэффициентов в OLS-регрессии, и на основе этого можно ожидать, что импульсные отклики будут сходиться ыстрее в некоторых направлениях. Причина несостоятельности заключается в том, что истинные импульсные отклики больше не затухают при увеличении горизонта, то есть элементы $\Theta_i$ в \eqref{AM1} не стремятся к нулю при $i\rightarrow\infty$, но несут эффекты единичных корней с их бесконечностью. Однако единичные корни, оцененные с ошибкой, и эффекты оценивания сохраняется в приделе при $n\rightarrow\infty$, когда рассматриваются долговременные импульсы $\Theta_i$, где $i$ -- некоторая доля ($f$) от объема выборки ($T$). В отличие от этого, когда система стабильна, элементы $\Theta_i$ стремятся к нулю при $i\rightarrow\infty$, и оцененные ошибки не оказывают влияния в пределе. То есть результат Филлипса охватывает случай стабильных VAR.

Если мы оценивиаем импульсные отклики в коинтегрированной VAR-модели, то они будут состоятельными на краткосрочных и долгосрочных горизонтах, если ранг коинтеграции выбирается состоятельной процедурой. На долгосрочных горизонтах щоки будут иметь инерционный эффект на систему бесконечно в будущее. Именно эти инерционные эффекты состоятельно оценвиаются регрессией с пониженным рангом (reduced rank regression, RRR). Если в системе присутствуют почти единичные корни, регерссия с пониженным рангом ошибочно принимает близкие к единице корни как единичные корни при росте выборки. То же самое остается верным, когда исопльзуются информационные критерии для выбора ранга коинтеграции. Таким образом, долговременные импульсные отклики несостоятельно оцениваются, когда существую почти единичные корни. Предельное расgределение этих оцененных импульсов, однако, все еще нормально. Это распределение обладает нежелатиельным свойством, которое заключается в том, что асимптотические дисперсии расходятся при $i\rightarrow\infty$. Это довольно озадачивает в связи с тем, что истинные матрицы импульсных откликов сходятся к фиксированным матрицам при $i\rightarrow\infty$, и мпульсные отклики, оцененные в регрессии с пониженным рангом, являюстя состоятельными. В \citep{AraiYamamoto2000} предлагается альтернативное представление асимптотического рапсределения RRR-оценок импульсных откликов со сходящимися асимптотическими дисперсиями для коинтегрированных VAR-систем. Получение близко следует \citep{Phillips1998}, за исключением того факта, что авторы явно используют тот факт, что $n=K-r$ единичных корней не оценевается RRR, где $K$ -- размерность системы, а $r$ -- ранг коинтеграции.

Также Филлипс показал, что оцененная матрица дисперсии ошибки прогноза из оцененной неограниченной VAR с некоторыми корнями, близкими или равными единице, ведет себя как случайная матрица, умноженная на горизонт прогноза $h$, а не как постоянная матрица, умноженная на $h$. Таким образом, оцененные матрицы дисперсий ошибок прогноза в долгосрочном плане в неограниченной VAR являются несостоятельными. Тот же самый результат следует для соответствующих оценок разложений дисперсий ошибок прогноза. Кроме того, предсказание по неограниченной VAR-регрессии не являесят асимптотически оптимлаьным в том смысле, что предсказания не сходятся к оптимлаьным предикторам, по крайней мере на длиных горизонтах прогноза. Этот результат являестя полностью противоположным стационарной VAR-модели, где ошибки от оценивания коэффициентов не влияют асимптотически, и разница между доступным и оптимлаьным прогнозами стремится к нулю при $T\rightarrow\infty$.

Если оценивается регрессия в пониженным рангом, то разложение дисперсий ошибок прогноза для фиксированного горизонта имеет ту же самую предельную теорию, как и неограниченная VAR. Но когда горизонт прогноза стремится к бесконечности с ростом выборки, регрессия с пониженным рангом продолжает быть состоятельной, в отличие от неограниченной VAR, которая несостоятельна и имеет случайные пределы. Прогнозы в этом случае дял корректно специфицированной модели будут асимптотически эквивалентными оптимальному предиктору. Однако, когда в системе есть почти единичные корни вместо единичных корней, прогнозы по регрессии с пониженным рангом не будут больше асимптотически эквивалентными оптимальному предиктору.

Мы предполагаем, что все переменные по крайней мере I(1), и что процесс порождения данных может быть представлен как VECM с рангом коинтеграции $r$ в виде
\begin{equation}\label{ECM1}
\Delta y_t=\vc{\alpha}\vc{\beta}'y_{t-1}+\vc{\Gamma}_1\Delta y_{t-1}+\dots+\vc{\Gamma}_{p-1}\Delta y_{t-p+1}+u_t,
\end{equation}
где все символы имеют свое стандартное значение. Другими словами, $y_t$ является $K$-мерным вектором наблюдаемых переменных, $\vc{\alpha}$ -- матрица корректирующих коэффициентов размерности $(K\times r)$, $\vc{\beta}$ -- матрица коинтегрирующих векторов размерности $(K\times r)$, $\vc{\Gamma}_j$ -- матрица краткосрочных коэффициентов для $j=1,\dots,p-1$ размерности $K\times K$, и $u_t\sim(0,\Sigma_u)$ -- вектор ошибок.

Процесс \eqref{ECM1} по Теореме предствления Гренджера имеет следующее MA-представление типа Бевериджа-Нельсона
\begin{equation}\label{ECM2}
y_t=\vc{\Xi}\sum_{i=1}^t{u_i}+\sum_{j=0}^\infty{\vc{\Xi}_j^*u_{t-j}}+y_0^*=C(L)u_t,
\end{equation}
где $\vc{\Xi}_j^*$ абсолютно суммируемы, так что бесконечная сумма определена, компонента $y_0^*$ содержит начальные значения, а $C(L)$ -- некоторый полином. Абсолютная суммируемость $\vc{\Xi}_j^*$ подразумевает, что эти матрицы сходятся к нулю при $j\rightarrow\infty$. Таким образом, долгосрочные эффекты шоков охватываются компонентой общих трендов $\vc{\Xi}\sum_{i=1}^t{u_i}$. Матрица
\[\vc{\Xi}=\vc{\beta}_{\perp}\left[\vc{\alpha}'_{\perp}\left(I_K-\sum_{i=1}^{p-1}{\vc{\Gamma}_i}\right)  \vc{\beta}_{\perp}\right]\vc{\alpha}'_{\perp}\]
имеет ранг $K-r$. Таким образом, существует $K-r$ общих трендов, и если инновации, embodied in the $u_t$, могут быть восстановлены, самое большее $r$ из них могут иметь преходящее влияние, только потому что матрица $\vc{\Xi}$ или ее невырожденное преобразование не могут иметь более $r$ нулевых столбцов. Таким образом, зная ранг коинтеграции системы, мы уже знаем максимальное число преходящих шоков.

В этом контексте в центре внимания, как правило, остатки и, следовательно, для того чтобы определить структурные инновации обычно используется анализ $\mathsf B$-модели. Другими словами, мы ищем матрицу $\mathsf B$, такую что
\[u_t=\mathsf B\varepsilon_t\quad\text{c}\quad\varepsilon_t\sim(0,I_K).\]
Подставление этого соотношения в компоненту общих трендов дает $\vc{\Xi}\mathsf B\sum_{i=1}^t{\varepsilon_i}$. Следовательно, долгосрочные эффекты структурных инноваций задаются матрицей $\vc{\Xi}\mathsf B$. Посколкьу структурные инновации представляют регулярный случайный вектор с невырожденной ковариационной матрицей, матрица $\mathsf B$ также невырождена. Вспомните, что $\Sigma_u=\mathsf B\mathsf B'$. Таким образом, $\mathrm{rk}(\vc{\Xi}\mathsf B)=K-r$ и может быть может быть не более $r$ нулевых столбцов в этой матрице. Другими словами, $r$ из структурных инноваций могут иметь преходящее влияние и $K-r$ из них могут иметь перманентное влияние. если есть $r$ преходящих шоков, мы можем ограничить $r$ столбцов в $\vc{\Xi}\mathsf B$, полагая их нулевыми. Поскольку матрица имеет пониенный ранг $K-r$, каждый нулевой столбец выступает только за $K-r$ независимых ограничений. Таким образом, $r$ преходящих шоков представляет только $r(K-r)$ независимых ограничений. Все еще полезно заметить, что ограничения могут быть наложены на основе нашего знания о ранге коинтеграции системы, который может быть определен статистическими способами. Однако, дальнейшие теоретические рассмотрения требуют накладывания дополнительных ограничений.

Для локальной точной идентифицируемости структурных инноваций в $\mathsf B$-модели нам нужно в общей сложности $K(K-1)/2$ ограничений. Предполагая, что существует только $r$ шоков с преходящими эффектами, мы уже имеем $r(K-r)$ ограничений из коинтеграционной структуры модели. Остается $\frac{1}{2}K(K-1)-r(K-r)$ дополнительных ограничений для точной идентифицируемости структурных инноваций. Фактически $r(r-1)/2$ дополнительных одновременных ограничений необходимо для распутывания преходящих шоков и $(K-r)((K-r)-1)/2$ ограничений для идентификации перманентных шоков (см., например, \citep*{KPSW1991} и \citep{GonzaloNg2001}). Затем у нас есть в общей сложности $\frac{1}{2}r(r-1)+\frac{1}{2}(K-r)((K-r)-1)=\frac{1}{2}K(K-1)-r(K-r)$ ограничений, как и требуется. Таким образом, недостаточно наложить произвольные ограничения на $\mathsf B$ или $\vc{\Xi}\mathsf B$, но мы должны выбрать их, чтобы идентифицировать преходящие и перманентные шоки по крайней мере локально. Фактически преходящие шоки могут быть только идентифицируемы через ограничения непосредственно на $\mathsf B$, посколкьу они соответствуют нулевым столбцам в $\vc{\Xi}\mathsf B$. Таким образом, должны ыть наложены на $\mathsf B$ непосредственно $r(r-1)/2$ ограничений. Как правило, ограничения имеют вид
\begin{equation}\label{ECM3}
C_{\vc{\Xi}\mathsf B}\ve(\vc{\Xi}\mathsf B)=c_l,\quad\text{или}\quad C_l\ve(\mathsf B)=c_l,\quad\text{и}\quad C_s\ve(\mathsf B)=c_s,
\end{equation}
где $C_l=C_{\vc{\Xi}\mathsf B}(I_K\otimes\vc{\Xi})$ являестя матрицей долгосрочных ограничений, то есть $C_{\vc{\Xi}\mathsf B}$ -- подходящая selection matrix , такая что $C_{\vc{\Xi}\mathsf B}\ve(\vc{\Xi}\mathsf B)$, а $C_s$ специфицирует краткосрочные или текущие ограничения, ограничивая элементы в $\mathsf B$ непосредственно. Здесь $c_l$ и $c_s$ -- векторы соответствующих размерностей. В прикладных работах они обычно являюстя нулевыми векторами. Другими словами, нулевые ограничения специфицированы в \eqref{ECM3} для $\vc{\Xi}\mathsf B$ и $\mathsf B$.

Как обсуждалось для стационарного случая в Разделе \ref{AB}, матрциа $\mathsf B$ будет только локально идентифицируема. в частности, в общем случае мы можем поменять знаки столбцов в $\mathsf B$, чтобы найти другую обоснованную матрицу. Формальное необходимое и достаточное условие для локальной идентифицируемости заключается в следующем. Предположим, что $\mathsf B$ невырожденная $(K\times K)$-матрица. Тогда множество уравнений
\[\Sigma_u=\mathsf B\mathsf B',\quad C_l\ve(\mathsf B)=c_l\quad\text{и}\quad C_s\ve(\mathsf B)=c_s\]
с $C_l$, $c_l$, $C_s$ и $c_s$ определенных как в \eqref{ECM3} имеют локально единственное решение для $\mathsf B$ тогда и только тогда, когда
\[\mathrm{rk}
\begin{bmatrix}
2\vc{D}_K^+(\mathsf B\otimes I_K)\\
C_l\\
C_s
\end{bmatrix}
=K^2.\]

Далее более детально рассмотрим подходы разделения перманентных и преходящих шоков. В \citep{GonzaloNg2001} (см. также \citep{Yang1998}) определяется $(K\times 1)$-вектор $\epsilon_t$, первые $K-r$ элементов которого являются перманентными шоками, а оставшиеся $r$ -- преходящими шоками, как $\epsilon_t=Gu_t$, где
\[G=\begin{bmatrix}
\alpha'_{\perp}\\
\beta'
\end{bmatrix}\]
и $\Sigma_\epsilon=G\Sigma_uG'$. Предполагается, что $(p\times p)$-матрица $G$ имеет полный ранг. Долгосрочная матрица вклада перманентных-преходящих шоков $\epsilon_t$ равна $\vc{\Xi}G^{-1}=C(1)G^{-1}$. Легко показать, что последние $r$ вектор-столбцов этой долгосрочной матрицы вклада нулевые, замечая что
\[G^{-1}=[\vc{\beta}_{\perp}(\vc{\alpha}'_{\perp}\vc{\beta}_{\perp})^{-1} \ \vc{\alpha}(\vc{\beta}'\vc{\alpha})^{-1} ],\]
как и требуется для перманентного-преходящего разложения. Далее применяется дополнительное преобразование для ортогонализации перманентных-преходящих шоков:
$\varepsilon_t=H^{-1}\epsilon_t=H^{-1}G\varepsilon_t,$
где $H$ -- единственная нижнетреугольная матрица, такая что $HH'=G\Sigma_uG'$. Другими словами, $\mathsf B=G^{-1}H$, и ортогонализованная матрциа вклада перманентны-преходящих шоков будет равна $\vc{\Xi}\mathsf B=\vc{\Xi}G^{-1}H$. P-T разложение сохраняется, поскольку умножение $\vc{\Xi}G^{-1}$ на нижнетреугольную матрицы приводит к матрице, все последние $r$ вектор-столбцов которой нулевые.

В \citep{FisherHuh2007} доказываестя следующее утверждение. Предположим, что существует $K-r$ слабо экзогенных переменных относительно коинтегрирующего вектора, и они упорядочены таким образом, чтобы быть первыми в векторе $y_t$. Тогда ортогонализованные шоки, полученные непосредственно из VECM накладыванием рекурсивной структуры на одновременные вклады ошибок составляют P-T разложение, где перманентные шоки идентичны P-T разложению \citep{GonzaloNg2001}. В дополнение, когда существует только одно коинтеграционное соотношение ($r=1$), ортогонализованные шоки, полученные путем накладывания одновременной рекурсивной структуры на ошибки VECM, идентичны P-T разложению \citep{GonzaloNg2001}. Также, если существует $0<j<K-r$ слабо экзогенных переменных отосительно коинтеграционного вектора, и они упорядочены быть первыми в $y_t$, то ортогонализованные шоки, полученные путем накладывания одновременной рекурсивной структуры на ошибки VECM не составляют P-T разложение; первые $j$ из этих шоков идентичны первым $j$ перманентным шокам в P-T разложении \citep{GonzaloNg2001} (см. также \citep{FisherHuh1999} где доказывается, что если у нас есть  $0<j<K-r$ слабо экзогенных переменных, то $r$ структурных шоков с преходящими эффектами не имеет одновременного вклада на эти $j$ слабо экзогенные переменные).

В \citep{Lutkepohl2008} утверждается, что дополнительные сверхидентифицирующие ограничения нужно накладывать с осторожность, поскольку некоторые из них невозможны из-за того, что они приводят к вырожденной ковариационной матрице остатков, котоаря обычно исключается из предположения, а также неправдоподобна с теоретической точки зрения. Другими словами, некоторые сверхидентифицирующие огарничения мгут не быть возможными, посоклкьу они будут вне допустимого постранства параметров. Поэтому соответствующие $t$-статистики не могут интерпретироваться обычным способом. Эта проблема влияет также и на импульсные отклики. Автор приводит следующее утверждение. Предположим, что в ECM матрица $\vc{\alpha}_{\perp}$ размерности $(K\times (K-r))$ такова, что все множества $K-r$ строк являются невырожденными $((K-r)\times(K-r))$-матрциами, и существует $r^*\leq r$ преходящих шоков. Тогда число допустимых нулевых ограничений, размещенных на столбце в $\mathsf B$, связанных с преходящим шоком, не может быть более $r-1$. Например, если ранг равен 1 (и один преходящий шок)), в столбце в матрице $\mathsf B$ не может быть ни одногоо ограничения. Если ранг равен 2 (и два преходящих шока), то может быть самое большее одно нулевой ограничение в каждом из двух столбцов в $\mathsf B$, соответствующих преходящим шокам. Условие, что матрица $\vc{\alpha}_{\perp}$ такова, что все множества $K-r$ строк являются невырожденными $((K-r)\times(K-r))$-матрциами, будет всегда удовлетворяться, если $\alpha$ оценивается без ограничений. Однако при наличии слабо экзогенных переменных полученное утверждение не будет выполняться, и преходящие шоки не будут иметь одновременный эффект на слабо экзогенные переменные (см. \citep{FisherHuh1999}).

Аналогичное свойство будет наблюдаться для ограничений на матрицу $\vc{\Xi}\mathsf B$. Предположим, что $((K-r)\times(K-r))$-субматрицы $\vc{\beta}_{\perp}$ невырождены, и есть $r$ преходящих шоков. Тогда число допустимых нулевых ограничений размещенных на столбце в $\vc{\Xi}\mathsf B$, связанных с перманентным шоком, не может быть более $K-r-1$.

В \citep{Lucke2010} было получено обобщение подхода \citep{Lutkepohl2008}, которое выполняется независимо от того, являются ли некоторые структурные шоки преходящими: при структурном разложении $K-r$ столбцов матрицы $\vc{\Xi}\mathsf B$ допускают самое большее $K-r-1$ нулевых ограничений каждое; оставшиеся $r$ столбцов допускают вплоть до $K$ нулевых ограничений каждое, из которых не более $K-r$ линейно независимы. Также предположим, что максимально допустимое число нулевых ограничений накладывается на $\vc{\Xi}\mathsf B$. Тогда структурная идентификация для \eqref{ECM1} требует дополнительных нулевых ограничений на $\mathsf B$ тогда и только тогда, когда $2r>K$.

Относительно дополнительных ограничений на матрицу $\mathsf B$ в \citep{Lucke2010} доказывается следующий результат. Предположим, что в структурном разложении \eqref{ECM1} существует $z\leq K$ нулевых ограничений, накладываемых на определенные столбцы матрицы $\vc{\Xi}\mathsf B$. Пусть $v=\min\{z,K-r\}$. Если из $z<K-r$ следует, что все множества $(v\times v)$-субматриц в $\vc{\Xi}$ невырожденные, и если из $z>K-r$ следует, что все множества $(v\times v)$-субматриц в $\vc{\alpha}_{\perp}$ невырождены, то самое большее $K-v-1$ нулевых огарничений допускается на соответствующий столбец в $\mathsf B$.

\subsubsection{Оценивание и построение доверительных интервалов}

Предположим теперь, что ограничения для VECM заданы в форме линейных ограничений на $\vc{\Xi}\mathsf B$ и $\mathsf B$, как в \eqref{ECM3}. Для вычисления оценок параметров мы можем заменить $\vc{\Xi}$ на ее ML-оценку приведенной формы,
\[\tilde{\vc{\Xi}}=\tilde{\vc{\beta}}_{\perp}\left[\tilde{\vc{\alpha}}'_{\perp}\left(I_K-\sum_{i=1}^{p-1}{\tilde{\vc{\Gamma}}_i}\right)  \tilde{\vc{\beta}}_{\perp}\right]\tilde{\vc{\alpha}}'_{\perp},\]
где $\tilde{\vc{\Gamma}}_i$ -- ML-оценки параметров $\vc{\Gamma}_i$, а $\tilde{\vc{\alpha}}_{\perp}$ и $\tilde{\vc{\beta}}_{\perp}$ -- ортогональные дополнения ML-оценок $\tilde{\vc{\alpha}}$ и $\tilde{\vc{\beta}}$, соответственно. Ограниченная ML-оценка для $\mathsf B$ может быть получена, полагая $\mathsf A=I_K$ и оптимизируя концентрированную функцию логарифмического правдоподобия \eqref{est3} с заменой $C_l$ на
\[\tilde{C}_l=C_{\vc{\Xi}\mathsf B}(I_K\otimes\tilde{\Xi})\]
(см. \citep{Vlaar2004}). Хотя эта процедура приводит к множеству стохастических ограничений, с численной точки зрения у нас есть стандартная оптимизационная задача с ограничениями, которую можно решить, исопльзуя подход Лагранжа, поскольку $\tilde{\vc{\Xi}}$ фиксирована в вычислении оценки для $\mathsf B$. Из-за того факта, что для точно идентифицированной структурной модели максимум логарифма правдоподобия тот же самый, что и для приведенной формы, сранвение значений логарифма правдоподобия может служить проверкой  надлежащей сходимости алгоритма оптимизации, используемого для структурного оценивания.

Свойства ML-оценки для $\mathsf B$ аналогично случаю SVAR-моделей. Другими словами, $\tilde{\mathsf B}$ является состоятельной и асимптотически нормлаьной при стандартных условиях,
\[\sqrt{T}\ve(\tilde{\mathsf B}-\mathsf B)\stackrel{d}{\longrightarrow}N(0,\Sigma_{\mathsf B}).\]
асимптотическое распределение являестя вырожденным из-за ограничений, которые наложены на $\mathsf B$. Таким образом, хотя $t$-отношения могут быть использованы для оценки значимости индивидуальных параметров, $F$-тесты, основанные на принципе Вальда, не будут в общем случае обоснованы и должны быть интерпретированы с осторожностью. Выражения для ковариационных матриц асимптотических распределений в терминах параметров модели могут быть получены обычным способом, используя соответствующие информационные матрицы (см. \citep{Vlaar2004}). Для практических целей распространенным способом является использование методов бутстрепа для статистических выводов в данном контексте.

В принципе, можно использовать аналогичный подход, если есть сверхидентифицирующие ограничения на $\mathsf B$. В этом случае $\tilde{\mathsf B}\tilde{\mathsf B}'$ не будет равно ковариационной матрицы оценки приведенной формы $\Sigma_u$, однако. Оценка $\mathsf B$ будет все еще состоятельной и асимптотически нормальной при более общих условиях, а также LR-статистика, заданная в \eqref{est6} может использоваться для проверки правильности сверхидентифицирующих ограничений. Она будет иметь обычное асимптотическое распределение $\chi^2$ с числом степеней свободы, равному числу сверхидентифицирующих ограничений.

Свойства доверительных интервалов для импульсных откликов SVECM на конечных выборках были анализированы в \citep{Bruggemann2006}. На основе симуляций Монте-Карло автор показал, что нет большой разницы между асимптотическими интервалами и процентильными бутстреп-интервалами Холла в SVECM с долгосрочными ограничениями. В отличие от этого стандартный процентильный бутстреп-интервал может быть менее подходящим в прикладных работах, так как он менее информативен о знаке лежащей в основе функции импульсного отклика. Сравнения доверительные интервалы для откликов на перманентные шоки, автор обнаружил, тчо асимптотические и процентильные бутстреп-интервалы Холла имеют похожую норму покрытия и указывают на правильный знак лежащего в основе отклика одинаково часто. Следовательно, они допускают одинаковую интерпертацию. Однако бутстреп-интервалы обычно асиммметричны и намного более широкие. В отличие от этого стандатные бутстреп-интервалы включают нулевую линия чаще, и, следовательно, указывают корректный знак реже. Для откликов на преходящие шоки доверительные интервалы имеют гораздо больше общего. Однако автор не рекомендует исопльзовать стьюдентизированные интервалы Холла из-за их вычислительных требований.

\subsubsection{SVECM с ненормальными ошибками}

Аналогично разделу \ref{MN} рассмотрим аналогичную идентификацию для VECM. Предположим, что накладываюстя только ограничения, связанные с разделением перманентных и преходящих шоков в матрице $\vc{\Xi}\mathsf B$, то есть последние $r$ столбцов в этой матрице нулевые и связаны с преходящими шоками. Тогда шоки будут идентифицирвоаны, если $u_t$ имеет смешанное нормлаьное распределение как в \eqref{MN2} с ковариационными матрицами $\Sigma_1=WW'$ и $\Sigma_2=W\Psi W'$, где $\psi_1,\dots,\psi_{n-r}$ различны, а также $\psi_{n-r+1},\dots,\psi_{n}$ различны. 

Заметим, что в VECM с рангом коинтеграции $r<K$ все структурные шоки могут быть, в прицнипе, перманентными, поскольку матрица $\vc{\Xi}\mathsf B$ может не иметь нулевых столбцов, даже если она и имеет пониженный ранг. Рассмотрение $r$ шоков как преходящих являестя предположением, которое в идеали не основано исключительно на ранге коинтеграции. Поэтому, если $u_t$ является fully general смешанным нормальным, как в \eqref{MN2}, нулевые ограничения на $\vc{\Xi}\mathsf B$ фактически являются сверхидентифицирующими, которые можно тестировать, например, LR-тестом. Другими словами, можно тестировать число перманентных и преходящих шоков, в том числе и последовательной процедурой, начиная с $H_0: r^*=r$ и заканчивая $H_0: r^*=1$. Тестовая последовательность останавливается и число преходящих шоков выбирается тогда, когда одна из нулевых гипотез не отвергается.

Для оценивания такой модели на первом шаге используется регрессия пониженного ранга Йохансена \citep{Johansen1996} для оценвиания коинтеграционных соотношений. Эти оценки эквивалентны ML для гауссовской модели, но являюстя квази-ML при смешанном нормальном распределении. На втором шаге мы можем тогда использовать условие на оцененные коинтеграционные соотношения и максимизировтаь функцию правдоподобия относительно других параметров.



\section{Система динамических одновременных уравнений}

\section{Байесовские SVAR и SVECM}

\chapter{Обзор литературы по эмпирическим приложениям SVAR}



\chapter{Эмпирика по российским данным}

\chapter*{Заключение}
\addcontentsline{toc}{chapter}{Заключение}
\markboth {\scshape Заключение}{\scshape Заключение}


\newpage
\thispagestyle{empty}

\renewcommand{\bibname}{Литература}
\addcontentsline{toc}{chapter}{Литература}
\markboth {\scshape Литература}{\scshape Литература}
\newpage

\bibliographystyle{OUPnamed}
\bibliography{svar}%bibliography,nonlinear,explosive,

\end{document}