\newcommand{\hb}{\hat\beta}
\newcommand{\Var}{\mathbb{V}\mathrm{ar}}

bmr

* Normal-inverse-Wishart Prior
* Minnesota Prior
  * (Koop and Korobilis, 2010, p. 7) version
  * (Canova, 2007, p. 378) version
    * harmonic decay d(l)=l^{H_4}
    * geometric decay d(l)=H_4^{1-l}
* steady state prior


Eviews:

* Litterman/Minnesota prior. (koop korobilis version) v
* Normal-Wishart prior. v
* Sims-Zha Normal-Wishart prior.
* Sims-Zha Normal-flat. v
* Diffuse prior
? conjugate Normal-Wishart


http://www.ihs.ac.at/vienna/resources/Economics/Papers/20120426_Slides_Giannone.pdf
* Minnesota prior (Litterman, 1980 and 1986)
* Inverse-Wishart prior on \Sigma
* Sum-of-coefficients prior (Doan, Litterman and Sims 1984)
* Single-unit-root prior (Sims, 1993)

http://personal.strath.ac.uk/gary.koop/kk3.pdf
Gary Koop (from bvar_full)
* Diffuse (Jeffreys) (MC integration)
* Minnesota (MC integration)
* Normal-Wishart (MC integration)
* Independent Normal-Wishart (Gibbs)
* SSVS in mean - Wishart (Gibbs)
* SSVS in mean - SSVS in in covariance (Gibbs)
SSVS -- Stochastic Search Variable Selection

y_t=a_0+A_1 y_{t-1} + \varepsilon_t


http://www.ecb.europa.eu/events/pdf/conferences/schorfheide.pdf
* Priors from General Equilibrium Models for VARs

Обозначения:
y_t=\Phi_0+\Phi_1 y_{t-1} +u_t



msbvar:

szbvar:

* Sims-Zha Normal-Wishart prior
* Sims-Zha Normal-flat prior
* (?) flat-flat prior

szbsvar

* "model described by Sims and Zha (1998) and Waggoner and Zha (2003)"


уже начатая статья, $y_t=v+A_1 y_{t-1} + \ldots + u_t$





Sims, C.A. and Tao A. Zha. 1998. "Bayesian Methods for Dynamic Multivariate Models." International Economic Review. 39(4):949-968.

Waggoner, Daniel F. and Tao A. Zha. 2003a. "A Gibbs sampler for structural vector autoregressions" Journal of Economic Dynamics \& Control. 28:349–366.

Waggoner, Daniel F. and Tao A. Zha. 2003b. "Likelihood preserving normalization in multiple equation models". Journal of Econometrics. 114: 329–347.

Brandt, Patrick T. and John R. Freeman. 2006. "Advances in Bayesian Time Series Modeling and the Study of Politics: Theory Testing, Forecasting, and Policy Analysis". Political Analysis 14(1):1-36.


Протокол:

1. Сезонная корректировка
2. Взятие логарифмов для всех переменных, исключая те, что выражены  в процентах.
3. Проверка на стационарность для определения априорного  матожидания (опционально. Carriero этого вообще не делает)
4. Формируем выборки с 3, 5, 7, 15 и 23 переменными
5. Оценивать нужно RW, VAR(3)=BVAR(\lambda=\infty), VAR(5), BVAR_ Minnesota, сопр. N-IW
6.  Количество лагов для  BVAR выбираем путем максимизации marginal density. Лаги смотрим от 1 до 12. Первая точка в обучающей выборке – январь 1996, количество исходных наблюдений – 150, выборка не меняется с изменением числа лагов. Второй вариант – количество исходных наблюдений – 200. Из любопытства можно сравнить выбранное предпочитаемое количество лагов с результатом минимизации информационных критериев.
7.  Подсчет \lambda по банбуровской схеме.  Процентную ставку во внимание не принимаем (хотя, как мы выяснили, она не вредная, но и не полезная)
8 Подсчет \lambda_1 путем максимизации marginal density. Можно по отдельности, можно максимизировать одновременно по \lambda_1 и по p.  \lambda_2  надо ставить равным 1. А по \lambda_3 и, возможно,  \lambda_4 можно оптимизировать. Вопрос, хватает ли для этого данных?
9. Прогнозы строим на 1,3, 6, 9 и 12 месяцев. Считаем темп роста прогнозируемых переменных (можно начать с прироста IP   и инфляции, потом, если результаты будут приятными, можно расширить число прогнозируемых переменных).
10. Сдвигаем наблюдения на единицу и делаем то же, что в п. 9. Количество наблюдений в выборке всегда 150. Последнее прогнозируемое наблюдение – апрель 2015, количество прогнозов на 1 период будет больше, чем на 3, а прогнозов на 3 будет больше, чем на 6
11. Считаем MSFE по всем прогнозам, делаем выводы.
12.  Потом решаем, что были глубоко неправы везде, где можно. Возвращаемся и переделываем.


о матрицах:

- svd, Schur, QR, ...
- разобраться с Муром-Пенроузом псевдообратной (решить пару примеров, свойства)
- разобраться с разложением Холецкого (решить пару примеров, свойста)

о классификации:

- отличие Сим-Жа от сопряженного нормального-Вишарта? похоже, что Сим-Жа более общий случай
- при каких априорных параметрах апостериорное среднее совпадёт с ML VAR?
будет ли это неинформативное-Джеффри?


мелочи:

- у банбуры пока идет речь о подборе лямбды все msfe --- in-sample

дизайн пакета:

priors <- bvar_priors(type="conjugate", style/spec="carriero", Y, p=4, lambdas=c(.....))
model <- bvar_estimate(priors)
summary(model)
пример тестов из coda:

forecast(model, h=)
forecast(model, out-of-sample=FALSE)


потестить:

- bvar optimal и var-3 (ок для fast_forecast)
- без fast_forecast
- при добавлении искуственных наблюдений (просто, а также sc, io) какое T брать при
преобразовании v_post=v_prior + T

# 19 августа 2015
18:51 возможная причина ошибки: у BVAR-3 n_lag=1 omsfe резко растут при переходе с h=1 до h=2 (ok, поймали ошибку: не надо копировать прошлый x_t при h>1)
19:17 добавить названия строк/столбцов в colnames/rownames Phi (ok)
сделать colnames/rownames Omega

# 20 августа 2015
13:01 сделать оценку VAR с автоподбором лагов (ok)
13:02 сделать табличку как у банбуры стр. 79 (ok)
18:09 сделать так, чтобы пользователь мог не вносить в априорный список вспомогательные
элементы
http://stackoverflow.com/questions/7719741/how-to-test-if-list-element-exists
18:45 сверить теоретическое апостериорное среднее и выборочное --- (ок)

# 21 августа 2015
* 0:25 сравнить средние коэффицинты: аналитическое апостериорное, выборочное среднее при двух способах генерировать коэффициенты (ok), sample sd (попалась разница)
  - затем сравнить msfe
  - сделать код для многих ядер процессора: в самом bvar_conjugate и в estimate
  - почистить код на минимальный priors (чтобы минимальный работал)
* 16:02 у способов svd/chol отличаются sample sd of Phi post (!corrected, не там было транспонирование)
* 16:18  может 13 лагов лучше чем 12?

# 23 августа 2015

* 11:26 изменить выборку (убрать 1995 год, например)
* 11:27 зафиксировать лямбды на base scenario Carriero
* 11:27 три части выборки: оценка, подбор лямбды под оптим. прогнозы, оценка
* 11:31 ввести id процесса оценивания, затем читалку результатов оценивания
* 14:30 гармония явного подхода с заданием априорных матриц: dummy_sс + dummy_io влияют только на априорные матрицы!!! но не включаются более никуда!!!!
* 14:55 больше наборов данных для сравнения прямо в пакет

# 24 августа 2015:
* Обнаружена ошибка в forecast rw in-sample, бралось время t=1, а надо брать с момента предсказания минус один. Исправлено.
* Еще одна ошибка в forecast rw in-sample. Делался прогноз от первой точки на h шагов вперед, а надо было от предыдущей на один шаг вперед. Исправлено.
* задача на сегодня: разобраться с гармонией явного подхода с заданием априорных матриц.
* fit_set в bvar_out_list (есть, ок)

# 25 авгутса 2015
* best_lambda наличие повторных строк (нет, ок)
* дизайн реализации двух подходов (ситуация слабо осложнена наличием nu всегда)
obs2prior
prior2obs (??? как выглядит решения для произвольных prior)
lambda2obs
lambda2hyper (двойная конвертация labmda -> obs -> prior)
estimate from obs (выбрать более робастную из from obs/prior)
estimate from prior
* в пакете сделать prior$Omega вместо prior$Omega_prior?
* хранить Omega или Omega^{-1}?
* разделить симуляции по banbura от отчёта по банбуре?
в отчете сверху указывается желаемое число лагов и прочее
* сделать корректные типы, чтобы убрать warnings() (ок)
* отказаться от длинных списков - оставить только широкие (ок)

# 26 августа 2015
* стандартизировать test/verbose, добавить печатаемую инфу, добавить проверку состоятельности
* разделить оценку и файл с параметрами и отчетом ?
* добавить удобную оценивалку одной модели
* нужен ли constant в setup модели? при прогнозе вроде как да (да)
* нужен ли Y_in в setup? если он легко рековерится? (нет)

# 8 сентября 2015
* корректность mdd (marginal data density)? Сравнение с Карьеро, рассмотрение предельных случаев, где можно руками посчитать
* неединственность оптимальной mdd (ок)
* бесконечные лямбда --- протестировать все функции
* дописать rmsfe (ok)
* сделать разные v_prior в списках моделей

# 9 сентября 2015
* выбор первой попавшейся оптимальной mdd в случае равенства,
стандартизировано с replicate banbura
* rmsfe for mdd ok
* в чем все (!) отличия кода каррьеро от нашего?

# 10 сентября 2015
* СТРАННАЯ ошибка: source() в R работает, пошаговое исполнение в Rstudio - ok
source() в Rstudio не работает
"Error in eval(expr, envir, enclos) : object at index 356 not a data.frame"
" incompatible type (data index: 414, column: 't', was collecting: numeric (dplyr::Collecter_Impl<14>),"
свежий RRO и Rstudio и пакеты после переустановки
  - вымарать foreach? (не помогло) попробовать классику?
  - перезагрузка? (кажется помогло?)
* автоматизация номеров столбцов в конце
* (ok) проверка корректности оценок при sigma^2 из AR(1)
* удобная функция для одной модели
* с каким omsfe сравнивать? с RW всегда? с моделью выбранной по тесту? с AR() с нужным коэффициентом?
- сравниваем с RW всегда, а установка delta влияет только на prior

# 12 сентября 2015
* вероятная причина мистической ошибки: использование устаревшей rbind_all/rbind_list
перешли на bind_rows. По крайней мере ошибка в нем!
* у Каррьеро вероятно ошибка --- он пропустил извлечение корня из сигма
* добавлена опция carriero_hack
* добавлена опция текстовой формулой для v_prior
* АХТУНГ: мистика вернулась!!!!!!!!!!!
* для борьбы с мистикой: обновили dplyr, отказались в forecast_models от bind_rows в пользу.
data.table::rbindlist. Главное еще там опцию use.names=TRUE ставить :)
Кажется ок!!!
* как автоматизировать в mdd вывод rmsfe_wide при разных optimal_by?

# 20 сентября 2015
* корова оценивает (именно оценивает) для mdd около 3х часов
* ошибка при расчете mdd, функция bvar_conj_mdd()


# 01 февраля 2016
статус кво:
1. статья по прогнозированию: (eng, tex)
- model selection set или
- bayesian model selection или
- SVS stochastic variable selection
- что из этого разумнее сделать?

- добить marginal likelihood
- сравнить с кодом на данных Банбуры
- отправить в англ журнал

2. статья по картографированию (rus, tex)
- проверить раздел про density
- таблица с описанием кодов (убрать или доделать)
- отправить в Прикладную эконометрику
- перевести, поправить на эпсилон и отправить в журнал

3. статья старая (rus, word)
- отравлять в разные журналы

прочее:
- ОМ: density forecasting
- OM: bvar sign restriction

# 07 февраля 2016
байесовское сравнение делать очень долго?
mcs философски частотный, но есть люди делающие mcs для bvar

хороший пакет для байесовского выбора линейных моделей
https://cran.r-project.org/web/packages/BMS/vignettes/bms.pdf

# 12 февраля 2016
* еще один пакет для R, код на c++
прогнозирование плотностей, tvp:
https://github.com/FK83/bvarsv
* добавить четкое описание VAR и RW как частных случаев BVAR
* marginal likelihood и bayesian factors - связь?

* 52-53 моё
* 54 моё
* F - условия прописать?

# 15 февраля 2016
* 54 - ок, выходит и для многомерного кореллированного --- условное ожидание для квадратной функции потерь
* F - прописаны условия, но проблема с равномерностью?

# 21 февраля 2016
```{r}
# MCSprocedure {MCS}
# смысл полей:
# _M --- статистика Tmax
# Rank_M -- номер v_M при сортировке по возрастанию
# v_M --- значение статистики t_{i\cdot}
# MCS_M --- ???
# _R --- статистика TR
# Rank_R -- номер v_R при сортировке по возрастанию
# v_R --- значение статистики
# MCS_R --- ???
# Loss -- это средний лось модели
```

репликация таблицы от экселевского файла до цветастой таблицы:
1. отрыли файл для переменной var
2. нашли эту переменную var
3. в подтаблице для данной var и выбранной h (в прямоугольном участке) выбрали наименьшее число
4. откопировали это число цветастую таблицу

```{r}
# if ind_prod/cpi/ib_rate - nothing to change
# if var \in set_6, but not var \in set_3 - add var to set_3
# if var \in set_23, but not var \in set_6 - add var to set_3 and set_6
```

# 02 марта 2016

Парадокс Штейна сотоварищи:

* https://www.ecb.europa.eu/pub/pdf/scpwps/ecbwp1494.pdf?25ce6d8d23d4553229cfec7f729e00e0
* http://web.missouri.edu/~nix/paper35.pdf
* http://onlinelibrary.wiley.com/doi/10.1111/1467-9574.00125/abstract
* http://www.stat.washington.edu/people/pdhoff/courses/581/LectureNotes/shrinkage.pdf
* http://econpapers.repec.org/article/eeejmvana/v_3a97_3ay_3a2006_3ai_3a9_3ap_3a1984-1996.htm



тудушки:

- Боря: возродить marginal likelihood из пепла
- Боря: проверка робасТности кода к обобщениям
- Оксана: вставить all_wide + поэкспериментироваь, гистограмма - файл на почте + таблицы для marginal table
- Может сделать кучу стран? И на этом сделать ставку? Я думаю, это неправильный путь
- Автоматический выбор лагов? - через marginal likelihood или еще как-то?
- Слияние с Midas?
- Боря: универсальная лямбда в пакет
- Привязать bvar mapping в repec



1. вставить форвардные цены на нефть вместо нефти
    - Хорошо ли предсказывается форвард на нефть остальными переменными?
    - А может форвардные цены лучше предсказывают выпуск?
2. TVP?
    - посмотреть на стабильность параметров
    - оценить TVP и сравнить RMSFE
3. проследить как меняется RMSFE по времени
    - является ли набор моделей которые мы считаем лучшими постоянным во времени
4. усреднить прогнозы

Оксана:
- обзор tvp-bvar априорных распределений
- обзор доступного кода
- данные по форвардам нефти
Боря:
- подготовить код к приему нефти
- реализовать оценивание с помощью tvp
- реализовать оценивание с помощью msbvar


# 08 февраля 2017

Советы от Маартена:
- Discuss your results openly from the point of view of a referee, reader (where are the obvious weak points). Better you mention them, then that they get irritated
- Презентация: Sometimes do not present model, but just a (2x2) example. Illustrate results in a simplified way (figures).
- Don't start presentation like: I present a paper on XXXX. The structure of my talk is Introduction, Model, Analysis, Conclusions.
- Titles. Attract attention. Main result. 

По названию предложения:
Does Bayesian VAR outperform frequentist models for Russian macroenomic indicators?

We estimate Bayesian vector autoregressions (BVARs) of different sizes and compare the accuracy of their out-of-sample forecasts with those obtained with unrestricted vector autoregressions and random walk with drift. We show that many Russian macroeconomic indicators can be forecast by BVARs more accurately than by com- peting models. Contrary to several other studies, increasing the number of time series in a model does not necessary decreases relative forecast error. In half of those cases where a BVAR appears to be the most accurate model, a small-dimensional BVAR outperforms its high-dimensional counterpart.


- Почитать Primiceri, Time Varying Structural Vector Autoregressions and monetary policy

* формула (2): похоже на диагонализацию, но не совсем, тк A_t - нижнетреугольная
* под heteroskedasticity имеется ввиду условная гетероскедастичность
* смена порядка в векторе y_t -> разные априорные распределения! (стр. 827)
* обратная к нижнетреугольной является нижнетреугольной
* Называет гиперпараметрами V (то есть Q, S, W), а не k_Q, k_W, k_S... (стр. 828 первый абзац)
* формула (8) - пропущено условие на Q, S, W, должно быть:
Var(вектор шумов | Q, S, W ) = ...
* Три способа выбрать гиперпараметры!
1. Кросс-валидация
2. Evidence maximization
3. Плюс один уровень иерархии: Априорное распределение на гиперпараметр, который надо подобрать!
* Характеристика априорного распределения: пропущены крышки над V()


# 15 февраля 2017


* $\hat B = (X'X)^{-1}X'Y$ — оцеки коэффициенты регрессий каждого столбца из $Y$ на все столбцы $X$ 

столбцы $X$ - единичный, первые лаги переменных, вторые лаги переменных

* $\hat U$ — остатки всех регрессий (столбцами)

* $\widehat{Var}(\hat B) = \frac{1}{T}\hat U' \hat U \otimes (X'X)^{-1}$

По смыслу — это ковариационная матрица всех оценок коэффициентов, то есть $\widehat{Var}(vec \hat B)$.

* Если $Au=\Sigma \varepsilon = v$, то

$u_{2} = -\alpha_{21} u_{1} + v_2$ 

$u_{3} = -\alpha_{31} u_{1} -\alpha_{32} u_{2} + v_3$

То есть, чтобы получить оценку $\hat\alpha_{32}$ надо построить регрессию $\hat u^{(3)}$   на  $\hat u^{(2)}$,  $\hat u^{(1)}$ и взять оценку коэффициента с противоположным знаком.

Эксперимент:

```{r}
n_obs <- 100000
v <- matrix(rnorm(n_obs * 3), ncol = 3)
A <- matrix(c(1, 0, 0, 2, 1, 0, 5, 6, 1), nrow = 3, byrow = TRUE)

u <- v %*% solve(t(A))
reg_2_1 <- lm(u[, 2] ~ 0 + u[, 1])
reg_3_12 <- lm(u[, 3] ~ 0 + u[, 1] + u[, 2])
A
coef(reg_2_1)
coef(reg_3_12)
```

**Ошибка 1**: Однако в matlab-коде kolb оценки из регрессий на -1 не домножаются!!!!

**Ошибка 2**: В описании-klob написано, что строятся две отдельные регрессии $\hat u^{(3)}$ на $\hat u^{(2)}$ и $\hat u^{(3)}$ на $\hat u^{(1)}$. На самом деле правильно (и в коде — ок) множественную одну.

Кроме того, в matlab коде используется трюк: kolb строит вместо нескольких регрессий одну. Трюк идейно такой (на примере одной объясняющей):

1. Мы хотим оценить две регрессии: $y_a$ на $x_a$ и $y_b$ на $x_b$.

2. Записываем $y_a$, а под ним $y_b$, получаем $y$. 

3. Напротив $y_a$ регрессорами будут  $x_a$ и столбец нулей.

4. Напротив $y_b$ регрессорами будут столбец нулей и $x_b$.

5. Строим одну регрессию

\[
y_i = \beta_a d_{ai}x_{ai} + \beta_b d_{bi}x_{bi} + u_i
\]

Переменная $d_{ai}$ равна единице для наблюдений из группы $a$.

В матричном виде, соответственно:
\[
\hb = 
\begin{pmatrix}
\hb_a \\
\hb_b \\
\end{pmatrix} =
\begin{pmatrix}
X_a'X_a & 0\\
0 & X_b'X_b \\
\end{pmatrix}^{-1} 
\begin{pmatrix}
X_a'y_a\\
X_b'y_b \\
\end{pmatrix}
\]

# 17 февраля 2017

* Carter and Kohn — где? West, Harrison — кратко

* Пустая регрессия. Для понимания кода можно себе представить регрессию-пустышку. Одна зависимая переменная и ноль (0) регрессоров. Ноль оцениваемых коэффициентов. Остатки от этой регрессии равны исходной зависимой.

* Для удобства: $v_{jt} = \sigma_j \varepsilon_{jt}$.

* В теории мы предполагаем, что компоненты вектора $\varepsilon_t$ некоррелированы. На практике при оценке элементов матрицы $A$ строится регрессия $\hat u_j$ на $\hat u_{j-1}$, $\ldots$, $\hat u_{1}$. 
\[
\hat u_3 = \alpha_{31} \hat u_1 + \alpha_{32} \hat u_2 + v_3
\]

Из условий первого порядка получаем ортогональность $\hat v_3$ регрессорам $\hat u_1$ и $\hat u_2$. Замечаем, что $\hat v_2$ линейно выражается через $\hat u_2$ и $\hat u_1$, поэтому $\hat v_3$ ортогонально $\hat v_2$. То есть выборочная ковариационная матрица остатков остатков, $\hat V'\hat V/T$, `oMa` в коде, диагональна. С точностью до машинного эпсилон. 

* Если строить отдельные регрессии для нахождения каждой строки матрицы, то в этих регрессия допускается разная дисперсия $v_j$. То есть при исполнении трюкового построения нужных регрессиий с помощью  единой регрессии мы получаем гетероскедастичность. Рассмотрим эту единую регрессию:

\[
\hat u = X\alpha + v.
\]

Под $\hat u$ подразумеваем записанные друг под другом вектора остатков $\hat u_j$.

И 
\[
\Var(\hat\alpha) = \Var((X'X)^{-1}X'\hat u) = (X'X)^{-1}X'\Var(v)X(X'X)^{-1}
\]

Здесь структура $\Var(v)$ гетероскедастичная блоками (для 3-х мерного $y$):

\[
\Var(v) = \begin{pmatrix}
\sigma^2_1 I_T & 0 & 0 \\
0 & \sigma^2_2 I_T & 0  \\
0 & 0 & \sigma^2_3 I_T  \\
\end{pmatrix} = 
\begin{pmatrix}
\sigma^2_1 & 0 & 0 \\
0 & \sigma^2_2 & 0  \\
0 & 0 & \sigma^2_3 \\
\end{pmatrix} \otimes I_{T\times T}
\]

В качестве оценки матрицы $\Sigma = diag(\sigma_1^2, \sigma^2_2, \sigma^2_3)$ берём выборочную ковариационную матрицу остатков остатков $\hat V'\hat V/T$. 

* Eсли $\Sigma$ диагональна, то $\Var(\hat\alpha)$ имеет блочно-диагональную структуру.

* Для спокойствия можно пробить строгими нулями недиагональные элементы выборочной ковариационной матрицы остатков-остатков $\hat V'\hat V/T$. Можно не пробивать, результат будет отличаться только на машинное эпсилон.

* Два подхода эквивалентны для недиагональной $\Sigma$: 
    - сначала применить формулу для $\Var(\hat\alpha)$ и потом убить нулями элементы вне диагональных блоков (так сделано в коде, нули вне диагонали убивает цикл).
    - сначала убить нулями внедиагольные элементы $\Sigma$, потом применить формулу $\Var(\hat\alpha)$.

# 20 февраля 2017

* Ruth Follet, Bayesian modelling multivariate macro data, thesis,
[http://lib.dr.iastate.edu/etd/15150/](http://lib.dr.iastate.edu/etd/15150/)

* Jim Savage, Hierarchical BVAR в STAN, [https://rpubs.com/jimsavage/hierarchical_var](https://rpubs.com/jimsavage/hierarchical_var)

* Jim Savage, [blog](http://modernstatisticalworkflow.blogspot.com), [вкусности на rpubs](https://rpubs.com/jimsavage), [github](https://github.com/khakieconomics?tab=repositories).

* [BVAR questions for STAN](https://groups.google.com/forum/#!topic/stan-users/8RerHVzxjUQ)

* Ссылки по bsts
    - [Sorry, Arima](http://multithreaded.stitchfix.com/blog/2016/04/21/forget-arima/)
    - [Predicting the present with BSTS](people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf)
    - [Predicting the present - presentation](https://pdfs.semanticscholar.org/2547/1816a77ba05f7cd9ee7831d3b7993c8d91ea.pdf)
    - [Scott, short course on bsts](https://sites.google.com/site/stevethebayesian/googlepageforstevenlscott/course-and-seminar-materials/bsts-bayesian-structural-time-series)
* [http://stats.stackexchange.com/questions/140990/using-kalman-filters-to-impute-missing-values-in-time-series](http://stats.stackexchange.com/questions/140990/using-kalman-filters-to-impute-missing-values-in-time-series).
Хорошо изложен Фильтр Калмана. 

# 22 февраля 2017

* Код kolb: 

В коде $Hpr$ — это априорное $E(H_0)$, оно отличается от статьи Primiceri множителем $0.5$. Похоже, что $VHpr$ — это априорная $\Var(H_0)$ — у Primiceri и kolb — $I$. Опечатка! стр.3: Чтобы всё сошлось надо считать, что
$H_t = \log \sigma_t$, а не квадрата. И более того, $H_t$ должно быть вектором :)
  
* [Bayesian Inference for a Covariance Matrix](https://arxiv.org/pdf/1408.4050.pdf):

Для обратного Уишарта $C \sim IW(C_0, \nu)$.

Если $\nu = p + 2$, то $E(C)=C_0$.

Если $\nu = p + 1$, то $E(C)$ не существует, но частное распределение корреляций оказывается равномерным на $[-1;1]$.

* В коде kolb: почему-то в матрице $Sig$ нет первой дисперсии. Это матрица $\Sigma_t$. И она захардкожена под размер $Sig_{2\times 2}$

* Ошибки со знаком априорного распределения $A_0$ нет, так как при инициализации домножено на $(-1)$, строки ~201-203

* В коде kolb: $Alt$ вместо трёх-мерного массива записаны одна под одной для каждого $t$.

* условное многомерное нормальное, http://stats.stackexchange.com/questions/30588/deriving-the-conditional-distributions-of-a-multivariate-normal-distribution

# 1 марта 2017

* В обозначениях Kim, Nelson "State space models" (стр. 190 и далее): $\beta_t$ — состояние (вектор), 
$\tilde \beta_t$ — вектор состояний $\beta_1, \beta_2, \ldots, \beta_t$.

* Carter-Kohn. Цель: сгенерировать $\tilde \beta_t$ зная $\tilde y_t$  и гиперпараметры модели.

В силу марковости:

Шаг 1. Генерируем $\beta_T |\tilde y_T \sim \cN(\beta_{T|T}, P_{T|T})$.

Шаг 2. Затем генерируем всё более ранние $\beta_t$, сначала $\beta_{T-1}$, затем $\beta_{T-2}$ и далее до $\beta_1$, а именно: $\beta_t | \tilde y_t, \beta_{t+1} \sim \cN(\beta_{t|t,\beta}, P_{t|t,\beta})$.


Для генерации нужно посчитать кучу матриц. Здесь $h$ — хз какая функция:
\[
\beta_{t|t}=h(\beta_{t|t-1}, P_{t|t-1}, f_{t|t-1}, \eta_{t|t-1}), \quad (3.79, p. 192)
\]
\[
P_{t|t}=h(P_{t|t-1}, f_{t|t-1}), \quad (3.80, p. 192)
\]

Величины с отстающим индексом находятся из фильтра Калмана:
\[
f_{t|t-1} = h(P_{t|t-1}) = HP_{t|t-1}H'+R
\]

Остались: $\beta_{t|t-1}$, $P_{t|t-1}$, $\eta_{t|t-1}$.


Величины с дополнительным $\beta$-индексом считаются так:
\[
\beta_{t|t,\beta} = h(\beta_{t|t}, P_{t|t}, \beta_{t+1}), \quad (8.16)
\]
\[
P_{t|t,\beta} = h(P_{t|t}), \quad (8.17)
\]

# 21 марта 2017
* [BigVAR](http://www.wbnicholson.com/BigVAR.pdf)

* [VI for statisticians](https://arxiv.org/pdf/1601.00670.pdf)
* [ADVI in STAN](https://arxiv.org/pdf/1506.03431.pdf)
* [VI for VAR(1)](https://theses.ncl.ac.uk/dspace/bitstream/10443/790/1/Houghton09.pdf)
* [BVAR, Wozniak](http://fbe.unimelb.edu.au/__data/assets/pdf_file/0010/1942966/2021TomaszWozniakBVARs.pdf)

* ADVI with stan:
```{r, eval=FALSE}
model <- stan_model(file = "model.stan")
data <- list(...)
fit <- sampling(model, data = data, seed = 42)
fit_advi <- vb(model, data = data, seed = 43, iter = 10000)
```
* "ADVI is still an experimental algorithm in that we're
still working on getting the code right and understanding what
the algorithm does". Bob Carpenter, 2016-04-27.

* "How do you compute the likelihood?  The lp__ value returned
is *not* the likelihood (or even th joint or posterior density),
even in Stan's MCMC.  To compound the confusion, I believe ADVI
just hacked the lp__ value to be 0 everywhere (and I believe the
fix for it is in for Stan 2.10)". Bob Carpenter, 2016-04-27.

* "One thing you can try is different starting points.  We’ve had lots of discussions in the stan meeting about ADVI failing in lots and lots of these simple examples, and it’s never clear whether the problem is with the variational solution or with the algorithm not converging.  Our guess is that in these settings the result is highly sensitive to initial values and turning parameters.  We have hopes that ADVI’s tuning can be improved so it will give reasonable answers more reliably.  For now, I think it’s best to be safe and run from multiple inits". Andrew Gelman, 2016-01-15.

* [matlab_stan](http://mc-stan.org/interfaces/matlab-stan)

* [TVP-BVAR, Jouchi Nakajima](http://www.imes.boj.or.jp/research/papers/english/me29-6.pdf)

* [TVP, Cointegration](http://www.economics.uci.edu/files/docs/econoseminar/w10/strachan.pdf)


# 22 марта 2017

* xgboost: все регрессоры, все кросс-произведения, накопленные стандартные ошибки (за 2 прошедших периода, за три, за четыре...), накопленные оценки ковариаций?, дамми на сезоны, тренд?

* функция от функции:
- все данные
- длина тестового с конца
- удлинняющийся или постоянной длины
- функция прогнозирующая
- функция создающая все регрессоры

* Ортонормализация внутри групп
Tibshirani, [Standardization and the group lasso penalty](http://faculty.washington.edu/nrsimon/standGL.pdf)

* Может выполнить ортонормализацию внутри групп?

* Проверить автоматическую нормализацию: если её предварительно сделать, то не должно поменяться оптимальное лямбда

# 10 мая 2017

* Koop, [Bayesian methods for empirical macroeconomics with big data](http://strathprints.strath.ac.uk/id/eprint/60339). Обзор ситуации с большими варами.

* Шевелев, [БАЙЕСОВСКИЙ ПОДХОД К ОЦЕНКЕ ВОЗДЕЙСТВИЯ ВНЕШНИХ ШОКОВ](http://www.nsu.ru/ef/vestnik_ngu_ef/2017_1_03). По России, цитирует нас, функции реакции.



