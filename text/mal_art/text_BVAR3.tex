% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt





\usepackage{filecontents}



\begin{filecontents}{bvar.bib}

@article{sims1998bayesian,
  title={Bayesian methods for dynamic multivariate models},
  author={Sims, Christopher A and Zha, Tao},
  journal={International Economic Review},
  pages={949--968},
  year={1998},
  publisher={JSTOR}
}

@article{carriero2015bayesian,
  title={Bayesian VARs: specification choices and forecast accuracy},
  author={Carriero, Andrea and Clark, Todd E and Marcellino, Massimiliano},
  journal={Journal of Applied Econometrics},
  volume={30},
  number={1},
  pages={46--73},
  year={2015},
  publisher={Wiley Online Library}
}

@article{doan1984forecasting,
  title={Forecasting and conditional projection using realistic prior distributions},
  author={Doan, Thomas and Litterman, Robert and Sims, Christopher},
  journal={Econometric reviews},
  volume={3},
  number={1},
  pages={1--100},
  year={1984},
  publisher={Taylor \& Francis}
}

@article{robertson1999vector,
  title={Vector autoregressions: forecasting and reality},
  author={Robertson, John C and Tallman, Ellis W},
  journal={Economic Review-Federal Reserve Bank of Atlanta},
  volume={84},
  number={1},
  pages={4},
  year={1999},
  publisher={Federal Reserve Bank of Atlanta}
}

@article{kadiyala1997numerical,
  title={NUMERICAL METHODS FOR ESTIMATION AND INFERENCE IN BAYESIAN VAR-MODELS},
  author={Kadiyala, K and Karlsson, Sune},
  journal={Journal of Applied Econometrics},
  volume={12},
  number={2},
  pages={99--132},
  year={1997},
  publisher={Wiley Online Library}
}


@article{forni2000generalized,
  title={The generalized dynamic-factor model: Identification and estimation},
  author={Forni, Mario and Hallin, Marc and Lippi, Marco and Reichlin, Lucrezia},
  journal={Review of Economics and statistics},
  volume={82},
  number={4},
  pages={540--554},
  year={2000},
  publisher={MIT Press}
}

@article{beauchemin2011medium,
  title={A medium scale forecasting model for monetary policy},
  author={Beauchemin, Kenneth R and Zaman, Saeed},
  year={2011},
  publisher={FRB of Cleveland Working Paper}
}

@article{de2008forecasting,
  title={Forecasting using a large number of predictors: Is Bayesian shrinkage a valid alternative to principal components?},
  author={De Mol, Christine and Giannone, Domenico and Reichlin, Lucrezia},
  journal={Journal of Econometrics},
  volume={146},
  number={2},
  pages={318--328},
  year={2008},
  publisher={Elsevier}
}

@article{banbura2010large,
  title={Large Bayesian vector auto regressions},
  author={Ba{\'n}bura, Marta and Giannone, Domenico and Reichlin, Lucrezia},
  journal={Journal of Applied Econometrics},
  volume={25},
  number={1},
  pages={71--92},
  year={2010},
  publisher={Wiley Online Library}
}

@article{waggoner1999conditional,
  title={Conditional forecasts in dynamic multivariate models},
  author={Waggoner, Daniel F and Zha, Tao},
  journal={Review of Economics and Statistics},
  volume={81},
  number={4},
  pages={639--651},
  year={1999},
  publisher={MIT Press}
}

@article{bloor2010analysing,
  title={Analysing shock transmission in a data-rich environment: a large BVAR for New Zealand},
  author={Bloor, Chris and Matheson, Troy},
  journal={Empirical Economics},
  volume={39},
  number={2},
  pages={537--558},
  year={2010},
  publisher={Springer}
}


@techreport{alessandri2014financial,
  title={Financial conditions and density forecasts for US output and inflation},
  author={Alessandri, Piergiorgio and Mumtaz, Haroon},
  year={2014},
  institution={Working Paper, School of Economics and Finance, Queen Mary, University of London}
}

@article{geweke2006bayesian,
  title={Bayesian forecasting},
  author={Geweke, John and Whiteman, Charles},
  journal={Handbook of economic forecasting},
  volume={1},
  pages={3--80},
  year={2006},
  publisher={Elsevier}
}

@techreport{berg2013point,
  title={Point and Density Forecasts for the Euro Area Using Many Predictors: Are Large BVARs Really Superior?},
  author={Berg, Tim Oliver and Henzel, Steffen},
  year={2013},
  institution={ifo Working Paper}
}


@article{litterman1986forecasting,
  title={Forecasting with Bayesian vector autoregressions—five years of experience},
  author={Litterman, Robert B},
  journal={Journal of Business \& Economic Statistics},
  volume={4},
  number={1},
  pages={25--38},
  year={1986},
  publisher={Taylor \& Francis}
}

@article{stock2002forecasting,
  title={Forecasting using principal components from a large number of predictors},
  author={Stock, James H and Watson, Mark W},
  journal={Journal of the American statistical association},
  volume={97},
  number={460},
  pages={1167--1179},
  year={2002},
  publisher={Taylor \& Francis}
}

@book{zellner1996introduction,
  title={An Introduction to Bayesian Inference in Econometrics},
  author={Zellner, A.},
  isbn={9780471169376},
  lccn={gb96082549},
  series={Wiley Classics Library},
  url={https://books.google.ru/books?id=9tSrQgAACAAJ},
  year={1996},
  publisher={Wiley}
}

@incollection{sims1993nine,
  title={A nine-variable probabilistic macroeconomic forecasting model},
  author={Sims, Christopher A},
  booktitle={Business Cycles, Indicators and Forecasting},
  pages={179--212},
  year={1993},
  publisher={University of Chicago Press}
}


\end{filecontents}

\usepackage[backend=biber, style=alphabetic, citestyle=authoryear]{biblatex}
\addbibresource{bvar.bib}



%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or\ldots .
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information


% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another\ldots

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout\ldots
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%My Additional Packages
\usepackage{mathtext}          % русские буквы в формулах
\usepackage[T2A]{fontenc}            % внутренняя кодировка  TeX
\usepackage[utf8]{inputenc}         % кодировка исходного текста
\usepackage{cmap}          % русский поиск в pdf
\usepackage[english,russian]{babel} % локализация и переносы
\usepackage{amsmath} % Математические окружения AMS
\usepackage{amsfonts} % Шрифты AMS
 \usepackage{amssymb} % Символы AMS
  \usepackage{graphicx} % Вставить pdf- или png-файлы

  \usepackage{euscript} % Красивый шрифт

  \usepackage{longtable}  % Длинные таблицы
  \usepackage{multirow} % Слияние строк в таблице

 \usepackage{indentfirst} % Отступ в первом абзаце.

 \newcommand*{\hm}[1]{#1\nobreak\discretionary{}%
            {\hbox{$\mathsurround=0pt #1$}}{}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}


%\DeclareMathOperator*{\argmax}{arg\,max}

 \usepackage{verbatim}

\usepackage[update,prepend]{epstopdf} % EPS-рисунки конвертируются в PDF
\usepackage{wrapfig} % Обтекание рисунков текстом

\usepackage{hyperref} % Гиперссылки

\DeclareMathOperator{\E}{\mathbb{E}}
\let\vec\relax
\DeclareMathOperator{\vec}{vec}
\DeclareMathOperator{\diag}{diag}

\DeclareMathOperator{\Var}{\mathbb{V}\mathrm{ar}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\lag}{\EuScript{L}}


%%% END Article customizations

%%% The "real" document content comes below\ldots

\title{BVAR in Russia}
\author{я и Боря}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed

\begin{document}
\maketitle

\section{Обзор литературы}

Построение точных  макроэкономических прогнозов является ключевым условием проведения верной политики центральными  банками.  Хорошо известно, что центральные банки развитых государств опираются на большое число макроиндикаторов при проведении политики (\cite{stock2002forecasting} или BBE для США., какая-нибудь аналогичная работа для ЕЗ). Однако обычная векторно-авторегрессионная модель, ставшая наиболее часто встречающимся инструментом для построения прогнозов, не может учесть большое количество переменных, так как количество параметров, подлежащих оценке, растет нелинейно с увеличением числа уравнений.  При этом неучтенная при построении VAR информация может приводить к смещенным оценкам и  неверным выводам  как относительно прогнозируемых значений, так и виде функций импульсных откликов.  Основные способы учета большого числа переменных – это использование DF и Байсовских VAR.
Динамические факторы были предложены в работах \cite{forni2000generalized} и \cite{stock2002forecasting}.  В указанных работах предполагается, что дисперсия большого количества временных рядов может быть описана с помощью нескольких, искусственно построенных (common factors)  с помощью метода главных компонент.  Расширением метода \cite{stock2002forecasting} служит FAVAR, предложенная в статье (Bernanke et al, 2005).В рамках FAVAR несколько динамических факторов  добавляются как дополнительные переменные в обычную VAR.
Цель данной работы состоит в построении  прогноза основных макроиндикаторов (выпуска, инфляции и др.) для российской экономики.  Задача осложняется отсутствием  большого количества длинных временных рядов, что не позволяет провести построение DFM.
Байесовские модели зарекомендовали себя как хороший инструмент построения прогнозов. В ряде работ было показано, что они обеспечивают более низкую ошибку прогноза, чем, например, обычные VAR и VECM.
(?) две стратегии – использовать shrinkage, который становится уже с ростом числа переменных
По Bloor and Matheson надо бы переписать.


Модификация Litterman prior была предложена в работах \cite{doan1984forecasting} (sum of coefficients prior) и \cite{sims1993nine}   (co-persistence prior).  Комбинация этих трех априорных распределений была использована в работе  \cite{robertson1999vector} для предсказания безработицы, темпа роста  и инфляции. В работе показано, что смешанное априорное распределение получает получить более точные прогнозы, чем априорные распределения \cite{litterman1986forecasting} и \cite{sims1998bayesian} (про эту работу пока ничего не писала).


Ключевую роль в развитии подхода сыграла статья \cite{de2008forecasting}. В этой работе на основе асимптотического анализа было показано, что если данные характеризуются высокой мультиколлинеарностью (что характерно для выборок макрорядов большой размерности) сужение априорного распределения при увеличении количества переменных дает больший вес нескольким первым главным компонентам.  Это означает, что если данные характеризуются факторной структурой, то наложение более узких априорных распределений с увеличением размерности модели  не  приводит к потере важной информации, т.к. для описания данных достаточно небольшого количества первых факторов.  Эта точка зрения  была подтверждена и развита в статье \cite{banbura2010large}, в которой авторы  строят VAR модели для 3, 7, 20 и 131 переменных и показывают, что модели с большей размерностью демонстрируют лучшие прогнозные способности, чем модели малой размерности и даже FAVAR (? Проверить, об этом пишет Бошеман). Интересно отметить, что хорошая прогнозная способность достигается уже в модели с 20  переменными, поэтому как для прогнозирования, так и для структурного анализа достаточно сконцентрироваться на агрегированных данных.
Аналогичная модель для Новой Зеландии была построена в работе \cite{bloor2010analysing}, в которой они использовали метод условного прогнозного оценивания \cite{waggoner1999conditional}, что позволило им сравнить сценарии , основанные на различной условной информации.  Строят три модели (с 9, 13 и 35 переменными), делают вывод, что BVAR обладает более высокой предсказательной способностью, чем AR и обычная VAR модель.  Хотя результаты варьируют по разным переменным, в общем и целом, BVAR c большим числом переменных характеризуется более высокой точностью прогноза.
Из Beauchemin
Koop (2010) расширил результаты \cite{banbura2010large}  и показал, что BVAR c большой размерностью обладают лучшей прогнозной способностью даже по отношению  к более сложным моделям (???)
Тот же метод построения априорного распределения (естественно-сопряженная версия Миннесоты-распределения \cite{kadiyala1997numerical}; \cite{sims1998bayesian}- проверить, они ли предложили? ), что в работах \cite{banbura2010large}, \cite{bloor2010analysing} и Koop (2010) был применен в работе \cite{beauchemin2011medium}. Они показывают, что BVAR с 16 переменными может быть с успехом использована как для прогнозов, так и для структурного анализа (трансмиссии монетарного шока (?)/cтруктурного анализа монетарной политики. Аналогичное построение априорного распределения используется в работе \cite{alessandri2014financial}, где с помощью линейной и нелинейной BVAR (?) модели показано, что учет финансовых индикаторов позволяет улучшить прогноз выпуска и инфляции, в т. ч. в кризисные периоды.

Во всех работах гиперпараметр, контролирующий жесткость (?) , выбирается таким образом, чтобы максимизировать функцию правдоподобия  данных ( это максимизирует точность вневыборочного прогноза ?). В работе \cite{geweke2006bayesian} было показано, что такой выбор гиперпараметра минимизирует ошибки прогноза на один период.


Сам Литтерман в своей работе показал, что использование априорного распределения (Bayesian shrinkage) в BVAR с  не менее  чем шестью переменными  улучшает прогнозную силу модели. Однако до~последнего времени считалось, что при использовании достаточно большого числа временных рядов уточнения правдоподобия только с помощью априорного распределения недостаточно.  Это приводило к необходимости задавать дополнительные ограничения.

\section{Методология}

\subsection{Удобная табличка}

\begin{center}
\begin{tabular}{ccp{6cm}l}
\toprule
Буква & Размер &  Описание & Формула \\
\midrule
$p$ & скаляр & количество лагов & \\
$m$ & скаляр & количество эндогенных переменных & \\
$d$ & скаляр & количество экзогенных переменных & \\
$k$ & скаляр & количество параметров в одном уравнении & $k=mp+d$ \\
$T$ & скаляр & количество наблюдений &  \\
\midrule
$z_t$ & $d \times 1$ & вектор экзогенных переменных (считая константу) & \\
$y_t$ & $m \times 1$ & вектор эндогенных переменных  & $y_t=\Phi' x_t+\varepsilon_t$ \\
$x_t$ & $k \times 1$ & вектор всех регрессоров & $x_t=[ y'_{t-1} \ldots  y'_{t-p} \; z'_t ]'$ \\
$\varepsilon_t$ & $m \times 1$ & вектор случайных ошибок  & \\
$Y$ & $T \times m$ & все эндогенные переменные & $Y=[y_1, y_2,\ldots, y_T]'$ \\
$X$ & $T \times k$ & матрица регрессоров& $X=[x_1, x_2,\ldots, x_T]'$ \\
$E$ & $T \times m$ & матрица ошибок & $E=[\varepsilon_1, \varepsilon_2,\ldots, \varepsilon_T]'$ \\
\midrule
$\Phi_1$, \ldots & $m \times m$ & коэффициенты VAR & $y_t= \Phi_1 y_{t-1} + \ldots + \Phi_{ex} z_t$ \\
$\Phi_{ex}$ & $m \times d$ & коэффициенты при экзогенных переменных & \\
$\Phi$ & $k \times m$ & упаковка матриц $\Phi_1$, \ldots & $\Phi=[ \Phi_1 \ldots \Phi_p \; \Phi_{ex}]'$ \\
$\phi$ & $km \times 1$ & вектор из матрицы $\Phi$ & $\vec{\Phi}$ \\
\midrule % здесь к миннесоте
$\underline{\Xi}$ & $km \times km$  & Априорная ковариационная матрица $\Phi$& \\
$\underline \Phi$ & $k \times m$ & априорное математическое ожидание $\Phi$ & \\
\midrule % здесь к сопряженному
$\underline{\Omega}$ & $k \times k$ & Матрица априорных масштабирующих коэффициентов ковариационной матрицы $\Phi$& \\
$\Sigma$ & $m \times m$ &Ковариационная матрица ошибок& $\E\varepsilon_t \varepsilon _t'=\Sigma$\\
$\underline{\nu}$ & скаляр & & \\
\bottomrule
\end{tabular}
\end{center}


\subsection{Байесовская VAR}
Рассмотрим переменные $y_{it}$, объединенные в~вектор  $y_{t}=(y_{1t},y_{2t},\ldots, y_{mt})'$ размерности $m$. Векторная авторегрессия в сокращенной форме записывается в~виде:
\begin{equation}
y_t =\Phi_{ex}+ \Phi_1 y_{t-1} + \Phi_2 y_{t-2} +\ldots + \Phi_p y_{t-p} + \varepsilon_t,\quad \varepsilon\sim \cN(0,\Sigma)
\end{equation}
где $\Phi_{ex}=(c_1,\ldots ,c_m)'$ --- вектор констант размерности $m$, $\Phi_l$ --– авторегрессионные матрицы размерности $m\times m$ при $l=1, \ldots, p$. Вектор $\varepsilon_t$ --- $m$-мерный вектор ошибок с ковариационной матрицей $\E\varepsilon_t \varepsilon _t'=\Sigma$, некоррелированный с объясняющими переменными.
Группируя матрицы параметров в общую матрицу $\Phi=[\Phi_1 \ldots \Phi_p \; \Phi_{ex}]'$ % здесь нужно транспонирование!
и определяя новый вектор $x_t=[ y'_{t-1} \ldots  y'_{t-p} \; 1]'$, получаем VAR записанную в более компактном виде:

\begin{equation}
y_t=\Phi' x_t+\varepsilon_t
\end{equation}
Если же сгруппировать переменные  и шоки следующим образом: $Y=[y_1, y_2,\ldots, y_T]'$, $X=[x_1, x_2,\ldots, x_T]'$, $E=[\varepsilon_1, \varepsilon_2,\ldots, \varepsilon_T]'$ то VAR можно записать как:
\begin{equation}
Y=X\Phi+E\label{var}
\end{equation}

Задача байесовского оценивания заключается в~поиске апостериорных распределений параметров $p(\Phi, \Sigma|Y)$ с~использованием функции максимального правдоподобия, $L(Y|\Phi, \Sigma)$, и~заданного априорного распределения, $p(\Phi, \Sigma|Y)$. Для этого используется правило Байеса:
\begin{gather}
p(\Phi, \Sigma|Y)=\frac{p(\Phi,\Sigma) L(Y|\Phi,\Sigma)}{p(Y)}
\text{Т.к. }p(Y) \text{ не зависит от } \Phi \text{ и }\Sigma, \text{ то можно записать: }\\
p(\Phi, \Sigma|Y)\propto p(\Phi,\Sigma) L(Y|\Phi,\Sigma)
\end{gather}\\
Так как $\varepsilon_t\sim \cN(0,\Sigma)$, то функция правдоподобия задается как:\footnote{ Другая форма записи функции правдоподобия: $L(Y|\Phi, \Sigma) \propto |\Sigma|^{-T/2}\exp\left\lbrace -\frac{1}{2} tr \left[\Sigma^{-1} \hat E' \hat E\right]\right\rbrace \times \exp\left\lbrace -\frac{1}{2} tr \left[\Sigma^{-1}(\Phi-\hat\Phi)'X'X(\Phi-\hat\Phi)\right]\right\rbrace$, где $\hat E=Y-X\hat\Phi$ и $\hat \Phi=(X'X)^{-1}X'Y$}
\begin{equation}
L(Y|\Phi, \Sigma) \propto |\Sigma|^{-T/2}\exp\left\lbrace -\frac{1}{2} tr \left[\Sigma^{-1}(Y-X\Phi)'(Y-X\Phi)\right]\right\rbrace\label{likelihood}
\end{equation}

\subsubsection{Априорное распределение Миннесоты}

Наиболее простым для применения является априорное распределение Миннесоты, предложенное в работе  \cite{litterman1986forecasting} и \cite{doan1984forecasting}.

Изначально \cite{litterman1986forecasting} предложил использовать априорное распределение Миннесоты, при котором в явном виде учитывается предпосылка о нестационарности большинства макрорядов.

Априорное распределение параметров предполагается многомерным нормальным, зависящим от нескольких гиперпараметров. Параметры предполагаются независимыми, следовательно, их ковариационная матрица диагональна. Ковариационная матрица вектора $\varepsilon_t$ также предполагается диагональной. Запишем задачу $\eqref{var}$ в векторизованном виде\footnote{Третье уравнение системы следует из тождества: $\vec(ABC)=(C\otimes A)\vec (B)$}:
\begin{gather*}
Y=X\Phi+E\\
\vec(Y)=\vec(X\Phi I)+\vec(E)\Leftrightarrow \\
%\vec(Y)=(I_m\otimes X)\vec(Phi)+\vec(E
%\intertext{либо}
y=(I_M\otimes X)\phi + \varepsilon
\end{gather*}
где $\varepsilon  \sim \cN(0,\varSigma\ \otimes\ I_T)$ и вектор $\phi=\vec{\Phi}$ имеет размерность $km\times 1$.

Тогда:
\begin{equation}
\phi\sim \cN(\underline \phi, \underline \Xi)
\end{equation}
На практике в качестве матрицы $\Sigma$ используют её оценку $\hat\Sigma$, диагональные элементы которой равны: $\hat\sigma_{1}^2, \hat\sigma_{2}^2,\ldots,\hat\sigma_{m}^2 $, где  $\hat\sigma_{i}^2$ --- оценка дисперсии случайной составляющей в $AR(p)$ модели для ряда $i$.
Априорная плотность распределения $\phi$ может быть записана как:
\begin{equation}
p(\phi)=\frac{1}{(2\pi)^{km/2}|\Xi|^{1/2}} \exp \left\lbrace-\frac{1}{2}(\phi-\underline \phi)'\Xi^{-1}(\phi-\underline \phi ) \right\rbrace.
\end{equation}

Комбинируя её с функцией правдоподобия \eqref{likelihood}, получаем, что апостериорное распределение параметров задаются в следующем виде:
\begin{gather}
\phi|Y\sim \cN(\bar{\phi},\bar \Xi)\\
\text{где}\quad \bar \Xi=[\underline \Xi^{-1}+(\varSigma^{-1}\otimes(X'X))]^{-1}\\
\text{и}\quad \bar{\phi}=\bar{\Xi}[\underline \Xi^{-1}\underline \phi+(\varSigma^{-1}\otimes X)'y].
\end{gather}

Априорное распределение Миннесоты было задумано таким образом, чтобы учесть нестационарность многих макроэкономических временных рядов. В этом априорном распределении предполагается, что диагональные элементы матрицы первого лага $\Phi_1$ имеют матожидание единица, а остальные элементы матрицы первого лага и все элементы остальных матриц равны нулю, т.е.:

\begin{equation}
\underline{\Phi}=\E[(\Phi_l)_{ij}|\Sigma]=\begin{cases}
1,& i=j, l=1;\\
0,&\text{ в остальных случаях }
\end{cases}\label{minnesota_exp}
\end{equation}

Однако это априорное распределение может быть обобщено до случая, когда все диагональные элементы матрицы первого лага имеют матожидание $\phi_{ii}$, где $\phi_{ii}$ принимает значение единица для нестационарных рядов и меньше единицы для стационарных (рядов с высокой степенью персистентности).

Априорное распределение Миннесоты предполагает, что априорная ковариационная матрица $\underline \Xi$ диагональна.
Пусть $\underline \Xi_i$ обозначает блок $\underline \Xi$, размера $k\times k$, связанный с коэффициентами уравнения $i$. Тогда  диагональные элементы  $\underline \Xi_i$ определяются по формулам:

\begin{equation}
\Var((\Phi_l)_{ij})=\begin{cases}
\frac{\lambda_1^2}{l^2}, \; \text{ для переменной  } i \text{ и лага } l,\\
\frac{\lambda_1^2\lambda_2^2\sigma^2_i}{l^2\sigma^2_j}, \; \text{ для переменной } j\neq i \text{ и лага } l, \\
\lambda_3^2\sigma_i^2, \; \text{ для коэффициентов при экзогенных переменных }
\end{cases}
\label{minnesota_variance}
\end{equation}

%\begin{itemize}
%\item $\frac{\lambda_1}{l^2}$ --- для переменной $i$ и лага $l$
%\item $\frac{\lambda_1\lambda_2\sigma^2_i}{l^2\sigma^2_j}$ --- для переменной $j\neq i$ и лага $l$
%\item $\lambda_3\sigma_i^2 \label{minnesota_variance}$ --- для коэффициентов при экзогенных переменных
%\end{itemize}

Как можно видеть из приведенной выше формулы \eqref{minnesota_variance} априорная дисперсия параметров зависит от нескольких гиперпараметров, задаваемых исследователем. Гиперпараметры имеют следующую интерпретацию: $\lambda_1$ (параметр регуляризации) отражает общую <<жесткость>> априорного распределения. Если $\lambda_1\to 0$, то априорное распределение полностью определяет апостериорное распределение, и данные не играют никакой роли при оценке параметров. Наоборот, если $\lambda_1\to \infty$, то априорное распределение перестает влиять и оценка параметров сходится к обычной оценке МНК. Параметр $\lambda_2$ (параметр кросс-регуляризации) добавляет дополнительную жесткость лагам других переменных по сравнению с лагами зависимой переменной. Если  $\lambda_2<1$, то собственные лаги зависимой переменной помогают предсказывать значение переменной лучше, чем лаги других переменных. Параметр $\lambda_3$ отражает относительную жесткость распределения константы.

При $\lambda_2=1$ матрица $\Xi$ имеет структуру кронекерова произведения и представима в виде
\[
\Xi = \Sigma \otimes \underline{\Omega},
\]
где $\underline{\Omega}$ --- матрица размера $k\times k$, соответствующая отдельному уравнению. Кронекерово домножение слева на матрицу $\Sigma$ для $i$-го уравнения означает домножение дисперсий, указанных в матрице $\underline{\Omega}$, на коэффициент $\sigma^2_i$.  Начало диагонали матрицы $\underline{\Omega}$ соответствует коэффициентам для лага равного $1$, затем коэффициентам  для лага равного $2$ и т.д. Конец диагонали матрицы $\underline{\Omega}$ соответствует экзогенным переменным. Таким образом диагональ матрицы $\underline{\Omega}$ состоит из вектора $\left(\frac{\lambda_1^2}{l^2 \sigma_1^2}, \frac{\lambda_1^2}{l^2 \sigma_2^2}, \ldots, \frac{\lambda_1^2}{l^2 \sigma_m^2}   \right)$, повторенного $p$ раз, и в конце стоит число $\lambda_3^2$.


Преимущества априорного распределения Миннесоты хорошо известны. Во-первых, оно просто задается, во-вторых, оно успешно применялось в литературе для решения различных задач. В-третьих, получившееся апостериорное распределение является нормальным, и значит, легко можно получить значение любой функции параметров с помощью методов Монте-Карло. Однако существенным недостатком этого распределения является то, что оно не предполагает использования байесовской процедуры для оценки $\Sigma$.

\subsubsection{Сопряженное нормальное-обратное Уишарта априорное распределение}

Указанного недостатка априорного распределения Миннесоты можно избежать, если рассматривать сопряженное априорное распределение, т.е. распределение, при котором  априорное распределение, функция правдоподобия и апостериорное распределение принадлежат одному классу. Т.к. функция правдоподобия может быть разбита на две части, одна из которых соответствует нормальному распределению (при условии известной ковариационной матрицы остатков), а другая --- обратному распределению Уишарта, то и~сопряженным априорным распределением для рассматриваемой модели будет также нормальное-обратное Уишарта распределение.


Априорное нормальное-обратное Уишарта распределение может быть записано как:
\begin{equation}
\Phi|\Sigma\sim \cN (\underline \Phi, \Sigma\otimes\underline \Omega), \qquad \Sigma\sim IW(\underline S, \underline \nu)
\end{equation}

Можно показать, что с учетом функции правдоподобия \eqref{likelihood} апостериорное распределение принадлежит к тому же классу (см, например, \cite{zellner1996introduction}):
\begin{gather}
\Phi|\Sigma,Y\sim \cN (\bar \Phi, \Sigma\otimes\bar \Omega), \qquad \Sigma\sim IW(\bar S, \bar \nu),\\
\mbox{где}\quad \bar \Phi=(\underline \Omega^{-1}+X'X)^{-1}(\underline \Omega^{-1}\underline \Phi+X'Y),\\
\bar{\Omega}=(\underline \Omega^{-1}+X'X)^{-1}\\
\bar\nu =\underline \nu+T\\
\bar S=\underline S +\hat E'\hat E+\hat \Phi X'X \hat \Phi +\underline \Phi'\underline\Omega^{-1}\underline \Phi-\bar \Phi'\bar\Omega^{-1}\bar \Phi\\
\hat\Phi=(X'X)^{-1}X'Y\\%\quad\text{и }
\hat E=Y-X\hat\Phi
\end{gather}
При этом математические ожидания и дисперсии априорного распределения параметров могут быть заданы по тому же принципу, что и в априорном распределении Миннесоты (см. \eqref{minnesota_exp}-\eqref{minnesota_variance}).
%При этом априорные распределения параметров, указанные в \eqref{minnesota_exp}-\eqref{minnesota_variance}), предполагают наличие  нулевой априорной корреляции между коэффициентами.

В работах \cite{doan1984forecasting} and \cite{sims1993nine} было предложено добавить к этим априорным распределениям дополнительную характеристику, введение которой обуславливается возможным наличием во временных рядах единичных корней и коинтеграционных  соотношений. Это позволяет исключить появление неправдоподобно большой доли внутривыборочной дисперсии, объясняемой экзогенными переменными \cite{carriero2015bayesian}. %%% ???

В работах \cite{banbura2010large}, \cite{berg2013point} соответствующее априорное распределение вводится путем добавления искусственных наблюдений:
\begin{equation}
y^{+}=\begin{bmatrix}
\diag(\delta_1\sigma_1,\ldots, \delta_n\sigma_n)\\
0_{n(p-1)\times n}\\
\diag(\sigma_1,\ldots,\sigma_n)\\
0_{1\times n}
\end{bmatrix}
\qquad
%
x^{+}=\begin{bmatrix}
\diag(1,2,\ldots, p)\otimes \diag(\sigma_1,\ldots,\sigma_n)/\lambda & 0_{np\times 1} \\
0_{n\times np}&0_{n\times 1}\\
0_{1\times np}&\epsilon
\end{bmatrix}
\end{equation}


\subsubsection*{Модификация априорных распределений}

Априорное распределение суммы коэффициентов\footnote{sum-of-coefficints prior} было предложено в работе \cite{doan1984forecasting}. Это распределение отражает следующую идею:
когда среднее значение лагированных значений какой либо переменной находится на некотором уровне $\bar y_{0i}$, то это же самое значение  $\bar y_{0i}$, является хорошим прогнозом  для будущих значений этой переменной. В качестве  $\bar y_{0i}$ мы используем среднее значение переменной  $\bar y_{i}$ по первым  $p$ наблюдениям. Внедрение этого априорного распределения производится путем добавления искусственных дамми-наблюдений по следующей схеме:
\begin{gather*}
y_d(i,j)=\begin{cases}
\bar y_{0i}/\lambda_3, \quad \text{если }i=j\\
0 \quad \text{в обратном случае}
\end{cases}
x_d(i,s)=\begin{cases}
\bar y_{0i}/\lambda_3,\quad \text{если }i=j, s<km\\
0 \quad \text{в обратном случае,}
\end{cases}
\end{gather*}
где $i,j=1,\ldots,m$, $s=1, \ldots, km$. Когда $\lambda_3\to 0$, модель стремится к виду, предполагающему запись в разностях, т.е. единичных корней становится столько же, сколько переменных, и нет коинтеграции.

Другими словами/ другой вариант введения (оставить нужно тот, который будет понятнее):

\begin{equation}
y^{++}=\begin{bmatrix}\diag(\mu_1,\ldots,\mu_n)/\tau\end{bmatrix}\qquad
x^{++}=\begin{bmatrix}(1,2\ldots p)\otimes \diag(\mu_1,\ldots,\mu_n)/\tau &0_{n\times 1}\end{bmatrix}
\end{equation}


Априорное распределение изначального наблюдения\footnote{dummy initial observation prior }, предложенное в работе \cite{sims1993nine} означает, что исследователь вводит единственное дамми-наблюдение, такое, что все значения всех переменных равны соответствующему среднему начальных условий с точностью до коэффициента масштаба $1/\lambda_4$. Это происходит  путем добавления в систему дамми-наблюдений следующего вида:
\begin{gather*}
y_d(j)=\begin{cases}\bar y_{0i}/\lambda_4 \qquad
\bar y_{0i}/\lambda_4\quad \text{если }s<km\\
1/\lambda_4 \quad \text{в обратном случае,}
\end{cases}
\end{gather*}
где $j=1,\ldots m, s=1,\ldots km$. Когда $\lambda_4\to 0 $ модель принимает вид, в котором либо все переменные стационарны со средним, равным выборочному среднему начальных условий, либо существуют коинтегрированные ряды с  единичным корнем но без дрейфа.

\subsection{Выбор гиперпараметров и числа лагов}

Как было показано в работе \cite{de2008forecasting} и подтверждено в других более поздних работах, использование сравнительно большого количества временных рядов требует уменьшения параметра $\lambda_1$ с увеличением размерности выборки, что означает наложение более жесткого априорного распределения. На данный момент в литературе используется два подхода к определению оптимальной величины $\lambda_1$. В своей работе мы используем оба и сравниваем качество прогноза.

Первый алгоритм был предложен в работе \cite{banbura2010large} и он основан на идее о том, что регуляризация должна быть настолько жесткой, чтобы не исключить возможность избыточной параметризации модели, при этом предполагается, что трехмерная VAR --- достаточно простая (parsimonious) модель, не содержащая слишком большого количества параметров. Процедура выбора $\lambda$ состоит в том, что что средний внутривыборочный прогноз для реального ВВП и индекса цен тот же самый, как на первой выборке (на которой происходит) оценивание. Каждая модель регуляризуется до размера простой VAR. При этом  референтной моделью является та, для которой апостериорное распределение не зависит от функции правдоподобия, т.е. для которой $\lambda=0$. Это означает, что дисперсии всех параметров $\phi$ равны нулю, и переменные описываются моделью случайного блуждания (RW) со смещением $(y_{i,t}=c+y_{i,t-1 +\varepsilon_t}, i=1,\ldots,m$. Обозначим эту модель индексом 0,  так как $\lambda=0$.
Схема выбора $\lambda$ состоит из следующих этапов:
\begin{enumerate}
\item На первом этапе  строятся внутривыборочные однопериодные прогнозы на обучающей выборке и рассчитывается среднеквадратичная ошибка прогноза выпуска $(MSFE_y^{0})$ и инфляции $(MSFE_{\pi}^{0})$.
\item Оценивается трехмерная VAR для $\lambda\to \infty$ \footnote{При $\lambda\to \infty$ оценки BVAR совпадают с оценками VAR методами OLS или ML, т. к. апостериорное распределение параметров в этом случае совпадает с функцией правдоподобия. Считается, что трехмерная VAR содержит достаточно маленькое число параметров, и байесовская регуляризация не требуется.} и рассчитываются среднеквадратичная ошибка прогноза выпуска $(MSFE_y^{\infty})$ и инфляции $(MSFE_{\pi}^{\infty})$ и показатель $FIT^{\infty}$:
\begin{equation}
FIT^{\infty}=\frac{1}{2}\cdot\frac{MSFE_y^{\infty}}{MSFE^0_y} + \frac{1}{2}\cdot\frac{MSFE_{\pi}^{\infty}}{MSFE^0_{\pi}}
\end{equation}
\item Оцениваются BVAR модели для $m$ переменных и для большого числа различных $\lambda$ рассчитываются среднеквадратичные ошибки прогноза для выпуска $(MSFE_y^{\lambda,m})$ и инфляции $(MSFE_{\pi}^{\lambda,m})$ и показатель $FIT^{{\lambda,m}}$: 
\begin{equation}
FIT^{\lambda,m}=\frac{1}{2}\cdot\frac{MSFE_y^{\lambda,m}}{MSFE^0_y} + \frac{1}{2}\cdot\frac{MSFE_{\pi}^{\lambda,m}}{MSFE^0_{\pi}}
\end{equation}
\item Оптимальное $\lambda$ рассчитывается как значение, при котором минимизируется отклонение $FIT^{\lambda,m}$ от $FIT^{\infty}$:
\begin{equation}
\lambda^*=\argmin |FIT^{\lambda, m}-FIT^{\infty}| 
\end{equation}
\end{enumerate}
После того как выбрано оптимальное значение $\lambda_1$ для каждой модели, происходит построение вневыборочных прогнозов на оценивающей выборке.


Второй алгоритм предложен в работе (Carriero et al, 2002) и представляет собой выбор такого параметра $\lambda_1$, который бы максимизировал функцию предельной плотности:
\begin{equation}
\lambda_{1t}^*=\argmax_{\lambda_1} \ln p(Y)
\end{equation}

При этом функция предельной плотности может быть получена путем интегрирования коэффициентов модели: \footnote{Т.к. интегрирование происходит по  всем коэффициентам, но не по гиперпараметрам априорного распределения ($\lambda_1,\lambda_2,\lambda_3$)  и не по числу лагов $p$, то предельная плотность является функцией $\lambda_j,j=1\ldots 3$ и $p$.}
\begin{equation}
p(Y)=\int p(Y|\phi)p(\phi) d \phi
\end{equation}
Если априорное распределение является нормальным --- обратным Уишарта, то предельная плотность $p(Y)$ может быть посчитана аналитически (\cite{zellner1996introduction}; Bauwens et al,1999; Carriero et al,2012):
%\begin{equation}
\begin{multline}
p(Y)=\pi^{-\frac{Tm}{2}}\times +\left |(I+X\underline{\Omega} X')^{-1}\right|^{\frac{N}{2}}\times |\underline{S}|^{\frac{\underline{\nu}}{2}}\times \frac{\Gamma_N(\frac{\underline{\nu}+T}{2})}{\Gamma_N(\frac{\underline{\nu}}{2})}\times \\ \times
\left|\underline{S}+(Y-X\underline{\Phi})'(I+X\underline{\Omega} X')^{-1}(Y-X\underline{\Phi})\right|^{-\frac{\underline{\nu}+T}{2}},\label{marginal_density}
\end{multline}
где $\Gamma_N(\cdot)$ обозначает $N$-мерную гамма функцию.
Выбор числа лагов происходит аналогично путем максимизации по $p$ функции предельной плотности \eqref{marginal_density}: 
\begin{equation}
p^*=\argmax_{p} \ln p(Y)
\end{equation} 





\printbibliography

\end{document} 